<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>mdsine2.dataset API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mdsine2.dataset</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import os
import logging
from typing import Dict, Union
from .pylab import TaxaSet, Study

__all__ = [&#39;load_gibson&#39;, &#39;parse&#39;]

def load_gibson(dset: str=None, as_df: bool=False, with_perturbations: bool=True, species_assignment: str=&#39;both&#39;,
    load_local: str=None, max_n_species: int=2) -&gt; Union[Dict[str, pd.DataFrame], Study]:
    &#39;&#39;&#39;Load the Gibson dataset.
    Returns either a `mdsine2.Study` object or the `pandas.DataFrame` objects that
    that comprise the Gibson dataset.

    Tries to load the dataset from Github. If there is no internet connection, then we
    can read it from a local path specfied with the parameter `load_local`.

    Parameters
    ----------
    dset : str, None
        If &#39;healthy&#39;, return the Healthy cohort.
        If &#39;UC&#39;, return the Ulcerative Colitis cohort.
        If &#39;replicates&#39;, return the replicate samples used for learning negative binomial
        dispersion parameters
        If &#39;inoculum&#39;, return the samples used for the inoculum
        If None, return all the data.
    as_df : bool
        If True, return the four dataframes that make up the data as a dict (str-&gt;pandas.DataFrame)
        dict: 
            &#39;taxonomy&#39; -&gt; Taxonomy table
            &#39;reads&#39; -&gt; Reads table
            &#39;qpcr&#39; -&gt; qPCR table
            &#39;metadata&#39; -&gt; metadata table
    with_perturbations : bool
        If True, load in the perturbations. Otherwise do not load them
    species_assignment : str, None
        How to assign the species
        If &#39;silva&#39;, only use the Silva species assignment
        If &#39;rdp&#39;, only use RDP 138 assignment
        If &#39;both&#39;, combine both the RDP and Silva species assignment
        If None, have no species assignment and just return the taxonomy provided by DADA2
    load_local : str, None
        If specified, this is the local base path with all the files to load from. it will
        expect the respective file names. One may want to use this if they cannot get access
        to the internet
    max_n_species : int
        This is the maximum number of species assignments allowed before the lowest taxonomic
        assignment gets bumped up to Genus.

    Returns
    -------
    mdsine2.Study OR dict
    &#39;&#39;&#39;
    # Load the taxonomy assignment
    logging.debug(&#39;Downloading taxonomy&#39;)
    taxonomy = _Gibson.load_taxonomy(species_assignment=species_assignment, load_local=load_local,
        max_n_species=max_n_species)
    logging.debug(&#39;Downloading metadata&#39;)
    metadata = _Gibson.load_sampleid(dset=dset, load_local=load_local)
    logging.debug(&#39;Downloading reads&#39;)
    reads = _Gibson.load_reads(dset=dset, load_local=load_local)
    logging.debug(&#39;Downloading qpcr&#39;)
    qpcr = _Gibson.load_qpcr_masses(dset=dset, load_local=load_local)
    if with_perturbations:
        logging.debug(&#39;Downloading peturbations&#39;)
        perturbations = _Gibson.load_perturbations(dset=dset, load_local=load_local)
    else:
        perturbations = None

    if as_df:
        return {&#39;metadata&#39;: metadata, &#39;taxonomy&#39;: taxonomy, 
            &#39;reads&#39;: reads, &#39;qpcr&#39;:qpcr, &#39;perturbations&#39;: perturbations}
    else:
        taxa = TaxaSet(taxonomy_table=taxonomy)
        study = Study(taxa=taxa, name=dset)
        study.parse(
            metadata=metadata,
            reads=reads,
            qpcr=qpcr,
            perturbations=perturbations)
        return study

def parse(name: str, metadata: str, taxonomy: str, reads: str=None, qpcr: str=None, 
    perturbations: str=None, sep: str=&#39;\t&#39;) -&gt; Study:
    &#39;&#39;&#39;Parse a dataset. Acts as a wrapper for `mdsine2.Study.parse`

    Parameters
    ----------
    name : str
        This is the name of the study
    metadata : str
        This is the location for the metadata table
    taxonomy : str
        This is the location for the taxonomy table
    reads : str
        This is the location for the reads table
    qpcr : str
        This is the location for the qPCR table
    perturbations : str
        This is the location for the perturbations table
    sep : str
        This is the separator for each table
    
    Returns
    -------
    mdsine2.Study
    &#39;&#39;&#39;
    taxonomy = pd.read_csv(taxonomy, sep=sep)
    taxa = TaxaSet()
    taxa.parse(taxonomy_table=taxonomy)
    study = Study(taxa, name=name)

    metadata = pd.read_csv(metadata, sep=sep)
    if reads is not None:
        reads = pd.read_csv(reads, sep=sep)
    if qpcr is not None:
        qpcr = pd.read_csv(qpcr, sep=sep)
    if perturbations is not None:
        perturbations = pd.read_csv(perturbations, sep=sep)
    
    return study.parse(metadata=metadata, reads=reads, qpcr=qpcr, perturbations=perturbations)

class _Gibson:
    &#39;&#39;&#39;Wrapper for the functionality of loading the gibson dataset. Called through
    `mdsine2.dataset.gibson`. See 
    &#39;&#39;&#39;
    _HEALTHY_SUBJECTS = set([&#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;])
    _UC_SUBJECTS = set([&#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;10&#39;])

    _URL_PATH = &#39;https://raw.githubusercontent.com/gerberlab/MDSINE2_Paper/master/datasets/gibson/&#39;

    _URL_READS = &#39;counts.tsv&#39;
    _URL_RDP_TAX = &#39;rdp_species.tsv&#39;
    _URL_SILVA_TAX = &#39;silva_species.tsv&#39;
    _URL_PERTS = &#39;perturbations.tsv&#39;
    _URL_QPCR = &#39;qpcr.tsv&#39;
    _URL_METADATA = &#39;metadata.tsv&#39;

    @staticmethod
    def load_taxonomy(species_assignment, load_local=None, max_n_species=2):
        &#39;&#39;&#39;Load the taxonomy assignment
        Parameters
        ----------
        species_assignment : str, None
            How to assign the species
            If &#39;silva&#39;, only use the Silva species assignment
            If &#39;rdp&#39;, only use RDP 138 assignment
            If &#39;both&#39;, combine both the RDP and Silva species assignment
            If None, have no species assignment and just return the taxonomy provided by DADA2
        load_local : str, None  
            This is the local path if we need to load it locally. Otherwise we download from
            github
        max_n_species : int
            This is the maximum number of species assignments allowed before the lowest taxonomic
            assignment gets bumped up to Genus.

        Returns
        -------
        pandas.DataFrame
        &#39;&#39;&#39;
        if species_assignment == &#39;silva&#39;:
            if load_local is None:
                path = _Gibson._URL_PATH + _Gibson._URL_SILVA_TAX
            else:
                logging.debug(&#39;Load local&#39;)
                path = os.path.join(load_local, _Gibson._URL_SILVA_TAX)
            taxonomy = pd.read_csv(path, sep=&#39;\t&#39;, index_col=0)
        elif species_assignment == &#39;rdp&#39;:
            if load_local is None:
                path = _Gibson._URL_PATH + _Gibson._URL_RDP_TAX
            else:
                logging.debug(&#39;Load local&#39;)
                path = os.path.join(load_local, _Gibson._URL_RDP_TAX)
            taxonomy = pd.read_csv(path, sep=&#39;\t&#39;, index_col=0)
        elif species_assignment == &#39;both&#39;:
            if load_local is None:
                path = _Gibson._URL_PATH + _Gibson._URL_RDP_TAX
            else:
                logging.debug(&#39;Load local&#39;)
                path = os.path.join(load_local, _Gibson._URL_RDP_TAX)
            rdp = pd.read_csv(path, sep=&#39;\t&#39;, index_col=0)
            
            if load_local is None:
                path = _Gibson._URL_PATH + _Gibson._URL_SILVA_TAX
            else:
                logging.debug(&#39;Load local&#39;)
                path = os.path.join(load_local, _Gibson._URL_SILVA_TAX)
            silva = pd.read_csv(path, sep=&#39;\t&#39;, index_col=0)

            rdp.columns = rdp.columns.str.lower()
            silva.columns = silva.columns.str.lower()

            data = []

            for iii, aname in enumerate(rdp.index):

                rdp_spec = rdp[&#39;species&#39;][aname]
                silva_spec = silva[&#39;species&#39;][aname]
                tmp = rdp.iloc[iii, :-1].to_list()

                if type(rdp_spec) == float:
                    rdp_spec = &#39;NA&#39;
                if type(silva_spec) == float:
                    silva_spec = &#39;NA&#39;
                rdp_spec = rdp_spec.split(&#39;/&#39;)
                silva_spec = silva_spec.split(&#39;/&#39;)

                both = list(set(rdp_spec + silva_spec))
                if &#39;NA&#39; in both and len(both) &gt; 1:
                    both.remove(&#39;NA&#39;)

                if len(both) &gt; max_n_species:
                    both = &#39;NA&#39;
                else:
                    both = &#39;/&#39;.join(both)
                tmp.append(both)
                data.append(tmp)

            taxonomy = pd.DataFrame(data, columns=rdp.columns, index=rdp.index)

        elif species_assignment is None:
            taxonomy = _Gibson._URL_PATH + _Gibson._URL_RDP_TAX
            taxonomy = pd.read_csv(taxonomy, sep=&#39;\t&#39;)
            taxonomy[&#39;species&#39;][:] = &#39;NA&#39;
        else:
            raise ValueError(&#39;`species_assignment` ({}) is not recognized.&#39;.format(species_assignment))
        return taxonomy
    
    @staticmethod
    def load_perturbations(dset=None, load_local=None):
        &#39;&#39;&#39;Load the perturbations for Gibson dataset as a `pandas.DataFrame`.

        Parameters
        ----------
        dset : str
            This is the dataset to load.
        load_local : str, None  
            This is the local path if we need to load it locally. Otherwise we download from
            github

        Returns
        -------
        pandas.DataFrame
        &#39;&#39;&#39;
        if load_local is None:
            path = _Gibson._URL_PATH + _Gibson._URL_PERTS
        else:
            logging.debug(&#39;Load local&#39;)
            path = os.path.join(load_local, _Gibson._URL_PERTS)
        df = pd.read_csv(path, sep=&#39;\t&#39;)

        if dset is None:
            pass
        elif dset == &#39;inoculum&#39;:
            df = None
        elif dset == &#39;replicates&#39;:
            df = None
        elif dset == &#39;healthy&#39;:
            row_to_keep = []
            for i, subj in enumerate(df[&#39;subject&#39;]):
                if str(subj) in _Gibson._HEALTHY_SUBJECTS:
                    row_to_keep.append(i)
            df = df.iloc[row_to_keep, :]
        elif dset == &#39;uc&#39;:
            row_to_keep = []
            for i, subj in enumerate(df[&#39;subject&#39;]):
                if str(subj) in _Gibson._UC_SUBJECTS:
                    row_to_keep.append(i)
            df = df.iloc[row_to_keep, :]
        else:
            raise ValueError(&#39;`dset` ({}) not recognized&#39;.format(dset))
        return df

    @staticmethod
    def load_qpcr_masses(dset=None, load_local=None):
        &#39;&#39;&#39;Load qpcr masses table into a `pandas.DataFrame`.

        Parameters
        ----------
        dset : str
            This is the dataset to load.
        load_local : str, None  
            This is the local path if we need to load it locally. Otherwise we download from
            github

        Returns
        -------
        pandas.DataFrame
        &#39;&#39;&#39;
        if load_local is None:
            path = _Gibson._URL_PATH + _Gibson._URL_QPCR
        else:
            logging.debug(&#39;Load local&#39;)
            path = os.path.join(load_local, _Gibson._URL_QPCR)
        
        df = pd.read_csv(path, sep=&#39;\t&#39;)
        df = df.set_index(&#39;sampleID&#39;)

        if dset is not None:
            keep = _Gibson._get_sampleids(eles=df.index, dset=dset)
            df = df.loc[keep]
        return df

    @staticmethod
    def load_reads(dset=None, load_local=None):
        &#39;&#39;&#39;Load reads table into a `pandas.DataFrame`.

        Parameters
        ----------
        dset : str
            This is the dataset to load.
        load_local : str, None  
            This is the local path if we need to load it locally. Otherwise we download from
            github

        Returns
        -------
        pandas.DataFrame
        &#39;&#39;&#39;
        if load_local is None:
            path = _Gibson._URL_PATH + _Gibson._URL_READS
        else:
            logging.debug(&#39;Load local&#39;)
            path = os.path.join(load_local, _Gibson._URL_READS)
        df = pd.read_csv(path, sep=&#39;\t&#39;, index_col=0)

        if dset is not None:
            keep = _Gibson._get_sampleids(eles=df.columns, dset=dset)
            df = df[keep]
        return df

    @staticmethod
    def load_sampleid(dset=None, load_local=None):
        &#39;&#39;&#39;Load sample ID table into a `pandas.DataFrame`.

        Parameters
        ----------
        dset : str
            This is the dataset to load.
        load_local : str, None  
            This is the local path if we need to load it locally. Otherwise we download from
            github

        Returns
        -------
        pandas.DataFrame
        &#39;&#39;&#39;
        if load_local is None:
            path = _Gibson._URL_PATH + _Gibson._URL_METADATA
        else:
            path = os.path.join(load_local, _Gibson._URL_METADATA)
        df = pd.read_csv(path, sep=&#39;\t&#39;)
        df = df.set_index(&#39;sampleID&#39;)

        if dset is not None:
            keep = _Gibson._get_sampleids(eles=df.index, dset=dset)
            df = df.loc[keep]
        return df

    @staticmethod
    def _get_sampleids(eles, dset):
        keep = []

        for sampleid in eles:

            mid = sampleid.split(&#39;-&#39;)[0]
            if mid == &#39;1&#39;:
                continue

            if dset == &#39;inoculum&#39; and _Gibson._is_inoc_sampleid(sampleid):
                keep.append(sampleid)
            elif dset == &#39;replicates&#39; and _Gibson._is_negbin_sampleid(sampleid):
                keep.append(sampleid)
            elif dset == &#39;healthy&#39; and _Gibson._is_healthy_sampleid(sampleid):
                keep.append(sampleid)
            elif dset == &#39;uc&#39; and _Gibson._is_uc_sampleid(sampleid):
                keep.append(sampleid)

        return keep

    @staticmethod
    def _is_healthy_sampleid(sampleid):
        &#39;&#39;&#39;Checks whether the sample id is for healty or UC
        Parameters
        ----------
        sampleid : str
            Sample ID
        Returns
        -------
        bool
        &#39;&#39;&#39;
        sid = sampleid.split(&#39;-&#39;)[0]
        return sid in _Gibson._HEALTHY_SUBJECTS

    @staticmethod
    def _is_uc_sampleid(sampleid):
        &#39;&#39;&#39;Checks whether the sample id is for healty or UC
        Parameters
        ----------
        sampleid : str
            Sample ID
        Returns
        -------
        bool
        &#39;&#39;&#39;
        sid = sampleid.split(&#39;-&#39;)[0]
        return sid in _Gibson._UC_SUBJECTS

    @staticmethod
    def _is_negbin_sampleid(sampleid):
        &#39;&#39;&#39;Checks whether the sample id is for learning the negative
        binomial dispersion parameters
        Parameters
        ----------
        sampleid : str
            Sample ID
        Returns
        -------
        bool
        &#39;&#39;&#39;
        return &#39;M2-D&#39; in sampleid

    @staticmethod
    def _is_inoc_sampleid(sampleid):
        &#39;&#39;&#39;Checks whether the sample id is from the inoculum
        Parameters
        ----------
        sampleid : str
            Sample ID
        Returns
        -------
        bool
        &#39;&#39;&#39;
        return &#39;inoculum&#39; in sampleid</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="mdsine2.dataset.load_gibson"><code class="name flex">
<span>def <span class="ident">load_gibson</span></span>(<span>dset: str = None, as_df: bool = False, with_perturbations: bool = True, species_assignment: str = 'both', load_local: str = None, max_n_species: int = 2) ‑> Union[Dict[str, pandas.core.frame.DataFrame], <a title="mdsine2.pylab.base.Study" href="pylab/base.html#mdsine2.pylab.base.Study">Study</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Load the Gibson dataset.
Returns either a <code>mdsine2.Study</code> object or the <code>pandas.DataFrame</code> objects that
that comprise the Gibson dataset.</p>
<p>Tries to load the dataset from Github. If there is no internet connection, then we
can read it from a local path specfied with the parameter <code>load_local</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dset</code></strong> :&ensp;<code>str, None</code></dt>
<dd>If 'healthy', return the Healthy cohort.
If 'UC', return the Ulcerative Colitis cohort.
If 'replicates', return the replicate samples used for learning negative binomial
dispersion parameters
If 'inoculum', return the samples used for the inoculum
If None, return all the data.</dd>
<dt><strong><code>as_df</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, return the four dataframes that make up the data as a dict (str-&gt;pandas.DataFrame)
dict:
'taxonomy' -&gt; Taxonomy table
'reads' -&gt; Reads table
'qpcr' -&gt; qPCR table
'metadata' -&gt; metadata table</dd>
<dt><strong><code>with_perturbations</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, load in the perturbations. Otherwise do not load them</dd>
<dt><strong><code>species_assignment</code></strong> :&ensp;<code>str, None</code></dt>
<dd>How to assign the species
If 'silva', only use the Silva species assignment
If 'rdp', only use RDP 138 assignment
If 'both', combine both the RDP and Silva species assignment
If None, have no species assignment and just return the taxonomy provided by DADA2</dd>
<dt><strong><code>load_local</code></strong> :&ensp;<code>str, None</code></dt>
<dd>If specified, this is the local base path with all the files to load from. it will
expect the respective file names. One may want to use this if they cannot get access
to the internet</dd>
<dt><strong><code>max_n_species</code></strong> :&ensp;<code>int</code></dt>
<dd>This is the maximum number of species assignments allowed before the lowest taxonomic
assignment gets bumped up to Genus.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.Study OR dict</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_gibson(dset: str=None, as_df: bool=False, with_perturbations: bool=True, species_assignment: str=&#39;both&#39;,
    load_local: str=None, max_n_species: int=2) -&gt; Union[Dict[str, pd.DataFrame], Study]:
    &#39;&#39;&#39;Load the Gibson dataset.
    Returns either a `mdsine2.Study` object or the `pandas.DataFrame` objects that
    that comprise the Gibson dataset.

    Tries to load the dataset from Github. If there is no internet connection, then we
    can read it from a local path specfied with the parameter `load_local`.

    Parameters
    ----------
    dset : str, None
        If &#39;healthy&#39;, return the Healthy cohort.
        If &#39;UC&#39;, return the Ulcerative Colitis cohort.
        If &#39;replicates&#39;, return the replicate samples used for learning negative binomial
        dispersion parameters
        If &#39;inoculum&#39;, return the samples used for the inoculum
        If None, return all the data.
    as_df : bool
        If True, return the four dataframes that make up the data as a dict (str-&gt;pandas.DataFrame)
        dict: 
            &#39;taxonomy&#39; -&gt; Taxonomy table
            &#39;reads&#39; -&gt; Reads table
            &#39;qpcr&#39; -&gt; qPCR table
            &#39;metadata&#39; -&gt; metadata table
    with_perturbations : bool
        If True, load in the perturbations. Otherwise do not load them
    species_assignment : str, None
        How to assign the species
        If &#39;silva&#39;, only use the Silva species assignment
        If &#39;rdp&#39;, only use RDP 138 assignment
        If &#39;both&#39;, combine both the RDP and Silva species assignment
        If None, have no species assignment and just return the taxonomy provided by DADA2
    load_local : str, None
        If specified, this is the local base path with all the files to load from. it will
        expect the respective file names. One may want to use this if they cannot get access
        to the internet
    max_n_species : int
        This is the maximum number of species assignments allowed before the lowest taxonomic
        assignment gets bumped up to Genus.

    Returns
    -------
    mdsine2.Study OR dict
    &#39;&#39;&#39;
    # Load the taxonomy assignment
    logging.debug(&#39;Downloading taxonomy&#39;)
    taxonomy = _Gibson.load_taxonomy(species_assignment=species_assignment, load_local=load_local,
        max_n_species=max_n_species)
    logging.debug(&#39;Downloading metadata&#39;)
    metadata = _Gibson.load_sampleid(dset=dset, load_local=load_local)
    logging.debug(&#39;Downloading reads&#39;)
    reads = _Gibson.load_reads(dset=dset, load_local=load_local)
    logging.debug(&#39;Downloading qpcr&#39;)
    qpcr = _Gibson.load_qpcr_masses(dset=dset, load_local=load_local)
    if with_perturbations:
        logging.debug(&#39;Downloading peturbations&#39;)
        perturbations = _Gibson.load_perturbations(dset=dset, load_local=load_local)
    else:
        perturbations = None

    if as_df:
        return {&#39;metadata&#39;: metadata, &#39;taxonomy&#39;: taxonomy, 
            &#39;reads&#39;: reads, &#39;qpcr&#39;:qpcr, &#39;perturbations&#39;: perturbations}
    else:
        taxa = TaxaSet(taxonomy_table=taxonomy)
        study = Study(taxa=taxa, name=dset)
        study.parse(
            metadata=metadata,
            reads=reads,
            qpcr=qpcr,
            perturbations=perturbations)
        return study</code></pre>
</details>
</dd>
<dt id="mdsine2.dataset.parse"><code class="name flex">
<span>def <span class="ident">parse</span></span>(<span>name: str, metadata: str, taxonomy: str, reads: str = None, qpcr: str = None, perturbations: str = None, sep: str = '\t') ‑> <a title="mdsine2.pylab.base.Study" href="pylab/base.html#mdsine2.pylab.base.Study">Study</a></span>
</code></dt>
<dd>
<div class="desc"><p>Parse a dataset. Acts as a wrapper for <code>mdsine2.Study.parse</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the name of the study</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location for the metadata table</dd>
<dt><strong><code>taxonomy</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location for the taxonomy table</dd>
<dt><strong><code>reads</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location for the reads table</dd>
<dt><strong><code>qpcr</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location for the qPCR table</dd>
<dt><strong><code>perturbations</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location for the perturbations table</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the separator for each table</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.Study</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse(name: str, metadata: str, taxonomy: str, reads: str=None, qpcr: str=None, 
    perturbations: str=None, sep: str=&#39;\t&#39;) -&gt; Study:
    &#39;&#39;&#39;Parse a dataset. Acts as a wrapper for `mdsine2.Study.parse`

    Parameters
    ----------
    name : str
        This is the name of the study
    metadata : str
        This is the location for the metadata table
    taxonomy : str
        This is the location for the taxonomy table
    reads : str
        This is the location for the reads table
    qpcr : str
        This is the location for the qPCR table
    perturbations : str
        This is the location for the perturbations table
    sep : str
        This is the separator for each table
    
    Returns
    -------
    mdsine2.Study
    &#39;&#39;&#39;
    taxonomy = pd.read_csv(taxonomy, sep=sep)
    taxa = TaxaSet()
    taxa.parse(taxonomy_table=taxonomy)
    study = Study(taxa, name=name)

    metadata = pd.read_csv(metadata, sep=sep)
    if reads is not None:
        reads = pd.read_csv(reads, sep=sep)
    if qpcr is not None:
        qpcr = pd.read_csv(qpcr, sep=sep)
    if perturbations is not None:
        perturbations = pd.read_csv(perturbations, sep=sep)
    
    return study.parse(metadata=metadata, reads=reads, qpcr=qpcr, perturbations=perturbations)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mdsine2" href="index.html">mdsine2</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="mdsine2.dataset.load_gibson" href="#mdsine2.dataset.load_gibson">load_gibson</a></code></li>
<li><code><a title="mdsine2.dataset.parse" href="#mdsine2.dataset.parse">parse</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>