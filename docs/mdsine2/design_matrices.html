<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>mdsine2.design_matrices API documentation</title>
<meta name="description" content="These are classes for constructing the design matrices â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mdsine2.design_matrices</code></h1>
</header>
<section id="section-intro">
<p>These are classes for constructing the design matrices.</p>
<h2 id="main-classes">Main Classes</h2>
<ul>
<li><code><a title="mdsine2.design_matrices.Data" href="#mdsine2.design_matrices.Data">Data</a></code><ul>
<li>This class is what <code>mdsine2.Graph.data</code> points to. It keeps all the design matrices for
each class consistent as well as provides functionality and core functions that are used
in inference. The main job of this class is to act as a pointer to the individual design
matrices that are used in inference. You can access these classes with the pointer
<code>Data.design_matrices[name_of_class]</code>.</li>
</ul>
</li>
<li><code><a title="mdsine2.design_matrices.LHSVector" href="#mdsine2.design_matrices.LHSVector">LHSVector</a></code><ul>
<li>This is the Left Hand Side (LHS) of the MDSINE2 model:
[
]
where<ul>
<li>x is the latent abundance at point k</li>
<li>t is the time at point k</li>
</ul>
</li>
</ul>
</li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></code> subclasses<ul>
<li>These build the right hand side of the MDSINE2 model and is broken up into individual
classes:<ul>
<li>Growth : The RHS for the growth parameter is in <code><a title="mdsine2.design_matrices.GrowthDesignMatrix" href="#mdsine2.design_matrices.GrowthDesignMatrix">GrowthDesignMatrix</a></code></li>
<li>Self-interactions : The RHS for the self-interaction parameter is in <code><a title="mdsine2.design_matrices.SelfInteractionDesignMatrix" href="#mdsine2.design_matrices.SelfInteractionDesignMatrix">SelfInteractionDesignMatrix</a></code></li>
<li>Perturbations : The RHS for the perturbation parameter is in <code><a title="mdsine2.design_matrices.PerturbationDesignMatrix" href="#mdsine2.design_matrices.PerturbationDesignMatrix">PerturbationDesignMatrix</a></code> which is
composed of <code><a title="mdsine2.design_matrices.PerturbationBaseDesignMatrix" href="#mdsine2.design_matrices.PerturbationBaseDesignMatrix">PerturbationBaseDesignMatrix</a></code> and <code><a title="mdsine2.design_matrices.PerturbationMixingDesignMatrix" href="#mdsine2.design_matrices.PerturbationMixingDesignMatrix">PerturbationMixingDesignMatrix</a></code>. For
more details, see <code><a title="mdsine2.design_matrices.PerturbationDesignMatrix" href="#mdsine2.design_matrices.PerturbationDesignMatrix">PerturbationDesignMatrix</a></code>.</li>
<li>Interactions : The RHS for the perturbation parameter is in <code><a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a></code> which is
composed of <code><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix">InteractionsBaseDesignMatrix</a></code> and <code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix">InteractionsMixingDesignMatrix</a></code>. For
more details, see <code><a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a></code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;These are classes for constructing the design matrices.

Main classes
------------
- `Data`
    * This class is what `mdsine2.Graph.data` points to. It keeps all the design matrices for
      each class consistent as well as provides functionality and core functions that are used
      in inference. The main job of this class is to act as a pointer to the individual design
      matrices that are used in inference. You can access these classes with the pointer
      `Data.design_matrices[name_of_class]`.
- `LHSVector`
    - This is the Left Hand Side (LHS) of the MDSINE2 model:
      .. math:: (log(x[k+1]) - log(x[k+1]))/(t[k+1] - t[k])
      where
          * x is the latent abundance at point k
          * t is the time at point k
- `DesignMatrix` subclasses
    - These build the right hand side of the MDSINE2 model and is broken up into individual
      classes:
          * Growth : The RHS for the growth parameter is in `GrowthDesignMatrix`
          * Self-interactions : The RHS for the self-interaction parameter is in `SelfInteractionDesignMatrix`
          * Perturbations : The RHS for the perturbation parameter is in `PerturbationDesignMatrix` which is
                            composed of `PerturbationBaseDesignMatrix` and `PerturbationMixingDesignMatrix`. For
                            more details, see `PerturbationDesignMatrix`.
          * Interactions : The RHS for the perturbation parameter is in `InteractionsDesignMatrix` which is
                           composed of `InteractionsBaseDesignMatrix` and `InteractionsMixingDesignMatrix`. For
                           more details, see `InteractionsDesignMatrix`.
&#39;&#39;&#39;

import numpy as np
import logging
import numba
import time
import itertools
import scipy.sparse
from orderedset import OrderedSet

from typing import Union, Dict, Iterator, Tuple, List, Any

from .pylab.graph import DataNode, Node, Graph
from .names import STRNAMES

from . import pylab as pl
from .pylab.base import Study

class Data(DataNode):
    &#39;&#39;&#39;Acts as a collection for the Observation object and a collection of Covariate objects.

    Description of internal objects
    -------------------------------
    - self.data : list(np.ndarray(n_taxa, n_times)) 
        - These are the data matrices that are used to build the design matrices. Index
          the replicate by the index of the list. 
    
    - self.dt[ridx][k] : list(np.ndarray((n_times, ))) 
        - This is the change in time from time index k to time index k+1 for replicate index `ridx`.
    - self.dt_vec : np.ndarray 
        - These have the same values as `self.dt` excpet that the arrays are flattened so that the 
          index of dt corresponds to the row in the design matrix. IE (x[k+1] - x[k])/self.dt[k] can be thought
          of as: 
          ..math:: (x[ridx][aidx, k+1] - x2[ridx][aidx, k])/(times[ridx][k+1] - times[ridx][k])
          for each replicate index `ridx` and Taxa index `aidx`
    - Difference between `self.times` and `self.given_timepoints`
        - `self.times` are all the timepoints that we have data for the latent trajectory whereas
        - `self.given_timepoints` are all the timepoints where we actually have data for as specified in 
        - `self.subjects`. These are going to be different if we have intermediate datapoints

    We assume that once this object gets initialized there is not more deletions of
    Taxas or replicates for the inference, i.e. `subjects` needs to stay fixed during inference
    for this object to stay consistent.

    Parameters
    ----------
    subjects : pylab.base.Study
        These are a list of the subjects that we are going to get data from
    zero_inflation_transition_policy : str
        How we handle the transitions from a structural zero to a non-structural zero.
        If None then we do not assume any zero-inflation. Options:
        &#39;sample&#39;
            Intermediate timepoint is uniformly sampled between the structural zero and 
            non-strctural zero and set at that point.
        &#39;half-way&#39;
            Intermediate timepoint is set to half-way between the structural-zero and
            non-structural zero
        &#39;ignore&#39;
            We ignore the change from not being there to being there and vice versa.
    **kwargs
        - These are the extra arguments for DataNode
    &#39;&#39;&#39;
    def __init__(self, subjects: Study, zero_inflation_transition_policy: str=None, **kwargs):
        if &#39;name&#39; not in kwargs:
            kwargs[&#39;name&#39;] = &#39;data matrix&#39;
        DataNode.__init__(self, **kwargs)
        if not pl.isstudy(subjects):
            raise ValueError(&#39;`subjects` ({}) must be a pylab Study&#39;.format(
                type(subjects)))

        self.taxa = subjects.taxa # This is the TaxaSet object in pylab.base.TaxaSet
        self.subjects = subjects # This is the Study object in pylab.base.Study
        self.zero_inflation_transition_policy = zero_inflation_transition_policy

        self.raw_data = [] # list(np.ndarray) data matrices in count abundance for each subject in order
        self.rel_data = [] # list(np.ndarray) data matrices in relative abundance for each subject in order
        self.abs_data = [] # list(np.ndarray) data matrices in absolute abundance for each subject in order
        self.qpcr = [] # list(dict(float -&gt; qPCRData)) of qPCR objects for the subjects in time order
        self.qpcr_variances = None
        self.read_depths = [] # read depths for each subject in time order
        self.given_timepoints = [] # These are the timepoints that are included with the subject
        self._given_timepoints_set = [] # this is a set object of `given_timepoints`
        self.given_timeindices = [] # These are the indicies for the given timepoints
        self.data_timeindex2given_timeindex = {} # maps the index for all of the times to the index in the original subject
        self.n_timepoints_for_replicate = [] # np.ndarray, number of timepoints for each subject
        self.n_dts_for_replicate = [] # np.ndarray, how many dts there are for each subject (n_timespoints - 1)
        self.times = [] # list(np.ndarray) This is the array of times for each subject
        self.data = [] # list(np.ndarray) This is the where we keep the filtered data
        self.dt = [] # list(np.ndarray) Has each dt between each timepoint for each subject
        self.timepoint2index = [] # list(dict(float, int)) for each subject, maps the time (float) to the index it occurs in (int)
        self.toupdate = OrderedSet() # Which design matrices we change once we filter the data
        self.n_replicates = len(self.subjects)
        self.n_taxa = len(self.taxa)

        for ridx, s in enumerate(self.subjects):
            d = s.matrix()
            self.raw_data.append(d[&#39;raw&#39;])
            self.rel_data.append(d[&#39;rel&#39;])
            self.abs_data.append(d[&#39;abs&#39;])
            temp_data = np.array(d[&#39;abs&#39;]) # to copy the array
            self.data.append(temp_data)
            self.qpcr.append(s.qpcr)
            self.n_timepoints_for_replicate.append(d[&#39;raw&#39;].shape[1])
            self.n_dts_for_replicate.append(d[&#39;raw&#39;].shape[1]-1)
            self.given_timepoints.append(np.asarray(s.times))
            self._given_timepoints_set.append(OrderedSet())
            self.given_timeindices.append(OrderedSet())
            self.times.append(np.asarray(s.times))
            for tidx,t in enumerate(self.times[ridx]):
                self._given_timepoints_set[ridx].add(t)
                self.given_timeindices[ridx].add(tidx)
                self.data_timeindex2given_timeindex[(ridx,tidx)] = tidx

            self.timepoint2index.append({})
            for tidx,t in enumerate(self.times[ridx]):
                self.timepoint2index[ridx][t] = tidx

            curr_read_depths = np.zeros(self.n_timepoints_for_replicate[ridx])
            for tidx,t in enumerate(s.times):
                curr_read_depths[tidx] = s.read_depth(t)
            self.read_depths.append(curr_read_depths)

            self.dt.append(np.zeros(self.n_timepoints_for_replicate[ridx] - 1))
            for k in range(len(self.dt[ridx])):
                self.dt[ridx][k] = self.times[ridx][k+1] - self.times[ridx][k]

        self.total_n_timepoints_per_taxa = 0
        self.total_n_dts_per_taxa = 0
        for nt in self.n_timepoints_for_replicate:
            self.total_n_timepoints_per_taxa += nt
            self.total_n_dts_per_taxa += (nt-1)

        # make dt_vec
        n = 0
        for ridx in range(self.n_replicates):
            n += len(self.dt[ridx])
        n *= self.n_taxa
        n_taxa = self.n_taxa
        self.dt_vec = np.zeros(n)
        i = 0
        for ridx in range(self.n_replicates):
            for t in self.dt[ridx]:
                self.dt_vec[i:i+n_taxa] = t
                i += n_taxa
        self.sqrt_dt_vec = np.sqrt(self.dt_vec)

        self.design_matrices = {}
        self.lhs = None

        # Make tidx arrays for perturbations if necessary
        self.tidxs_in_perturbation = None
        if self.subjects.perturbations is not None:
            self.tidxs_in_perturbation = []
            for ridx, subj in enumerate(self.subjects):
                self.tidxs_in_perturbation.append([])
                for perturbation in self.subjects.perturbations:
                    start = perturbation.starts[subj.name]
                    end = perturbation.ends[subj.name]

                    if start in self.timepoint2index[ridx]:
                        # There is a measurement at the start of the perturbation
                        start_idx = self.timepoint2index[ridx][start]
                    else:
                        # There is no measurement at the start of the perturbation.
                        # Get the next timepoint
                        start_idx = np.searchsorted(self.times[ridx], start)
                    
                    if end in self.timepoint2index[ridx]:
                        # There is a measurement at the end of the perturbation
                        end_idx = self.timepoint2index[ridx][end]
                    else:
                        # There is no measurement at the end of the perturbation
                        # Get the previous timepoint
                        end_idx = np.searchsorted(self.times[ridx], end) - 1

                    # Check if anything is weird
                    start_idx = int(start_idx)
                    end_idx = int(end_idx)
                    if start_idx &gt; end_idx:
                        # raise ValueError(&#39;end time index ({}) of a perturbation less&#39; \
                        #     &#39; than the start index ({})?&#39;.format(end_idx, start_idx))
                        self.tidxs_in_perturbation[ridx].append((None, None))
                    if start_idx == end_idx:
                        self.tidxs_in_perturbation[ridx].append((start_idx, start_idx+1))
                    else:
                        self.tidxs_in_perturbation[ridx].append((start_idx, end_idx))
        
        # Set structural zeros - everything is set to non-structural zero initially
        if self.zero_inflation_transition_policy is not None:
            self._structural_zeros = []
            for ridx in range(self.n_replicates):
                self._structural_zeros.append(np.zeros(
                    shape=(len(self.taxa), self.n_timepoints_for_replicate[ridx]), dtype=bool))
            self._setrows_to_include_zero_inflation()

    def iter_for_building(self) -&gt; Tuple[int, int, int]:
        for ridx in range(self.n_replicates):
            for tidx in range(self.n_dts_for_replicate[ridx]):
                for oidx in range(len(self.taxa)):
                    yield oidx, tidx, ridx

    def make_delta_t(self, sqrt: bool=False) -&gt; np.ndarray:
        &#39;&#39;&#39;Returns the whole delta_t vector for each time point.

        Parameters
        ----------
        sqrt : bool
            If True, return the square root of the vector. Default is False
        &#39;&#39;&#39;
        if sqrt:
            return self.sqrt_dt_vec
        else:
            return self.dt_vec

    def is_intermediate_timepoint(self, ridx: int, t: float) -&gt; bool:
        &#39;&#39;&#39;Checks if the given time `t` for subject index `ridx` is
        an intermediate time point or not

        Parameters
        ----------
        ridx : int
            Replicate index
        t : numeric
            Time point

        Returns
        -------
        bool
        &#39;&#39;&#39;
        return t not in self._given_timepoints_set[ridx]

    def is_intermediate_timeindex(self, ridx: int, tidx: int) -&gt; bool:
        &#39;&#39;&#39;Checks if the given time index `tidx` for subject index `ridx` is
        an intermediate time point or not

        Parameters
        ----------
        ridx : int
            Replicate index
        tidx : int
            Time index

        Returns
        -------
        bool
        &#39;&#39;&#39;
        return tidx not in self.given_timeindices[ridx]

    def set_timepoints(self, times: np.ndarray=None, timestep: float=None, ridx: int=None, 
        eps: float=None, reset_timepoints: bool=False):
        &#39;&#39;&#39;Set times if you want intermediate timepoints.
        
        These are the time points that you want to generate the latent state at.
        If there is a time in `times` that is not in the given data, then we set
        it as an intermediate time point. You can specify the times that you 
        want either as a vector with `times` or with a constant time-step
        with the interval `timestep`. Only one of them is necessary. It will crash
        if both are supplied.

        `eps` is a radius around each of the given timepoints already supplied by
        the data in `subjects` where no intermediate timepoints can be set.
        If a timepoint that is set is within `eps` days of a timepoint already there,
        then we skip adding that timepoint. If `eps` is None then we assume
        that there is no constraint. 

        If `reset_timepoints` is True, then we delete the intermediate timepoints
        that may have been added at a different time and use only these. If False
        then the set of timepoints added at this call is adde to the set of 
        timepoints that were added at a previous call. 

        Parameters
        ----------
        times : array
            These are the time points to set
            If there are any time points not included in here but are included
            with the given data then we automatically add them in. If there
            are any time points in times that are already in the given data,
            it is automatically set as a given time point
            You need to provide this argument if you are not providing `timestep`
        timestep : float, int
            This is the time steps to generate the times at until the last time
            at every replicate.
            A data point will only be added if there is not already a datapoint
            at that time. This is only necessary if you did not pass in `times`
        ridx : int, Optional
            If this is given, then we only set these times for the given
            replicate index. If nothing is specified then we set the time points
            for all of the replicates.
        eps : numeric, None
            If an intermediate timestep is within `eps` days of a given timepoint
            then we do not add it. If None then there is no restriction to how close
            the intermediate timepoint can be.
        reset_timepoints : bool
            If this is True then we delete the previous added intermediate timepoints.
            If False then we add the set of timepoints added at this call with the
            intermediate timepoints from a previous call.
        &#39;&#39;&#39;
        if (times is None and timestep is None) or (times is not None and timestep is not None):
            raise ValueError(&#39;Either `times` or `timestep` must be provided&#39;)
        if not pl.isbool(reset_timepoints):
            raise TypeError(&#39;`reset_timepoints` ({}) must be a bool&#39;.format(
                type(reset_timepoints)))
        if ridx is not None:
            if not pl.isint(ridx):
                raise ValueError(&#39;`ridx` ({}) must be an int&#39;.format(type(ridx)))
            ridxs = [ridx]
        else:
            ridxs = np.arange(self.n_replicates)
        
        if timestep is not None:
            if not pl.isnumeric(timestep):
                raise ValueError(&#39;`timestep` ({}) must be a numeric&#39;.format(type(timestep)))
            # get the earliest start and the latest end
            start = float(&#39;inf&#39;)
            end = -1
            for ts in self.times:
                if start &gt; ts[0]:
                    start = ts[0]
                if end &lt; ts[-1]:
                    end = ts[-1]
            times = np.arange(start,end,timestep)
        if not pl.isarray(times):
            raise ValueError(&#39;`times` ({}) must be an array&#39;.format(type(times)))
        
        if eps is not None:
            if not pl.isnumeric(eps):
                raise TypeError(&#39;`eps` ({}) must be a numeric&#39;.format(type(eps)))
            if eps &lt; 0:
                raise ValueError(&#39;`eps` ({}) must be &gt;= 0&#39;.format(eps))
            
        for ridx in ridxs:
            if reset_timepoints:
                new_times = np.array(self.given_timepoints[ridx])
            else:
                new_times = np.array(self.times[ridx])

            n_added = 0
            for t in times:
                if t not in new_times:
                    # Check if the datapoint is within `eps` of real data
                    # Get the surrounding timepoints
                    if eps is None:
                        n_added += 1
                        new_times = np.append(new_times, t)
                    else:
                        smallest_big = float(&#39;-inf&#39;)
                        largest_small = float(&#39;inf&#39;)
                        for tt in new_times:
                            if tt &lt; t and tt &gt; largest_small:
                                largest_small = tt
                            elif tt &gt; t and tt &lt; smallest_big:
                                smallest_big = tt
                        if np.min([t-largest_small, smallest_big-t]) &lt; eps:
                            n_added += 1
                            new_times = np.append(new_times, t)
                        
            sorted_tidxs = np.argsort(new_times)
            self.times[ridx] = new_times[sorted_tidxs]
            if reset_timepoints:
                self.data[ridx] = np.hstack((
                    self.abs_data[ridx], 
                    np.zeros(shape=(self.n_taxa, n_added))*np.nan))
            else:
                self.data[ridx] = np.hstack((
                    self.data[ridx],
                    np.zeros(shape=(self.n_taxa, n_added)) * np.nan))
            self.data[ridx] = self.data[ridx][:,sorted_tidxs]
            self.n_timepoints_for_replicate[ridx] = len(self.times[ridx])
            self.n_dts_for_replicate[ridx] = len(self.times[ridx])-1

            # redo `given_timeindices`
            self.given_timeindices[ridx] = OrderedSet()
            for tidx in range(len(self.times[ridx])):
                if self.times[ridx][tidx] in self._given_timepoints_set[ridx]:
                    self.given_timeindices[ridx].add(tidx)

            # redo `data_timeindex2given_timeindex` - first delete all ones that
            # have that as the replicate and then add the new oens
            new_d = {}
            for aaa,bbb in self.data_timeindex2given_timeindex:
                if aaa == ridx:
                    continue
                new_d[(aaa,bbb)] = self.data_timeindex2given_timeindex[(aaa,bbb)]
            self.data_timeindex2given_timeindex = new_d

            given_times = self.given_timepoints[ridx]
            for tidx in range(self.n_timepoints_for_replicate[ridx]):
                if tidx in self.given_timeindices[ridx]:
                    # Get index where the time occurs in the given times
                    t = self.times[ridx][tidx]
                    found = False
                    for i in range(len(given_times)):
                        if t == given_times[i]:
                            found = True
                            self.data_timeindex2given_timeindex[(ridx,tidx)] = i
                            break
                    if not found:
                        raise ValueError(&#39;Not found - something is wrong&#39;)

                else:
                    self.data_timeindex2given_timeindex[(ridx,tidx)] = np.nan

            # Redo the reverse indexing
            self.timepoint2index[ridx] = {}
            for tidx,t in enumerate(self.times[ridx]):
                self.timepoint2index[ridx][t] = tidx

            # redo `dt`
            self.dt[ridx] = np.zeros(self.n_timepoints_for_replicate[ridx]-1)
            for k in range(len(self.dt[ridx])):
                self.dt[ridx][k] = self.times[ridx][k+1] - self.times[ridx][k]

        # redo dt_vec
        n = 0
        for ridx in range(self.n_replicates):
            n += len(self.dt[ridx])
        n *= self.n_taxa
        n_taxa = self.n_taxa
        self.dt_vec = np.zeros(n)
        i = 0
        for ridx in range(self.n_replicates):
            for t in self.dt[ridx]:
                self.dt_vec[i:i+n_taxa] = t
                i += n_taxa
        self.sqrt_dt_vec = np.sqrt(self.dt_vec)

        self.total_n_timepoints_per_taxa = 0
        self.total_n_dts_per_taxa = 0
        for nt in self.n_timepoints_for_replicate:
            self.total_n_timepoints_per_taxa += nt
            self.total_n_dts_per_taxa += (nt - 1)


        # redo tidx arrays for perturbations if necessary
        if self.tidxs_in_perturbation is not None:
            self.tidxs_in_perturbation = []
            for ridx, subj in enumerate(self.subjects):
                self.tidxs_in_perturbation.append([])
                for perturbation in self.subjects.perturbations:
                    start = perturbation.starts[subj.name]
                    end = perturbation.ends[subj.name]

                    if start in self.timepoint2index[ridx]:
                        # There is a measurement at the start of the perturbation
                        start_idx = self.timepoint2index[ridx][start]
                    else:
                        # There is no measurement at the start of the perturbation.
                        # Get the next timepoint
                        start_idx = np.searchsorted(self.times[ridx], start)
                    
                    if end in self.timepoint2index[ridx]:
                        # There is a measurement at the end of the perturbation
                        end_idx = self.timepoint2index[ridx][end]
                    else:
                        # There is no measurement at the end of the perturbation
                        # Get the previous timepoint
                        end_idx = np.searchsorted(self.times[ridx], end) - 1

                    # Check if anything is weird
                    start_idx = int(start_idx)
                    end_idx = int(end_idx)
                    if start_idx &gt; end_idx:
                        # raise ValueError(&#39;end time index ({}) of a perturbation less&#39; \
                        #     &#39; than the start index ({})?&#39;.format(end_idx, start_idx))
                        self.tidxs_in_perturbation[ridx].append((None, None))
                    if start_idx == end_idx:
                        self.tidxs_in_perturbation[ridx].append((start_idx, start_idx + 1))
                    else:
                        self.tidxs_in_perturbation[ridx].append((start_idx, end_idx))

    def set_zero_inflation(self, turn_on: Iterator[Tuple[int, int, int]]=None, 
        turn_off: Iterator[Tuple[int, int, int]]=None):
        &#39;&#39;&#39;Set which timepoints taxa are set to be turned off. Any taxa, timepoints tuple
        not in `d` is assumed to be &#34;present&#34; (a nonn-structural zero). `d` is an array
        of 3-tuples, where:
            (ridx, tidx, aidx)
                ridx: replicate index (not the same as replicate name)
                tidx: timepoint index (not the same as timepoint)
                aidx: Taxa index (not the same as Taxa name)
        
        Parameters
        ----------
        turn_on : list(3-tuple)
            A list of ridx, tidx, aidx to set to being present
        turn_on : list(3-tuple)
            A list of ridx, tidx, aidx to set to a structural zero
        &#39;&#39;&#39;
        if self.zero_inflation_transition_policy is None:
            # raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
            #     &#39;is not set during initialization&#39;)
            logging.warning(&#39;`zero_inflation_transition_policy` is None so we are not doing anything&#39;)
            return
        if turn_on is not None:
            for i, (ridx,tidx,aidx) in enumerate(turn_on):
                if ridx &gt; self.n_replicates or ridx &lt; 0:
                    raise ValueError(&#39;ridx ({}) in index `{}` ({}) is out of range. Only {} replicates&#39;.format(
                        ridx, i, (ridx,tidx,aidx), self.n_replicates))
                if tidx &gt; self.n_timepoints_for_replicate[ridx] or tidx &lt; 0:
                    raise ValueError(&#39;tidx ({}) in index `{}` ({}) is out of range. Only {} timepoints in replicate {}&#39;.format(
                        tidx, i, (ridx,tidx,aidx), self.n_timepoints_for_replicate[ridx], ridx))
                if aidx &gt; len(self.taxa) or aidx &lt; 0:
                    raise ValueError(&#39;aidx ({}) in index `{}` ({}) is out of range. Only {} s&#39;.format(
                        aidx, i, (ridx,tidx,aidx), len(self.taxa)))

                self._structural_zeros[ridx][aidx,tidx] = False

        if turn_off is not None:
            for i, (ridx,tidx,aidx) in enumerate(turn_off):
                if ridx &gt; self.n_replicates or ridx &lt; 0:
                    raise ValueError(&#39;ridx ({}) in index `{}` ({}) is out of range. Only {} replicates&#39;.format(
                        ridx, i, (ridx,tidx,aidx), self.n_replicates))
                if tidx &gt; self.n_timepoints_for_replicate[ridx] or tidx &lt; 0:
                    raise ValueError(&#39;tidx ({}) in index `{}` ({}) is out of range. Only {} timepoints in replicate {}&#39;.format(
                        tidx, i, (ridx,tidx,aidx), self.n_timepoints_for_replicate[ridx], ridx))
                if aidx &gt; len(self.taxa) or aidx &lt; 0:
                    raise ValueError(&#39;aidx ({}) in index `{}` ({}) is out of range. Only {} s&#39;.format(
                        aidx, i, (ridx,tidx,aidx), len(self.taxa)))

                self._structural_zeros[ridx][aidx,tidx] = True
        self._setrows_to_include_zero_inflation()

    def is_timepoint_structural_zero(self, ridx: int, tidx: int, aidx: int) -&gt; bool:
        &#39;&#39;&#39;Returns True if the replicate index `ridx`, timepoint index `tidx`, and
        Taxa index `aidx` is a structural zero or not
        &#39;&#39;&#39;
        if self.zero_inflation_transition_policy is None:
            raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
                &#39;is not set during initialization&#39;)
        return self._structural_zeros[ridx][aidx, tidx]

    def _setrows_to_include_zero_inflation(self):
        &#39;&#39;&#39;Make a rows matrix for what to include based on `self._structural_zeros`
        &#39;&#39;&#39;
        if self.zero_inflation_transition_policy is None:
            raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
                &#39;is not set during initialization&#39;)

        iii = 0

        l = len(self.taxa) * self.total_n_dts_per_taxa
        self.rows_to_include_zero_inflation = np.zeros(l, dtype=bool)
        iii = 0
        for ridx in range(self.n_replicates):
            curr_structural_zero = self._structural_zeros[ridx]
            for dtidx in range(self.n_dts_for_replicate[ridx]):
                # we look at timepoint indices `dtidx` and `dtidx+1`

                tidxstart = dtidx
                tidxend = dtidx

                for aidx in range(len(self.taxa)):

                    structzero_start = curr_structural_zero[aidx, tidxstart]
                    structzero_end = curr_structural_zero[aidx, tidxend]
                    
                    if structzero_start and structzero_end:
                        # If both are not there, exclude
                        self.rows_to_include_zero_inflation[iii] = False
                    
                    elif (not structzero_end) and (not structzero_start):
                        # If both are there, include
                        self.rows_to_include_zero_inflation[iii] = True

                    else:
                        # Else we are in a transition and we must use a policy
                        if self.zero_inflation_transition_policy == &#39;ignore&#39;:
                            # don&#39;t include it
                            self.rows_to_include_zero_inflation[iii] = False
                        elif self.zero_inflation_transition_policy == &#39;half-way&#39;:
                            raise NotImplementedError(&#39;Not implemented&#39;)
                        elif self.zero_inflation_transition_policy == &#39;sample&#39;:
                            raise NotImplementedError(&#39;Not implemented&#39;)
                        else:
                            raise ValueError(&#39;`zero_inflation_transition_policy` ({}) not recognized&#39;.format(
                                self.zero_inflation_transition_policy))

                    iii += 1

        self.off_previously_arr_zero_inflation = np.zeros(l, dtype=int)
        n_off_prev = 0
        for i in range(1, l):
            if not self.rows_to_include_zero_inflation[i-1]:
                n_off_prev += 1
            self.off_previously_arr_zero_inflation[i] = n_off_prev

    def _get_non_pert_rows_of_regress_matrices(self) -&gt; np.ndarray:
        &#39;&#39;&#39;This will get the rows where there are no perturbations in the
        regressor matrices
        &#39;&#39;&#39;
        if self.G.perturbations is None:
            return None

        replicate_offset = 0
        ridxs = np.array([], dtype=int)
        n_taxa = self.n_taxa
        for ridx in range(self.n_replicates):
            # For each replicate, get the time indices where ther are 
            # perturbations and then index them out
            for pidx in range(len(self.G.perturbations)):
                start_tidx, end_tidx = self.G.data.tidxs_in_perturbation[ridx][pidx]
                if start_tidx is None:
                    continue

                ridxs = np.append(ridxs, replicate_offset + np.arange(
                    start_tidx*n_taxa, (end_tidx-1)*n_taxa, dtype=int))
            replicate_offset += n_taxa * self.n_dts_for_replicate[ridx]

        ret = np.ones(len(self.lhs), dtype=bool)
        ret[ridxs] = False

        if self.zero_inflation_transition_policy is not None:
            ret = ret[self.rows_to_include_zero_inflation]

        return ret

    def construct_lhs(self, keys: List[str]=[], kwargs_dict: Dict[str, Dict[str, Any]]={}, 
        index_out_perturbations: bool=False) -&gt; np.ndarray:
        &#39;&#39;&#39;Does the stacking and subtracting necessary to make the observation vector

        Parameters
        ----------
        keys : list(str)
            These are the keys of the matrices to go on the left-hand-side (lhs)
        kwargs_dict: dict
            This is a dict of dicts:
                str -&gt; (str -&gt; val)
            The first level dictionary is one of the names in the keys
            The second level dictionary are the additional arguements that are
            send to that keys `construct_lhs` function.
        index_out_perturbations : bool
            If this is True, it will index out the rows that are in the perturbation.
            This would be used for times that you want to initialize the data not
            with any perturbation periods

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        y = self.lhs.vector
        valid_indices = None
        if index_out_perturbations and self.G.perturbations is not None:
            valid_indices = self._get_non_pert_rows_of_regress_matrices()
            y = y[valid_indices]
        for x in keys:
            if x in kwargs_dict:
                kwargs = kwargs_dict[x]
            else:
                kwargs = {}
            try:
                b = self.design_matrices[x].set_to_lhs(**kwargs)
            except:
                logging.critical(&#39;Crash in `construct_lhs` making the matrix. Key: {}. {}&#39;.format(x,
                    keys))
                raise
            if valid_indices is not None:
                b = b[valid_indices]
            try:
                y = y - b
            except:
                logging.critical(&#39;Crash in `construct_lhs` subtracting the matrix.&#39; \
                    &#39; Key: {}, y.shape: {}, b.shape: {}&#39;.format(x, y.shape, b.shape))
                raise
        return y.reshape(-1,1)

    # @profile
    def construct_rhs(self, keys: List[str], kwargs_dict: Dict[str, Dict[str, Any]]={}, 
        index_out_perturbations: bool=False, toarray: bool=False) -&gt; Union[scipy.sparse.spmatrix, np.ndarray]:
        &#39;&#39;&#39;Does the stacking and subtracting necessary to make the covariate matrix.
        Default setting for this matrix is a `scipy.sparse` matrix unless you
        explicitly convert it with `toarray`.

        Parameters
        ----------
        keys : list(keys)
            These are the keys of the matrices to go on the right-hand-side (rhs)
        kwargs_dict : dict(dict)
            This is a dict of dicts: str -&gt; (str -&gt; val)
            The first level dictionary is one of the names in the keys
            The second level dictionary are the additional arguements that are send to that keys 
            `construct_lhs` function.
        index_out_perturbations : bool, Optional
            If this is True, it will index out the rows that are in the perturbation.
            This would be used for times that you want to initialize the data not
            with any perturbation periods
        toarray : bool
            If True, converts the input into a numpy C_CONTIGUOUS array

        Returns
        -------
        scipy.sparse.csc_matrix or np.ndarray
        &#39;&#39;&#39;
        v = []
        valid_indices = None
        if index_out_perturbations and self.G.perturbations is not None:
            valid_indices = self._get_non_pert_rows_of_regress_matrices() 
        for x in keys:
            if x in kwargs_dict:
                kwargs = kwargs_dict[x]
            else:
                kwargs = {}
            if x not in self.design_matrices:
                raise KeyError(&#39;Key `{}` not found. Valid keys: {}&#39;.format(
                    x, list(self.design_matrices.keys())))
            X = self.design_matrices[x].set_to_rhs(**kwargs)
            if valid_indices is not None:
                X = X[valid_indices, :]
            v.append(X)
        if len(keys) == 0:
            X =  v[0]
        else:
            try:
                X = scipy.sparse.hstack(v)
            except:
                # try:
                #     X = torch.cat(v, 1)
                #     return X
                # except:
                t = [type(a) for a in v]
                s = [a.shape for a in v]
                logging.critical(&#39;shapes: {}, types: {}&#39;.format(s,t))
                logging.critical(&#39;keys: {}&#39;.format([self.G[a].name for a in keys]))
                raise
        if toarray:
            X_ = np.zeros(shape=X.shape)
            X.toarray(out=X_)
            return X_
        return X

    def update_values(self):
        &#39;&#39;&#39;Update the values of the data (because the latent state changed)
        &#39;&#39;&#39;
        self.lhs.update_value()
        for key in self.toupdate:
            self.design_matrices[key].update_value()


class ObservationVector(Node):
    &#39;&#39;&#39;This is the left hand side (lhs) vector
    &#39;&#39;&#39;
    def __init__(self, name: str, G: Graph):
        self.G = G
        self.name = name
        self.G.data.lhs = self
        self.vector = None

    def build(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def update_value(self):
        &#39;&#39;&#39;This updates the data for each design matrix
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;You must implement this function&#39;)


class DesignMatrix:
    &#39;&#39;&#39;This is a covariate class
    &#39;&#39;&#39;
    def __init__(self, varname: str, G: Graph, update: bool=False, add_to_dict: bool=True):
        &#39;&#39;&#39;Parameters

        varname (str)
            - This is the name of the variable we are building it for
        update (bool)
            - If True, this matrix gets updated when Data.update_values() is
              called.
        add_to_dict (bool)
            - If True, it adds to the design_matrices dictionary.
            - Else it does not
        &#39;&#39;&#39;

        name = varname + &#39;_design_matrix&#39;
        self.name = name
        self.G = G
        self.varname = varname
        if add_to_dict:
            self.G.data.design_matrices[varname] = self
        self.matrix = None
        if update:
            self.G.data.toupdate.add(varname)

    def build(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def set_to_lhs(self):
        &#39;&#39;&#39;Multiply the current value of the var with the current matrix
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def update_value(self):
        &#39;&#39;&#39;This updates the data for each design matrix
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def toarray(self, dest: np.ndarray=None, T: bool=False) -&gt; np.ndarray:
        &#39;&#39;&#39;Converts `self.matrix` into a C_CONTIGUOUS numpy matrix if 
        the matrix is sparse. If it is not sparse then it just returns
        the matrix.

        Parameters
        ----------
        dest : np.ndarray
            If this is specified, send the array into this array. Assumes
            the shapes are compatible. Else create a new array
        T : bool
            If True, set the transpose

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        return pl.toarray(self.matrix, dest=dest, T=T)


################################################################################
################################################################################
# Design matrices
################################################################################
################################################################################
class LHSVector(ObservationVector):
    &#39;&#39;&#39;This builds the Left-Hand-Side (LHS) vector
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        ObservationVector.__init__(self, **kwargs)
        logging.info(&#39;Initializing LHS vector&#39;)

    def build(self, subjects: Union[List[int], int, str]=&#39;all&#39;):
        &#39;&#39;&#39;Build the observation vector

        (log(x_{k+1}) - log(x_{k}))/dt

        Parameters
        ----------
        subjects : str, array(int), int
            These are the subjects to build the vector for. If &#39;all&#39;, we build it
            for all the subjects. If you want to pass in an array, we do it with 
            the subject index
        &#39;&#39;&#39;
        if pl.isint(subjects):
            subjects = [subjects]
        if subjects == &#39;all&#39;:
            subjects = np.arange(self.G.data.n_replicates)
            n_dts = self.G.data.total_n_dts_per_taxa
        else:
            n_dts = 0
            for sidx in subjects:
                n_dts += self.G.dta.n_dts_for_replicate[sidx]
        self.vector = np.zeros(self.G.data.n_taxa * n_dts, dtype=float)
        i = 0
        for ridx in range(self.G.data.n_replicates):
            if ridx not in subjects:
                # skip subject
                continue
            l = self.G.data.n_dts_for_replicate[ridx] * self.G.data.n_taxa
            LHSVector._fast_build_log(
                ret=self.vector[i:i+l],
                data=self.G.data.data[ridx],
                dt=self.G.data.dt[ridx],
                n_ts=self.G.data.n_dts_for_replicate[ridx],
                n_taxa=self.G.data.n_taxa)
            i += l

        if self.G.data.zero_inflation_transition_policy is not None:
            self.vector = self.vector[self.G.data.rows_to_include_zero_inflation]
        self.vector = self.vector.reshape(-1,1)

    def __len__(self) -&gt; int:
        return len(self.vector)

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def _fast_build_log(ret: np.ndarray, data: np.ndarray, dt: np.ndarray, n_ts: int, 
        n_taxa: int):
        &#39;&#39;&#39;About 99.4% faster than regular python looping
        &#39;&#39;&#39;
        i = 0
        for tidx in range(n_ts):
            for oidx in range(n_taxa):
                ret[i] = (np.log(data[oidx, tidx+1]) - np.log(data[oidx,tidx]))/dt[tidx]
                i += 1

    def update_value(self):
        self.build()
            

class SelfInteractionDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Base matrix class for growth and self interactions
    Since the dynamics subtract the self-interaction parameter, we set the
    parameter to positive, which means our data is negative.

    We build this matrix as a scipy sparse matrix, then convert it to a 
    numpy array if necessary. Since the shape of the sparse matrix does
    not change during inference, we can premake the rows and columns during initialization,
    which is done below.
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self, varname=STRNAMES.SELF_INTERACTION_VALUE,
            update=True, **kwargs)
        self.n_cols_master = self.G.data.n_taxa # 
        total_n_dts = self.G.data.total_n_dts_per_taxa
        self.n_rows_master = self.n_cols_master * total_n_dts
        self.master_rows = np.arange(self.n_rows_master, dtype=int)
        self.master_cols = np.kron(
                np.ones(total_n_dts, dtype=int),
                np.arange(self.G.data.n_taxa,dtype=int))
        logging.info(&#39;Initializing self-interactions design matrix&#39;)

    def build(self):
        &#39;&#39;&#39;Builds the matrix. Flatten Fortran style
        &#39;&#39;&#39;
        self.rows = self.master_rows
        self.cols = self.master_cols

        self.data = np.zeros(self.n_rows_master, dtype=float)
        data = self.G.data.data
        i = 0
        for ridx in range(self.G.data.n_replicates):
            l = (self.G.data.n_dts_for_replicate[ridx]) * self.G.data.n_taxa
            self.data[i:i+l] = -data[ridx][:,:-1].ravel(&#39;F&#39;)
            i += l
            
        shape = (self.n_rows_master, self.n_cols_master)
        self.matrix = scipy.sparse.coo_matrix(
            (self.data,(self.rows,self.cols)), shape=shape).tocsc()
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix = self.matrix[self.G.data.rows_to_include_zero_inflation, :]


    def set_to_lhs(self) -&gt; np.ndarray:
        &#39;&#39;&#39;Multiply self.matrix by the current value of
        growth/self interaction
        &#39;&#39;&#39;
        b = self.G[self.varname].value.reshape(-1,1)
        return self.matrix.dot(b)

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        &#39;&#39;&#39;Add in perturbations
        &#39;&#39;&#39;
        return self.matrix

    def update_value(self):
        self.build()


class GrowthDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Builds the design matrix for the growth

    We need two different matrices for growth, depending on if we are conditioning on the
    perturbations or not. If we are setting the growth to the RHS, that means
    that we are trying to learn the growth values and we have to keep the
    perturbation parameters fixed, so:
        a_1 * (1 + \\gamma)
    we need to put the perturbation parameters on the rhs matrix factored into the data matrix

    If we are putting the growth on the LHS, that means that we are either
    trying to learn the perturbations or we are marginalizing over the parameters
    dependent on the cluster assignments:
        a_1 + \\gamma * a_1
        ---
    The underlined part goes to the LHS.

    If there are no perturbations, the rhs and the lhs are equal and are set to
    the parameterization of the LHS

    We build this matrix as a scipy sparse matrix, then convert it to a 
    numpy array if necessary. Since the shape of the sparse matrix does
    not change during inference, we can premake the rows and columns during initialization,
    which is done below.
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.GROWTH_VALUE, update=True, **kwargs)
        self.n_cols_master = self.G.data.n_taxa # int
        total_n_dts = self.G.data.total_n_dts_per_taxa # int
        self.n_rows_master = self.n_cols_master * total_n_dts # int
        self.master_rows = np.arange(self.n_rows_master, dtype=int) 
        self.master_cols = np.kron(
                np.ones(total_n_dts, dtype=int),
                np.arange(self.G.data.n_taxa,dtype=int))
        logging.info(&#39;Initializing growth design matrix&#39;)

    def build(self):
        &#39;&#39;&#39;Build RHS matrices with perturbations multiplied in and not multiplied in.
        &#39;&#39;&#39;
        self.build_without_perturbations()
        self.build_with_perturbations()

    def build_without_perturbations(self):
        &#39;&#39;&#39;Builds the matrix without perturbations factored in.
        &#39;&#39;&#39;
        self.cols = self.master_cols
        self.rows = self.master_rows
        self.data = np.ones(self.n_rows_master, dtype=float)

        shape = (self.n_rows_master, self.n_cols_master)

        self.matrix_without_perturbations = scipy.sparse.coo_matrix(
            (self.data,(self.rows,self.cols)), shape=shape).tocsc()
        
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix_without_perturbations = self.matrix_without_perturbations[self.G.data.rows_to_include_zero_inflation, :]

    def build_with_perturbations(self):
        &#39;&#39;&#39;Incorporate perturbation factors while building the data structure.

        a_1 * (1 + \\gamma) * x_k

        How perturbations are switched on/off:
        ------------------------------------------------------------------------
        &#39;The time ahead prediction must be included in the perturbation&#39; - Travis

        Example: Pertubtion period (2,5) - this is **3** doses

        ```
                           |--&gt;|--&gt;|--&gt;|
        perturbation on    #############
        Days           1   2   3   4   5   6
        ```

        `d1` indicates the perturbation parameter that gets added for the day that it
        should be included in.

        * x2 = x1 + ...
        * x3 = x2 + ... + d1
        * x4 = x3 + ... + d1
        * x5 = x4 + ... + d1
        * x6 = x5 + ...

        The perturbation periods that are given are in the format (start, end).
        For the above example our perturbation period would be (2, 5). Thus, we should do
        inclusion/exclusion brackets such that:
        &#39;&#39;&#39;
        self.cols = self.master_cols
        self.rows = self.master_rows

        if self.G.perturbations is None:
            self.matrix_with_perturbations = None
            return

        self.data_w_perts = np.zeros(self.n_rows_master, dtype=float)
        d = []
        for ridx in range(self.G.data.n_replicates):
            d.append(np.ones(shape=self.G.data.data[ridx].shape))

        for pidx, pert in enumerate(self.G.perturbations):
            val = (pert.item_array(only_pos_ind=True) + 1).reshape(-1,1)
            oidxs = pert.indicator.item_arg_array()

            for ridx in range(self.G.data.n_replicates):
                start,end = self.G.data.tidxs_in_perturbation[ridx][pidx]
                if len(oidxs) &gt; 0:
                    d[ridx][oidxs, start:end] *= val
        i = 0
        for ridx in range(self.G.data.n_replicates):
            l = (self.G.data.n_dts_for_replicate[ridx]) * self.G.data.n_taxa
            self.data_w_perts[i:i+l] = d[ridx][:,:-1].ravel(&#39;F&#39;)
            i += l

        shape = (self.n_rows_master, self.n_cols_master)
        self.matrix_with_perturbations = scipy.sparse.coo_matrix(
            (self.data_w_perts,(self.rows,self.cols)), shape=shape).tocsc()
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix_with_perturbations = \
                self.matrix_with_perturbations[self.G.data.rows_to_include_zero_inflation, :]
            self.matrix_with_perturbations = self.matrix_with_perturbations.tocsc()

    def set_to_lhs(self, with_perturbations: bool) -&gt; np.ndarray:
        &#39;&#39;&#39;Multiply the design matrix by the current value of
        growth
        &#39;&#39;&#39;
        if not pl.isbool(with_perturbations):
            raise ValueError(&#39;`with_perturbations` ({}) must be a bool&#39;.format(
                type(with_perturbations)))
        if with_perturbations:
            matrix = self.matrix_with_perturbations
        else:
            matrix = self.matrix_without_perturbations
        b = self.G[self.varname].value.reshape(-1,1)
        return matrix.dot(b)

    def set_to_rhs(self, with_perturbations: bool) -&gt; scipy.sparse.spmatrix:
        &#39;&#39;&#39;If `with_perturbations` is True, we return the matrix with the
        perturbation factors incorporated. If False we return the matrix
        without perturbations
        &#39;&#39;&#39;
        if not pl.isbool(with_perturbations):
            raise ValueError(&#39;`with_perturbations` ({}) must be a bool&#39;.format(
                type(with_perturbations)))
        if with_perturbations:
            matrix = self.matrix_with_perturbations
        else:
            matrix = self.matrix_without_perturbations
        return matrix

    def update_value(self):
        self.build()


class PerturbationBaseDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This is the base data for the perturbations.

    This creates the baseline perturbation effects for each __Taxa__, for every indicator.
    This class used in conjungtion with `PerturbationMixingDesignMatrix` and should
    be accessed through `PerturbationDesignMatrix`.

    Note that this is not what is used during inference - we multiply this matrix by the
    mixing matrix

    Parameterization
    ----------------
    We parameterize the MDSINE2 model with multiplicative perturbations
    .. math::
        \\frac {log(x_{i,k+1}) - log(x_{i,k})} {t_{k+1} - t_{k}} =
            a_{1,i} (1 + \sum_{p=1}^P u_p(k) \gamma_{i,p} ) + \sum_{j} b_{ij} x{j,k} 
    where:
        :math:`x_{i,k}` : abundance for Taxa :math:`i` at time :math:`t_k`
        :math:`t_k` : time at k
        :math:`a_{1,i}` : growth for Taxa :math:`i`
        :math:`b_{ij}` : interactions from :math:`i` to :math:`j`
        :math:`b_{ii}` : self interactions for :math:`i`
        :math:`u_p(k)` : step function for perturbation :math:`p` at time :math:`t_k`
        :math:`\gamma_{i,p}` : perturbation value for perturbation :math:`p` for taxon :math:`i`
        Here the perturbation has an &#34;effect&#34; on the growth rates

    See Also
    --------
    mdsine2.data_matrices.PerturbationMixingDesignMatrix
    mdsine2.data_matrices.PerturbationDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        name = STRNAMES.PERT_VALUE+&#39;_base_data&#39;
        DesignMatrix.__init__(self, varname=name, **kwargs)
        if self.G.data.zero_inflation_transition_policy is not None:
            raise NotImplementedError(&#39;Not Implemented&#39;)

        self.perturbations = self.G.perturbations # pylab.base.Perturbations object
        self.n_perturbations = len(self.perturbations) # int
        self.n_replicates = self.G.data.n_replicates # int
        self.n_taxa = len(self.G.data.taxa) # int
        self.growths = self.G[STRNAMES.GROWTH_VALUE] # This is the pointer to the growth variable learned in inference

        self.starts = [] # list[list[int]] top index indexes the subject, bottom index indexes the perturbation
        self.ends = [] # list[list[int]] top index indexes the subject, bottom index indexes the perturbation
        self.tidxs_in_pert_per_replicate = []

        self.tidxs_in_perturbation = np.zeros(shape=(self.n_replicates,
            self.n_perturbations, 2), dtype=int) - 1

        # Get the total number of timepoints in perturbations
        total_tidxs = 0
        for ridx, subj in enumerate(self.G.data.subjects):
            self.starts.append([]) # indices where the perturbation starts
            self.ends.append([]) # indices where the perturbation ends
            i = 0
            for pidx in range(self.n_perturbations):
                start, end = self.G.data.tidxs_in_perturbation[ridx][pidx]
                if start is None:
                    continue
                self.tidxs_in_perturbation[ridx,pidx,0] = start
                self.tidxs_in_perturbation[ridx,pidx,1] = end
                self.starts[-1].append(start)
                self.ends[-1].append(end)
                i += end-start
                total_tidxs += i

            self.tidxs_in_pert_per_replicate.append(i)
            self.starts[-1] = np.asarray(self.starts[-1], dtype=int)
            self.ends[-1] = np.asarray(self.ends[-1], dtype=int)

        # Set rows and cols
        self.total_len = int(total_tidxs * self.n_taxa)
        self.tidxs_in_pert_per_replicate = np.asarray(self.tidxs_in_pert_per_replicate, dtype=int)
        self.rows = np.zeros(self.total_len, dtype=int)
        self.cols = np.zeros(self.total_len, dtype=int)
        self.data = np.zeros(self.total_len)

        # Make the rows and columns for the data matrix
        PerturbationBaseDesignMatrix.init(
            rows=self.rows, 
            cols=self.cols, 
            n_perturbations=self.n_perturbations, 
            n_taxa=self.n_taxa, 
            n_replicates=self.n_replicates, 
            tidxs_in_perturbation=self.tidxs_in_perturbation, 
            n_dts_for_replicate=self.G.data.n_dts_for_replicate)

        # Initialize the rows and cols for the data
        self.n_rows = self.G.data.total_n_dts_per_taxa * self.G.data.n_taxa
        self.n_cols = self.n_taxa * self.n_perturbations
        self.shape = (self.n_rows, self.n_cols)

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def init(rows: np.ndarray, cols: np.ndarray, n_perturbations: int, n_taxa: int, 
        n_replicates: int, tidxs_in_perturbation: np.ndarray, n_dts_for_replicate: np.ndarray):

        i = 0
        base_row_idx = 0
        for ridx in range(n_replicates):
            for pidx in range(n_perturbations):
                start = tidxs_in_perturbation[ridx,pidx,0]
                end = tidxs_in_perturbation[ridx,pidx,1]
                if start == -1:
                    continue
                base_col_idx = pidx * n_taxa
                for oidx in range(n_taxa):
                    col = oidx + base_col_idx
                    for tidx in range(start, end):
                        rows[i] = oidx + tidx * n_taxa + base_row_idx
                        cols[i] = col
                        i += 1

            base_row_idx = base_row_idx + n_taxa * n_dts_for_replicate[ridx]

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def fast_build(ret: np.ndarray, n_perturbations: int, n_taxa: int, n_replicates: int, 
        tidxs_in_perturbation: np.ndarray, growths: np.ndarray, data: np.ndarray):

        i = 0
        for pidx in range(n_perturbations):
            start, end = tidxs_in_perturbation[pidx]
            if start == -1:
                continue
            for oidx in range(n_taxa):
                growth = growths[oidx]
                ret[i:(i+end-start)] = growth
                i += end-start

    def build(self):
        growths = self.growths.value # these are the current values of the growth parameters for each taxa
        i = 0
        for ridx in range(self.n_replicates):
            l = self.tidxs_in_pert_per_replicate[ridx] * self.n_taxa
            PerturbationBaseDesignMatrix.fast_build(
                ret=self.data[i:i+l], 
                n_perturbations=self.n_perturbations, 
                n_taxa=self.n_taxa, 
                n_replicates=self.n_replicates, 
                tidxs_in_perturbation=self.tidxs_in_perturbation[ridx], 
                growths=growths, 
                data=self.G.data.data[ridx])
            i += l

        self.matrix = scipy.sparse.coo_matrix(
            (self.data,(self.rows,self.cols)),shape=self.shape).tocsc()

    def update_value(self):
        self.build()

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        return self.matrix


class PerturbationMixingDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This class creates the permutation matrix required for mixing the base matrix into
    cluster effects

    See Also
    --------
    mdsine2.data_matrices.PerturbationBaseDesignMatrix
    mdsine2.data_matrices.PerturbationDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, parent: &#34;PerturbationDesignMatrix&#34;, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.PERT_VALUE+&#39;mixing_matrix&#39;,
            **kwargs)

        self.parent = parent # This is the PerturbationDesignMatrix object
        self.perturbations = self.G.perturbations # pylab.base.Perturbations
        self.n_perturbations = len(self.perturbations) # int
        self.n_taxa = len(self.G.data.taxa) # int
        self.n_rows = self.n_perturbations * self.n_taxa # int

        # Maps a taxa and a perturbation to the column it corresponds to in `base`
        self.keypair2col = np.zeros(shape=(self.n_taxa, self.n_perturbations), dtype=int)
        i = 0
        for pidx in range(self.n_perturbations):
            for oidx in range(self.n_taxa):
                self.keypair2col[oidx, pidx] = i
                i += 1
        self.build(build=False)

    # @profile
    def build(self, build: bool=True, build_for_neg_ind: bool=False, only_cids: List[int]=None):
        &#39;&#39;&#39;Build the matrix

        Parameters
        ----------
        build : bool
            If True, the parent will re-build as well
        build_for_neg_ind : bool
            If True, it will build for negative indicators as well
        only_cids : list, None
            If specified, it will only build for the cids specified.
        &#39;&#39;&#39;
        if only_cids is not None:
            oc = OrderedSet(list(only_cids))
        else:
            oc = None
        keypair2col = self.keypair2col
        rows = []
        cols = []
        col = 0
        for pidx, perturbation in enumerate(self.G.perturbations):
            ind = perturbation.indicator.value
            order = perturbation.clustering.order
            for cid in order:
                if oc is not None:
                    if cid not in oc:
                        continue
                if ind[cid] or build_for_neg_ind:
                    for oidx in perturbation.clustering[cid].members:
                        rows.append(keypair2col[oidx, pidx])
                        cols.append(col)
                    col += 1
        self._make_matrix(rows=rows, cols=cols, n_cols=col, build=build)

    # @profile
    def _make_matrix(self, rows: np.ndarray, cols: np.ndarray, n_cols: int, build: bool):
        &#39;&#39;&#39;Builds the mixing matrix from the specified rows and columns
        (data is always going to be 1 because it is a mixing matrix)

        Rebuild after we have changed the mixing matrix if `build` is True
        &#39;&#39;&#39;
        data = np.ones(len(rows), dtype=np.float64)
        self.matrix = scipy.sparse.coo_matrix((data,(rows,cols)),
            shape=(self.n_rows, n_cols)).tocsc()
        self.shape = self.matrix.shape
        self.n_rows = self.shape[0]
        self.n_cols = self.shape[1]
        if build:
            self.parent.build()
  

class PerturbationDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Builds the design matrix for the perturbations.

    This matrix is composed of two, individual design matrices, `Base` and `M`.
    To make the matrix that we use during inference, we matrix multiply `Base`@`M`,
    which is what this class is for. It wraps these two base classes so that it
    is more streamlined in the inference code.

    `Base` : mdsine2.design_matrices.PerturbationBaseDesignMatrix
        This is an object that builds the perturbation matrix as if there was no
        clustering or indicators. It builds the data for all the Taxas and
        as if every perturbation indicator was on. This is actually faster than
        just building it for individual indicators for a few different reasons:
            1) We only need to update `Base` when we do filtering or update the 
               values of the growth matrix because these are the only two things
               that `Base` is dependent on.
            2) Because we don&#39;t have to check indicators or have different shapes
               when building the matrix, it is much easier to build this matrix
               with Numba, which is nearly as fast as C.
    `Mixing` : mdsine2.design_matrices.PerturbationMixingDesignMatrix
        This is the object that selects for indicators and groups taxa together
        into clusters. When we change the indicators of the perturbations or 
        the cluster assignments of the taxa, we only need to change this matrix,
        which is a lot faster than changing everything.

    See Also
    --------
    mdsine2.data_matrices.PerturbationBaseDesignMatrix
    mdsine2.data_matrices.PerturbationBaseDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self, varname=STRNAMES.PERT_VALUE, **kwargs)

        self.n_rows = self.G.data.total_n_dts_per_taxa * self.G.data.n_taxa
        self.n_cols = None

        self.base = PerturbationBaseDesignMatrix(add_to_dict=False, **kwargs)
        self.M = PerturbationMixingDesignMatrix(add_to_dict=False, parent=self, **kwargs)

    def set_to_lhs(self) -&gt; np.ndarray:
        # Make the perturbation vector
        b = self.G[STRNAMES.PERT_VALUE].toarray().reshape(-1,1)

        return self.matrix.dot(b)

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        return self.matrix

    def update_values(self):
        # self.build()
        self.base.update_value()
        self.build()

    def build(self):
        self.matrix = self.base.matrix @ self.M.matrix
        self.n_cols = self.matrix.shape[1]
        self.shape = self.matrix.shape


class InteractionsBaseDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This is the base data for the design matrix of the interactions.

    This builds the interaction matrix for each __Taxa-Taxa__ interaction as if there
    were no indicators. Note that this is not what is used during inference - we multiply 
    this matrix by the mixing matrix.

    See Also
    --------
    mdsine2.design_matrices.InteractionsMixingDesignMatrix
    mdsine2.design_matrices.InteractionsDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        name = STRNAMES.CLUSTER_INTERACTION_VALUE+&#39;_base_data&#39;
        DesignMatrix.__init__(self,varname=name, **kwargs)

        # Initialize and set up rows and cols for base matrix
        total_n_dts = self.G.data.total_n_dts_per_taxa # int

        n_taxa = self.G.data.n_taxa # int
        self.n_rows = int(n_taxa * total_n_dts) # int
        self.n_cols = int(n_taxa * (n_taxa - 1)) # int
        self.shape = (self.n_rows, self.n_cols)

        self.master_rows = np.kron(
                np.arange(self.n_rows, dtype=int),
                np.ones(n_taxa-1, dtype=int))
        self.master_cols = np.kron(
            np.ones(total_n_dts, dtype=int),
            np.arange(self.n_cols, dtype=int))

        self.master_data = np.zeros(len(self.master_cols))
        logging.info(&#39;Initializing interactions base design matrix&#39;)

    # @profile
    def build(self):
        &#39;&#39;&#39;Build the base matrix
        &#39;&#39;&#39;
        n_taxa = self.G.data.n_taxa
        data = self.G.data.data

        self.rows = self.master_rows
        self.cols = self.master_cols
        self.data = self.master_data

        i = 0
        for ridx in range(self.G.data.n_replicates):
            i = InteractionsBaseDesignMatrix._fast_build(
                ret=self.master_data, data=data[ridx], n_taxa=n_taxa,
                n_dts=self.G.data.n_dts_for_replicate[ridx], i=i)
            
        if self.G.data.zero_inflation_transition_policy is not None:
            # All of the rows that need to be taken out will be taken out. All of the 
            # remaining nans in the matrix are effects of a structural zero on a non-structural
            # zero - making a nan. We can set this to zero because if this is the case we can say 
            # this means &#34;no effect&#34;
            self.master_data[np.isnan(self.master_data)] = 0
        else:
            if np.any(np.isnan(self.master_data)):
                raise ValueError(&#39;nans in matrix, this should not happen. check the values&#39;)
        self.matrix = scipy.sparse.coo_matrix(
            (self.master_data,(self.master_rows,self.master_cols)),shape=self.shape).tocsc()
        
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix = self.matrix[self.G.data.rows_to_include_zero_inflation, :]

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def _fast_build(ret: np.ndarray, data: np.ndarray, n_dts: int, n_taxa: int, i: int):
        &#39;&#39;&#39;About 99.5% faster than regular python looping
        &#39;&#39;&#39;
        for tidx in range(n_dts):
            for toidx in range(n_taxa):
                for soidx in range(n_taxa):
                    if toidx == soidx:
                        continue
                    ret[i] = data[soidx, tidx]
                    i = i + 1
        return i

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def _fast_build_zi_ignore(ret: np.ndarray, data: np.ndarray, n_dts: int, n_taxa: int, i: int, 
        zero_inflation: np.ndarray, zi_mask: np.ndarray):
        &#39;&#39;&#39;About 99.5% faster than regular python looping

        Only set to include if target taxa current timepoint and future timepoint are there and
        if the source taxa timepoint is there
        &#39;&#39;&#39;
        for tidx in range(n_dts):
            for toidx in range(n_taxa):
                for soidx in range(n_taxa):
                    if toidx == soidx:
                        continue

                    if not (zero_inflation[soidx, tidx] and zero_inflation[toidx, tidx] and \
                        zero_inflation[toidx, tidx+1]):
                        zi_mask[i] = False
                    else:
                        ret[i] = data[soidx, tidx]
                        zi_mask[i] = True
                    
                    i = i + 1
        return i

    def update_value(self):
        self.build()

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        return self.matrix


class InteractionsMixingDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This is the mixing matrix that is used along with
    `InteractionsBaseDesignMatrix` for the  `InteractionsDesignMatrix`
    class



    The `keypair2col` dictionary maps a tuple of (target_taxa_idx,source_taxa_idx)
    to the column they belong to in the full, non-clustered matrix.

    This class has a few different options on how to build M, dependiing on where
    it is being called in inference, some are faster than others, or build very
    specific parts, or build the matrix given some specific data. 

    See Also
    --------
    mdsine2.design_matrices.InteractionsBaseDesignMatrix
    mdsine2.design_matrices.InteractionsDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, parent: &#34;InteractionsDesignMatrix&#34;, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.CLUSTER_INTERACTION_VALUE+&#39;mixing_matrix&#39;,
            **kwargs)

        self.parent = parent # InteractionsDesignMatrix
        n_taxa = self.G.data.n_taxa

        # mdsine2.pylab.cluster.Clustering object
        # This tells the design matrix which taxon is in which cluster
        self.clustering = self.G[STRNAMES.CLUSTERING_OBJ]

        # mdsine2.pylab.contrib.Interactions object
        # This tells the design matrix what interactions have positive indicators
        self.interactions = self.G[STRNAMES.INTERACTIONS_OBJ]

        self.n_rows = int(n_taxa * (n_taxa - 1)) # int

        # Build the keypair2col dictionary
        self.keypair2col = np.zeros(
            shape=(len(self.G.data.taxa), len(self.G.data.taxa)), dtype=int)
        i = 0
        for tidx in range(len(self.G.data.taxa)):
            for sidx in range(len(self.G.data.taxa)):
                if tidx == sidx:
                    continue
                self.keypair2col[tidx, sidx] = i
                i += 1

        self.build(build=False)
        logging.info(&#39;Initialized interactions mixing design matrix&#39;)

        # Compile and set `_get_rows` in cache - these values are dummy values that are
        # not used in inference
        a = np.zeros(1, int)
        tmems = np.asarray([1], dtype=int)
        smems = np.asarray([2], dtype=int)
        InteractionsMixingDesignMatrix.get_indices(a, self.keypair2col, tmems, smems)

    # @profile
    def build(self, build: bool=True, build_for_neg_ind: bool=False):
        &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
        from scratch slowly - it does not take advantage of the clus2clus dictionary.

        This will only build for positive indicators unless `build_for_neg_ind` is
        True, where it will also build for negative indicators as well.

        We save the castings of the sets of Taxa ids into numpy arrays so we 
        dont have to do it each iteration. This saves ~45% computation time

        Parameters
        ----------
        build : bool
            This is a flag whether we should build the parent matrix in the
            function `make_matrix`
        build_for_neg_ind : bool
            If True, builds for all the interactions and not just the positively
            indicated
        &#39;&#39;&#39;
        rows = []
        cols = []

        # interaction terms
        # Cluster 2 Cluster Interaction InDeX (c2ciidx)
        c2ciidx = 0
        d = {}

        if build_for_neg_ind:
            for interaction in self.interactions:
                d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
                c2ciidx += 1
        else:
            for tcid, scid in self.interactions.iter_valid_pairs():
                d, rows, cols = self.inner_faster(rows, cols, d, tcid, scid, c2ciidx)
                c2ciidx += 1

        rows = np.asarray(list(itertools.chain.from_iterable(rows))) #, dtype=int)
        cols = np.asarray(list(itertools.chain.from_iterable(cols))) #, dtype=int)
        self._make_matrix(rows=rows, cols=cols, n_cols=c2ciidx, build=build)

        self.rows = rows
        self.cols = cols

    # @profile
    def build_clustering(self, build: bool=True):
        &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
        from scratch slowly - it does not take advantage of the clus2clus dictionary.

        This will only build for positive indicators unless `build_for_neg_ind` is
        True, where it will also build for negative indicators as well.

        We save the castings of the sets of Taxa ids into numpy arrays so we 
        dont have to do it each iteration. This saves ~45% computation time

        Parameters
        ----------
        build : bool
            This is a flag whether we should build the parent matrix in the
            function `make_matrix`
        &#39;&#39;&#39;
        self.cols = np.zeros(400, dtype=int)
        self.rows = np.zeros(400, dtype=int)
        self.baseidx = 0


        # interaction terms
        # Cluster 2 Cluster Interaction InDeX (c2ciidx)
        c2ciidx = 0
        self.d = {}

        # print(&#39;this bitch&#39;)

        for tcid, scid in self.interactions.iter_valid_pairs():
            self.inner_faster_faster(tcid, scid, c2ciidx)
            c2ciidx += 1

        self.rows = self.rows[:self.baseidx]
        self.cols = self.cols[:self.baseidx]
        self._make_matrix(rows=self.rows, cols=self.cols, n_cols=c2ciidx, build=build)

    # @profile
    def build_for_cols(self, build: bool, cols: np.ndarray):
        &#39;&#39;&#39;This does the same as `build` but it only builds for the 
        column indices specified, in order

        NOTE - these are the indicies for the on interactions only, that means we skip 
        over the interactions that are false for enumerating them
        &#39;&#39;&#39;
        input_cols = OrderedSet(list(cols))

        rows = []
        cols = []
        d = {}

        iidx = 0
        i = 0
        for tcid,scid in self.interactions.iter_valid_pairs():
            if iidx in input_cols:
                d, rows, cols = self.inner_faster(rows, cols, d, tcid, scid, i)
                i += 1
            iidx += 1
        
        rows = np.asarray(list(itertools.chain.from_iterable(rows)))
        cols = np.asarray(list(itertools.chain.from_iterable(cols)))
        self._make_matrix(rows=rows, cols=cols, n_cols=len(input_cols), build=build)

    # @profile
    def build_for_specified(self, build: bool, idxs: np.ndarray, tcids: np.ndarray, scids: np.ndarray):
        &#39;&#39;&#39;This does the same as `build` but it only builds for the 
        pair of tcids and scids at the same index passed in
        &#39;&#39;&#39;
        # input_cols = OrderedSet(list(idxs))

        rows = []
        cols = []
        d = {}

        for i in range(len(idxs)):
            d, rows, cols = self.inner_faster(rows, cols, d, tcids[idxs[i]], scids[idxs[i]], i)

        
        rows = np.asarray(list(itertools.chain.from_iterable(rows)))
        cols = np.asarray(list(itertools.chain.from_iterable(cols)))
        self._make_matrix(rows=rows, cols=cols, n_cols=len(idxs), build=build)

    # @profile
    def build_to_and_from(self, cids: List[int], build: bool):
        &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
        from scratch for only positive interactions going to an from each 
        of the clusters in `cids`.

        Parameters
        ----------
        cids : list
            This is a list of cids that we are getting the M matrix for
        &#39;&#39;&#39;
        rows = []
        cols = []
        d = {}
        c2ciidx = 0

        cids = OrderedSet(cids)
        # print(&#39;cidxs\n&#39;, cidxs)
        # print(&#39;from data\n&#39;, self.interactions.clustering.order)

        for interaction in self.interactions:
            if not interaction.indicator:
                continue
            if interaction.target_cid in cids:
                d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
            elif interaction.source_cid in cids:
                d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
            c2ciidx += 1

        # print(&#39;interactions_used&#39;, interactions_used)
            
        rows = np.asarray(list(itertools.chain.from_iterable(rows))) #, dtype=int)
        cols = np.asarray(list(itertools.chain.from_iterable(cols))) #, dtype=int)
        self._make_matrix(rows=rows, cols=cols, n_cols=c2ciidx, build=build)

    # @profile
    def inner(self, rows: List, cols: List, d: Dict[int, Any], interaction: pl.contrib._Interaction, 
        c2ciidx: int) -&gt; Tuple[Dict[int, Any], List, List]:
        tcid = interaction.target_cid
        scid = interaction.source_cid

        if tcid not in d:
            tmems = np.asarray(list(self.clustering.clusters[tcid].members))
            d[tcid] = tmems
        else:
            tmems = d[tcid]

        if scid not in d:
            smems = np.asarray(list(self.clustering.clusters[scid].members))
            d[scid] = smems
        else:
            smems = d[scid]

        a = np.zeros(len(tmems)*len(smems), int)
        rows.append(InteractionsMixingDesignMatrix.get_indices(
            a, self.keypair2col, tmems, smems))
        cols.append(np.full(len(tmems)*len(smems), fill_value=c2ciidx))

        return d, rows, cols

    # @profile
    def inner_faster(self, rows: List, cols: List, d: Dict[int, Any], tcid: int, scid: int, 
        c2ciidx: int) -&gt; Tuple[Dict[int, Any], List, List]:
        if tcid not in d:
            tmems = np.asarray(list(self.clustering.clusters[tcid].members))
            d[tcid] = tmems
        else:
            tmems = d[tcid]

        if scid not in d:
            smems = np.asarray(list(self.clustering.clusters[scid].members))
            d[scid] = smems
        else:
            smems = d[scid]

        a = np.zeros(len(tmems)*len(smems), int)
        rows.append(InteractionsMixingDesignMatrix.get_indices(
            a, self.keypair2col, tmems, smems))
        cols.append(np.full(len(tmems)*len(smems), fill_value=c2ciidx))

        return d, rows, cols

    # @profile
    def inner_faster_faster(self, tcid: int, scid: int, c2ciidx: int):
        if tcid not in self.d:
            tmems = np.asarray(list(self.clustering.clusters[tcid].members))
            self.d[tcid] = tmems
        else:
            tmems = self.d[tcid]

        if scid not in self.d:
            smems = np.asarray(list(self.clustering.clusters[scid].members))
            self.d[scid] = smems
        else:
            smems = self.d[scid]

        end = self.baseidx + len(tmems)*len(smems)
        if end &gt; len(self.cols):
            # pad 400 to the length
            self.rows = np.append(self.rows, np.zeros(400, dtype=int))
            self.cols = np.append(self.cols, np.zeros(400, dtype=int))

        InteractionsMixingDesignMatrix.get_indices(
            self.rows[self.baseidx:end], self.keypair2col, tmems, smems)
        self.cols[self.baseidx:end] = c2ciidx
        self.baseidx = end

    # @profile
    def _make_matrix(self, rows, cols, n_cols, build):
        &#39;&#39;&#39;Builds the mixing matrix from the specified rows and columns
        (data is always going to be 1 because it is a mixing matrix)

        Rebuild after we have changed the mixing matrix if `build` is True.
        &#39;&#39;&#39;
        self.n_cols = n_cols
        # else:
        data = np.ones(len(rows), dtype=int)
        self.matrix = scipy.sparse.coo_matrix((data,(rows,cols)),
            shape=(self.n_rows, n_cols)).tocsc()
        self.shape = self.matrix.shape
        if build:
            self.parent.build()

    @staticmethod
    @numba.jit(nopython=True, cache=True)
    def get_indices(a: np.ndarray, keypair2col: np.ndarray, tmems: np.ndarray, 
        smems: np.ndarray) -&gt; np.ndarray:
        &#39;&#39;&#39;Use Just in Time compilation to reduce the &#39;getting&#39; time
        by about 95%

        Parameters
        ----------
        a : np.ndarray
            Return array
        keypair2col : np.ndarray
            Maps (target_oidx, source_oidx) pair to the place the interaction
            index would be on a full interactio design matrix on the Taxa level
        tmems, smems : np.ndarray
            These are the Taxa indices in the target cluster and the source cluster
            respectively

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        i = 0
        for tidx in tmems:
            for sidx in smems:
                a[i] = keypair2col[tidx, sidx]
                i += 1
        return a


class InteractionsDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Builds the design matrix for the interactions: 
    - A_{i,j} @ M = A_{c_i,c_j}, where
        - A_{i,j} is the __Taxa-Taxa__ interaction matrix (self.base)
        - M is the mixing matrix (self.M)
        - A_{c_i,c_j} is the cluster-cluster interaction matrix

    This matrix is composed of two, individual design matrices, `Base` and `M`.
    To make the matrix that we use during inference, we matrix multiply `Base`@`M`,
    which is what this class is for. It wraps these two base classes so that it
    is more streamlined in the inference code.

    * `Base` : mdsine2.design_matrices.InteractionsBaseDesignMatrix
        - This is an object that builds the interaction matrix as if there was no
          clustering or indicators. It builds the data for all the Taxa/OTUs and
          as if every interaction indicator was on. This is actually faster than
          just building it for individual indicators for a few different reasons:
              1) We only need to update `Base` when we do filtering or update the 
                 values of the growth matrix because these are the only two things
                 that `Base` is dependent on.
              2) Because we don&#39;t have to check indicators or have different shapes
                 when building the matrix, it is much easier to build this matrix
                 with Numba, which is nearly as fast as C. This speeds up building
                 time by ~97%.
    * `Mixing` : mdsine2.design_matrices.InteractionsMixingDesignMatrix
        - This is the object that selects for indicators and groups taxa together
          into clusters. When we change the indicators of the perturbations or 
          the cluster assignments of the Taxa, we only need to change this matrix,
          which is a lot faster than changing everything. Because both matrices are
          sparse matrices and this matrix is 98% zeros, this is a very fast operation.

    See Also
    --------
    mdsine2.design_matrices.InteractionsBaseDesignMatrix
    mdsine2.design_matrices.InteractionsMixingDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.CLUSTER_INTERACTION_VALUE,
            update=True, **kwargs)

        # Initialize and set up rows and cols for base matrix
        total_n_dts = self.G.data.total_n_dts_per_taxa
        n_taxa = self.G.data.n_taxa

        self.n_rows = int(n_taxa * total_n_dts)
        self.clustering = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].clustering

        self.base = InteractionsBaseDesignMatrix(add_to_dict=False, **kwargs)
        self.base.build()
        self.M = InteractionsMixingDesignMatrix(add_to_dict=False, parent=self,**kwargs)
        self.build()
        self.interactions = self.M.interactions
        logging.info(&#39;Initializing interactions matrix&#39;)

    def build(self):
        self.matrix = self.base.matrix @ self.M.matrix
        self.n_cols = self.shape[1]

    @property
    def shape(self) -&gt; Tuple[int, int]:
        return self.matrix.shape

    def set_to_lhs(self) -&gt; np.ndarray:
        b_cicj = self.interactions.get_values(
            use_indicators=True).reshape(-1,1)
        return self.matrix.dot(b_cicj)

    def set_to_rhs(self)-&gt; scipy.sparse.spmatrix:
        return self.matrix

    def update_value(self):
        self.base.update_value()
        self.build()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mdsine2.design_matrices.Data"><code class="flex name class">
<span>class <span class="ident">Data</span></span>
<span>(</span><span>subjects:Â <a title="mdsine2.pylab.base.Study" href="pylab/base.html#mdsine2.pylab.base.Study">Study</a>, zero_inflation_transition_policy:Â strÂ =Â None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Acts as a collection for the Observation object and a collection of Covariate objects.</p>
<h2 id="description-of-internal-objects">Description Of Internal Objects</h2>
<ul>
<li>
<p>self.data : list(np.ndarray(n_taxa, n_times)) </p>
<ul>
<li>These are the data matrices that are used to build the design matrices. Index
the replicate by the index of the list. </li>
</ul>
</li>
<li>
<p>self.dt[ridx][k] : list(np.ndarray((n_times, ))) </p>
<ul>
<li>This is the change in time from time index k to time index k+1 for replicate index <code>ridx</code>.</li>
</ul>
</li>
<li>self.dt_vec : np.ndarray <ul>
<li>These have the same values as <code>self.dt</code> excpet that the arrays are flattened so that the
index of dt corresponds to the row in the design matrix. IE (x[k+1] - x[k])/self.dt[k] can be thought
of as:
[
]
for each replicate index <code>ridx</code> and Taxa index <code>aidx</code></li>
</ul>
</li>
<li>Difference between <code>self.times</code> and <code>self.given_timepoints</code><ul>
<li><code>self.times</code> are all the timepoints that we have data for the latent trajectory whereas</li>
<li><code>self.given_timepoints</code> are all the timepoints where we actually have data for as specified in </li>
<li><code>self.subjects</code>. These are going to be different if we have intermediate datapoints</li>
</ul>
</li>
</ul>
<p>We assume that once this object gets initialized there is not more deletions of
Taxas or replicates for the inference, i.e. <code>subjects</code> needs to stay fixed during inference
for this object to stay consistent.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>subjects</code></strong> :&ensp;<code>pylab.base.Study</code></dt>
<dd>These are a list of the subjects that we are going to get data from</dd>
<dt><strong><code>zero_inflation_transition_policy</code></strong> :&ensp;<code>str</code></dt>
<dd>How we handle the transitions from a structural zero to a non-structural zero.
If None then we do not assume any zero-inflation. Options:
'sample'
Intermediate timepoint is uniformly sampled between the structural zero and
non-strctural zero and set at that point.
'half-way'
Intermediate timepoint is set to half-way between the structural-zero and
non-structural zero
'ignore'
We ignore the change from not being there to being there and vice versa.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>
<ul>
<li>These are the extra arguments for DataNode</li>
</ul>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Data(DataNode):
    &#39;&#39;&#39;Acts as a collection for the Observation object and a collection of Covariate objects.

    Description of internal objects
    -------------------------------
    - self.data : list(np.ndarray(n_taxa, n_times)) 
        - These are the data matrices that are used to build the design matrices. Index
          the replicate by the index of the list. 
    
    - self.dt[ridx][k] : list(np.ndarray((n_times, ))) 
        - This is the change in time from time index k to time index k+1 for replicate index `ridx`.
    - self.dt_vec : np.ndarray 
        - These have the same values as `self.dt` excpet that the arrays are flattened so that the 
          index of dt corresponds to the row in the design matrix. IE (x[k+1] - x[k])/self.dt[k] can be thought
          of as: 
          ..math:: (x[ridx][aidx, k+1] - x2[ridx][aidx, k])/(times[ridx][k+1] - times[ridx][k])
          for each replicate index `ridx` and Taxa index `aidx`
    - Difference between `self.times` and `self.given_timepoints`
        - `self.times` are all the timepoints that we have data for the latent trajectory whereas
        - `self.given_timepoints` are all the timepoints where we actually have data for as specified in 
        - `self.subjects`. These are going to be different if we have intermediate datapoints

    We assume that once this object gets initialized there is not more deletions of
    Taxas or replicates for the inference, i.e. `subjects` needs to stay fixed during inference
    for this object to stay consistent.

    Parameters
    ----------
    subjects : pylab.base.Study
        These are a list of the subjects that we are going to get data from
    zero_inflation_transition_policy : str
        How we handle the transitions from a structural zero to a non-structural zero.
        If None then we do not assume any zero-inflation. Options:
        &#39;sample&#39;
            Intermediate timepoint is uniformly sampled between the structural zero and 
            non-strctural zero and set at that point.
        &#39;half-way&#39;
            Intermediate timepoint is set to half-way between the structural-zero and
            non-structural zero
        &#39;ignore&#39;
            We ignore the change from not being there to being there and vice versa.
    **kwargs
        - These are the extra arguments for DataNode
    &#39;&#39;&#39;
    def __init__(self, subjects: Study, zero_inflation_transition_policy: str=None, **kwargs):
        if &#39;name&#39; not in kwargs:
            kwargs[&#39;name&#39;] = &#39;data matrix&#39;
        DataNode.__init__(self, **kwargs)
        if not pl.isstudy(subjects):
            raise ValueError(&#39;`subjects` ({}) must be a pylab Study&#39;.format(
                type(subjects)))

        self.taxa = subjects.taxa # This is the TaxaSet object in pylab.base.TaxaSet
        self.subjects = subjects # This is the Study object in pylab.base.Study
        self.zero_inflation_transition_policy = zero_inflation_transition_policy

        self.raw_data = [] # list(np.ndarray) data matrices in count abundance for each subject in order
        self.rel_data = [] # list(np.ndarray) data matrices in relative abundance for each subject in order
        self.abs_data = [] # list(np.ndarray) data matrices in absolute abundance for each subject in order
        self.qpcr = [] # list(dict(float -&gt; qPCRData)) of qPCR objects for the subjects in time order
        self.qpcr_variances = None
        self.read_depths = [] # read depths for each subject in time order
        self.given_timepoints = [] # These are the timepoints that are included with the subject
        self._given_timepoints_set = [] # this is a set object of `given_timepoints`
        self.given_timeindices = [] # These are the indicies for the given timepoints
        self.data_timeindex2given_timeindex = {} # maps the index for all of the times to the index in the original subject
        self.n_timepoints_for_replicate = [] # np.ndarray, number of timepoints for each subject
        self.n_dts_for_replicate = [] # np.ndarray, how many dts there are for each subject (n_timespoints - 1)
        self.times = [] # list(np.ndarray) This is the array of times for each subject
        self.data = [] # list(np.ndarray) This is the where we keep the filtered data
        self.dt = [] # list(np.ndarray) Has each dt between each timepoint for each subject
        self.timepoint2index = [] # list(dict(float, int)) for each subject, maps the time (float) to the index it occurs in (int)
        self.toupdate = OrderedSet() # Which design matrices we change once we filter the data
        self.n_replicates = len(self.subjects)
        self.n_taxa = len(self.taxa)

        for ridx, s in enumerate(self.subjects):
            d = s.matrix()
            self.raw_data.append(d[&#39;raw&#39;])
            self.rel_data.append(d[&#39;rel&#39;])
            self.abs_data.append(d[&#39;abs&#39;])
            temp_data = np.array(d[&#39;abs&#39;]) # to copy the array
            self.data.append(temp_data)
            self.qpcr.append(s.qpcr)
            self.n_timepoints_for_replicate.append(d[&#39;raw&#39;].shape[1])
            self.n_dts_for_replicate.append(d[&#39;raw&#39;].shape[1]-1)
            self.given_timepoints.append(np.asarray(s.times))
            self._given_timepoints_set.append(OrderedSet())
            self.given_timeindices.append(OrderedSet())
            self.times.append(np.asarray(s.times))
            for tidx,t in enumerate(self.times[ridx]):
                self._given_timepoints_set[ridx].add(t)
                self.given_timeindices[ridx].add(tidx)
                self.data_timeindex2given_timeindex[(ridx,tidx)] = tidx

            self.timepoint2index.append({})
            for tidx,t in enumerate(self.times[ridx]):
                self.timepoint2index[ridx][t] = tidx

            curr_read_depths = np.zeros(self.n_timepoints_for_replicate[ridx])
            for tidx,t in enumerate(s.times):
                curr_read_depths[tidx] = s.read_depth(t)
            self.read_depths.append(curr_read_depths)

            self.dt.append(np.zeros(self.n_timepoints_for_replicate[ridx] - 1))
            for k in range(len(self.dt[ridx])):
                self.dt[ridx][k] = self.times[ridx][k+1] - self.times[ridx][k]

        self.total_n_timepoints_per_taxa = 0
        self.total_n_dts_per_taxa = 0
        for nt in self.n_timepoints_for_replicate:
            self.total_n_timepoints_per_taxa += nt
            self.total_n_dts_per_taxa += (nt-1)

        # make dt_vec
        n = 0
        for ridx in range(self.n_replicates):
            n += len(self.dt[ridx])
        n *= self.n_taxa
        n_taxa = self.n_taxa
        self.dt_vec = np.zeros(n)
        i = 0
        for ridx in range(self.n_replicates):
            for t in self.dt[ridx]:
                self.dt_vec[i:i+n_taxa] = t
                i += n_taxa
        self.sqrt_dt_vec = np.sqrt(self.dt_vec)

        self.design_matrices = {}
        self.lhs = None

        # Make tidx arrays for perturbations if necessary
        self.tidxs_in_perturbation = None
        if self.subjects.perturbations is not None:
            self.tidxs_in_perturbation = []
            for ridx, subj in enumerate(self.subjects):
                self.tidxs_in_perturbation.append([])
                for perturbation in self.subjects.perturbations:
                    start = perturbation.starts[subj.name]
                    end = perturbation.ends[subj.name]

                    if start in self.timepoint2index[ridx]:
                        # There is a measurement at the start of the perturbation
                        start_idx = self.timepoint2index[ridx][start]
                    else:
                        # There is no measurement at the start of the perturbation.
                        # Get the next timepoint
                        start_idx = np.searchsorted(self.times[ridx], start)
                    
                    if end in self.timepoint2index[ridx]:
                        # There is a measurement at the end of the perturbation
                        end_idx = self.timepoint2index[ridx][end]
                    else:
                        # There is no measurement at the end of the perturbation
                        # Get the previous timepoint
                        end_idx = np.searchsorted(self.times[ridx], end) - 1

                    # Check if anything is weird
                    start_idx = int(start_idx)
                    end_idx = int(end_idx)
                    if start_idx &gt; end_idx:
                        # raise ValueError(&#39;end time index ({}) of a perturbation less&#39; \
                        #     &#39; than the start index ({})?&#39;.format(end_idx, start_idx))
                        self.tidxs_in_perturbation[ridx].append((None, None))
                    if start_idx == end_idx:
                        self.tidxs_in_perturbation[ridx].append((start_idx, start_idx+1))
                    else:
                        self.tidxs_in_perturbation[ridx].append((start_idx, end_idx))
        
        # Set structural zeros - everything is set to non-structural zero initially
        if self.zero_inflation_transition_policy is not None:
            self._structural_zeros = []
            for ridx in range(self.n_replicates):
                self._structural_zeros.append(np.zeros(
                    shape=(len(self.taxa), self.n_timepoints_for_replicate[ridx]), dtype=bool))
            self._setrows_to_include_zero_inflation()

    def iter_for_building(self) -&gt; Tuple[int, int, int]:
        for ridx in range(self.n_replicates):
            for tidx in range(self.n_dts_for_replicate[ridx]):
                for oidx in range(len(self.taxa)):
                    yield oidx, tidx, ridx

    def make_delta_t(self, sqrt: bool=False) -&gt; np.ndarray:
        &#39;&#39;&#39;Returns the whole delta_t vector for each time point.

        Parameters
        ----------
        sqrt : bool
            If True, return the square root of the vector. Default is False
        &#39;&#39;&#39;
        if sqrt:
            return self.sqrt_dt_vec
        else:
            return self.dt_vec

    def is_intermediate_timepoint(self, ridx: int, t: float) -&gt; bool:
        &#39;&#39;&#39;Checks if the given time `t` for subject index `ridx` is
        an intermediate time point or not

        Parameters
        ----------
        ridx : int
            Replicate index
        t : numeric
            Time point

        Returns
        -------
        bool
        &#39;&#39;&#39;
        return t not in self._given_timepoints_set[ridx]

    def is_intermediate_timeindex(self, ridx: int, tidx: int) -&gt; bool:
        &#39;&#39;&#39;Checks if the given time index `tidx` for subject index `ridx` is
        an intermediate time point or not

        Parameters
        ----------
        ridx : int
            Replicate index
        tidx : int
            Time index

        Returns
        -------
        bool
        &#39;&#39;&#39;
        return tidx not in self.given_timeindices[ridx]

    def set_timepoints(self, times: np.ndarray=None, timestep: float=None, ridx: int=None, 
        eps: float=None, reset_timepoints: bool=False):
        &#39;&#39;&#39;Set times if you want intermediate timepoints.
        
        These are the time points that you want to generate the latent state at.
        If there is a time in `times` that is not in the given data, then we set
        it as an intermediate time point. You can specify the times that you 
        want either as a vector with `times` or with a constant time-step
        with the interval `timestep`. Only one of them is necessary. It will crash
        if both are supplied.

        `eps` is a radius around each of the given timepoints already supplied by
        the data in `subjects` where no intermediate timepoints can be set.
        If a timepoint that is set is within `eps` days of a timepoint already there,
        then we skip adding that timepoint. If `eps` is None then we assume
        that there is no constraint. 

        If `reset_timepoints` is True, then we delete the intermediate timepoints
        that may have been added at a different time and use only these. If False
        then the set of timepoints added at this call is adde to the set of 
        timepoints that were added at a previous call. 

        Parameters
        ----------
        times : array
            These are the time points to set
            If there are any time points not included in here but are included
            with the given data then we automatically add them in. If there
            are any time points in times that are already in the given data,
            it is automatically set as a given time point
            You need to provide this argument if you are not providing `timestep`
        timestep : float, int
            This is the time steps to generate the times at until the last time
            at every replicate.
            A data point will only be added if there is not already a datapoint
            at that time. This is only necessary if you did not pass in `times`
        ridx : int, Optional
            If this is given, then we only set these times for the given
            replicate index. If nothing is specified then we set the time points
            for all of the replicates.
        eps : numeric, None
            If an intermediate timestep is within `eps` days of a given timepoint
            then we do not add it. If None then there is no restriction to how close
            the intermediate timepoint can be.
        reset_timepoints : bool
            If this is True then we delete the previous added intermediate timepoints.
            If False then we add the set of timepoints added at this call with the
            intermediate timepoints from a previous call.
        &#39;&#39;&#39;
        if (times is None and timestep is None) or (times is not None and timestep is not None):
            raise ValueError(&#39;Either `times` or `timestep` must be provided&#39;)
        if not pl.isbool(reset_timepoints):
            raise TypeError(&#39;`reset_timepoints` ({}) must be a bool&#39;.format(
                type(reset_timepoints)))
        if ridx is not None:
            if not pl.isint(ridx):
                raise ValueError(&#39;`ridx` ({}) must be an int&#39;.format(type(ridx)))
            ridxs = [ridx]
        else:
            ridxs = np.arange(self.n_replicates)
        
        if timestep is not None:
            if not pl.isnumeric(timestep):
                raise ValueError(&#39;`timestep` ({}) must be a numeric&#39;.format(type(timestep)))
            # get the earliest start and the latest end
            start = float(&#39;inf&#39;)
            end = -1
            for ts in self.times:
                if start &gt; ts[0]:
                    start = ts[0]
                if end &lt; ts[-1]:
                    end = ts[-1]
            times = np.arange(start,end,timestep)
        if not pl.isarray(times):
            raise ValueError(&#39;`times` ({}) must be an array&#39;.format(type(times)))
        
        if eps is not None:
            if not pl.isnumeric(eps):
                raise TypeError(&#39;`eps` ({}) must be a numeric&#39;.format(type(eps)))
            if eps &lt; 0:
                raise ValueError(&#39;`eps` ({}) must be &gt;= 0&#39;.format(eps))
            
        for ridx in ridxs:
            if reset_timepoints:
                new_times = np.array(self.given_timepoints[ridx])
            else:
                new_times = np.array(self.times[ridx])

            n_added = 0
            for t in times:
                if t not in new_times:
                    # Check if the datapoint is within `eps` of real data
                    # Get the surrounding timepoints
                    if eps is None:
                        n_added += 1
                        new_times = np.append(new_times, t)
                    else:
                        smallest_big = float(&#39;-inf&#39;)
                        largest_small = float(&#39;inf&#39;)
                        for tt in new_times:
                            if tt &lt; t and tt &gt; largest_small:
                                largest_small = tt
                            elif tt &gt; t and tt &lt; smallest_big:
                                smallest_big = tt
                        if np.min([t-largest_small, smallest_big-t]) &lt; eps:
                            n_added += 1
                            new_times = np.append(new_times, t)
                        
            sorted_tidxs = np.argsort(new_times)
            self.times[ridx] = new_times[sorted_tidxs]
            if reset_timepoints:
                self.data[ridx] = np.hstack((
                    self.abs_data[ridx], 
                    np.zeros(shape=(self.n_taxa, n_added))*np.nan))
            else:
                self.data[ridx] = np.hstack((
                    self.data[ridx],
                    np.zeros(shape=(self.n_taxa, n_added)) * np.nan))
            self.data[ridx] = self.data[ridx][:,sorted_tidxs]
            self.n_timepoints_for_replicate[ridx] = len(self.times[ridx])
            self.n_dts_for_replicate[ridx] = len(self.times[ridx])-1

            # redo `given_timeindices`
            self.given_timeindices[ridx] = OrderedSet()
            for tidx in range(len(self.times[ridx])):
                if self.times[ridx][tidx] in self._given_timepoints_set[ridx]:
                    self.given_timeindices[ridx].add(tidx)

            # redo `data_timeindex2given_timeindex` - first delete all ones that
            # have that as the replicate and then add the new oens
            new_d = {}
            for aaa,bbb in self.data_timeindex2given_timeindex:
                if aaa == ridx:
                    continue
                new_d[(aaa,bbb)] = self.data_timeindex2given_timeindex[(aaa,bbb)]
            self.data_timeindex2given_timeindex = new_d

            given_times = self.given_timepoints[ridx]
            for tidx in range(self.n_timepoints_for_replicate[ridx]):
                if tidx in self.given_timeindices[ridx]:
                    # Get index where the time occurs in the given times
                    t = self.times[ridx][tidx]
                    found = False
                    for i in range(len(given_times)):
                        if t == given_times[i]:
                            found = True
                            self.data_timeindex2given_timeindex[(ridx,tidx)] = i
                            break
                    if not found:
                        raise ValueError(&#39;Not found - something is wrong&#39;)

                else:
                    self.data_timeindex2given_timeindex[(ridx,tidx)] = np.nan

            # Redo the reverse indexing
            self.timepoint2index[ridx] = {}
            for tidx,t in enumerate(self.times[ridx]):
                self.timepoint2index[ridx][t] = tidx

            # redo `dt`
            self.dt[ridx] = np.zeros(self.n_timepoints_for_replicate[ridx]-1)
            for k in range(len(self.dt[ridx])):
                self.dt[ridx][k] = self.times[ridx][k+1] - self.times[ridx][k]

        # redo dt_vec
        n = 0
        for ridx in range(self.n_replicates):
            n += len(self.dt[ridx])
        n *= self.n_taxa
        n_taxa = self.n_taxa
        self.dt_vec = np.zeros(n)
        i = 0
        for ridx in range(self.n_replicates):
            for t in self.dt[ridx]:
                self.dt_vec[i:i+n_taxa] = t
                i += n_taxa
        self.sqrt_dt_vec = np.sqrt(self.dt_vec)

        self.total_n_timepoints_per_taxa = 0
        self.total_n_dts_per_taxa = 0
        for nt in self.n_timepoints_for_replicate:
            self.total_n_timepoints_per_taxa += nt
            self.total_n_dts_per_taxa += (nt - 1)


        # redo tidx arrays for perturbations if necessary
        if self.tidxs_in_perturbation is not None:
            self.tidxs_in_perturbation = []
            for ridx, subj in enumerate(self.subjects):
                self.tidxs_in_perturbation.append([])
                for perturbation in self.subjects.perturbations:
                    start = perturbation.starts[subj.name]
                    end = perturbation.ends[subj.name]

                    if start in self.timepoint2index[ridx]:
                        # There is a measurement at the start of the perturbation
                        start_idx = self.timepoint2index[ridx][start]
                    else:
                        # There is no measurement at the start of the perturbation.
                        # Get the next timepoint
                        start_idx = np.searchsorted(self.times[ridx], start)
                    
                    if end in self.timepoint2index[ridx]:
                        # There is a measurement at the end of the perturbation
                        end_idx = self.timepoint2index[ridx][end]
                    else:
                        # There is no measurement at the end of the perturbation
                        # Get the previous timepoint
                        end_idx = np.searchsorted(self.times[ridx], end) - 1

                    # Check if anything is weird
                    start_idx = int(start_idx)
                    end_idx = int(end_idx)
                    if start_idx &gt; end_idx:
                        # raise ValueError(&#39;end time index ({}) of a perturbation less&#39; \
                        #     &#39; than the start index ({})?&#39;.format(end_idx, start_idx))
                        self.tidxs_in_perturbation[ridx].append((None, None))
                    if start_idx == end_idx:
                        self.tidxs_in_perturbation[ridx].append((start_idx, start_idx + 1))
                    else:
                        self.tidxs_in_perturbation[ridx].append((start_idx, end_idx))

    def set_zero_inflation(self, turn_on: Iterator[Tuple[int, int, int]]=None, 
        turn_off: Iterator[Tuple[int, int, int]]=None):
        &#39;&#39;&#39;Set which timepoints taxa are set to be turned off. Any taxa, timepoints tuple
        not in `d` is assumed to be &#34;present&#34; (a nonn-structural zero). `d` is an array
        of 3-tuples, where:
            (ridx, tidx, aidx)
                ridx: replicate index (not the same as replicate name)
                tidx: timepoint index (not the same as timepoint)
                aidx: Taxa index (not the same as Taxa name)
        
        Parameters
        ----------
        turn_on : list(3-tuple)
            A list of ridx, tidx, aidx to set to being present
        turn_on : list(3-tuple)
            A list of ridx, tidx, aidx to set to a structural zero
        &#39;&#39;&#39;
        if self.zero_inflation_transition_policy is None:
            # raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
            #     &#39;is not set during initialization&#39;)
            logging.warning(&#39;`zero_inflation_transition_policy` is None so we are not doing anything&#39;)
            return
        if turn_on is not None:
            for i, (ridx,tidx,aidx) in enumerate(turn_on):
                if ridx &gt; self.n_replicates or ridx &lt; 0:
                    raise ValueError(&#39;ridx ({}) in index `{}` ({}) is out of range. Only {} replicates&#39;.format(
                        ridx, i, (ridx,tidx,aidx), self.n_replicates))
                if tidx &gt; self.n_timepoints_for_replicate[ridx] or tidx &lt; 0:
                    raise ValueError(&#39;tidx ({}) in index `{}` ({}) is out of range. Only {} timepoints in replicate {}&#39;.format(
                        tidx, i, (ridx,tidx,aidx), self.n_timepoints_for_replicate[ridx], ridx))
                if aidx &gt; len(self.taxa) or aidx &lt; 0:
                    raise ValueError(&#39;aidx ({}) in index `{}` ({}) is out of range. Only {} s&#39;.format(
                        aidx, i, (ridx,tidx,aidx), len(self.taxa)))

                self._structural_zeros[ridx][aidx,tidx] = False

        if turn_off is not None:
            for i, (ridx,tidx,aidx) in enumerate(turn_off):
                if ridx &gt; self.n_replicates or ridx &lt; 0:
                    raise ValueError(&#39;ridx ({}) in index `{}` ({}) is out of range. Only {} replicates&#39;.format(
                        ridx, i, (ridx,tidx,aidx), self.n_replicates))
                if tidx &gt; self.n_timepoints_for_replicate[ridx] or tidx &lt; 0:
                    raise ValueError(&#39;tidx ({}) in index `{}` ({}) is out of range. Only {} timepoints in replicate {}&#39;.format(
                        tidx, i, (ridx,tidx,aidx), self.n_timepoints_for_replicate[ridx], ridx))
                if aidx &gt; len(self.taxa) or aidx &lt; 0:
                    raise ValueError(&#39;aidx ({}) in index `{}` ({}) is out of range. Only {} s&#39;.format(
                        aidx, i, (ridx,tidx,aidx), len(self.taxa)))

                self._structural_zeros[ridx][aidx,tidx] = True
        self._setrows_to_include_zero_inflation()

    def is_timepoint_structural_zero(self, ridx: int, tidx: int, aidx: int) -&gt; bool:
        &#39;&#39;&#39;Returns True if the replicate index `ridx`, timepoint index `tidx`, and
        Taxa index `aidx` is a structural zero or not
        &#39;&#39;&#39;
        if self.zero_inflation_transition_policy is None:
            raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
                &#39;is not set during initialization&#39;)
        return self._structural_zeros[ridx][aidx, tidx]

    def _setrows_to_include_zero_inflation(self):
        &#39;&#39;&#39;Make a rows matrix for what to include based on `self._structural_zeros`
        &#39;&#39;&#39;
        if self.zero_inflation_transition_policy is None:
            raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
                &#39;is not set during initialization&#39;)

        iii = 0

        l = len(self.taxa) * self.total_n_dts_per_taxa
        self.rows_to_include_zero_inflation = np.zeros(l, dtype=bool)
        iii = 0
        for ridx in range(self.n_replicates):
            curr_structural_zero = self._structural_zeros[ridx]
            for dtidx in range(self.n_dts_for_replicate[ridx]):
                # we look at timepoint indices `dtidx` and `dtidx+1`

                tidxstart = dtidx
                tidxend = dtidx

                for aidx in range(len(self.taxa)):

                    structzero_start = curr_structural_zero[aidx, tidxstart]
                    structzero_end = curr_structural_zero[aidx, tidxend]
                    
                    if structzero_start and structzero_end:
                        # If both are not there, exclude
                        self.rows_to_include_zero_inflation[iii] = False
                    
                    elif (not structzero_end) and (not structzero_start):
                        # If both are there, include
                        self.rows_to_include_zero_inflation[iii] = True

                    else:
                        # Else we are in a transition and we must use a policy
                        if self.zero_inflation_transition_policy == &#39;ignore&#39;:
                            # don&#39;t include it
                            self.rows_to_include_zero_inflation[iii] = False
                        elif self.zero_inflation_transition_policy == &#39;half-way&#39;:
                            raise NotImplementedError(&#39;Not implemented&#39;)
                        elif self.zero_inflation_transition_policy == &#39;sample&#39;:
                            raise NotImplementedError(&#39;Not implemented&#39;)
                        else:
                            raise ValueError(&#39;`zero_inflation_transition_policy` ({}) not recognized&#39;.format(
                                self.zero_inflation_transition_policy))

                    iii += 1

        self.off_previously_arr_zero_inflation = np.zeros(l, dtype=int)
        n_off_prev = 0
        for i in range(1, l):
            if not self.rows_to_include_zero_inflation[i-1]:
                n_off_prev += 1
            self.off_previously_arr_zero_inflation[i] = n_off_prev

    def _get_non_pert_rows_of_regress_matrices(self) -&gt; np.ndarray:
        &#39;&#39;&#39;This will get the rows where there are no perturbations in the
        regressor matrices
        &#39;&#39;&#39;
        if self.G.perturbations is None:
            return None

        replicate_offset = 0
        ridxs = np.array([], dtype=int)
        n_taxa = self.n_taxa
        for ridx in range(self.n_replicates):
            # For each replicate, get the time indices where ther are 
            # perturbations and then index them out
            for pidx in range(len(self.G.perturbations)):
                start_tidx, end_tidx = self.G.data.tidxs_in_perturbation[ridx][pidx]
                if start_tidx is None:
                    continue

                ridxs = np.append(ridxs, replicate_offset + np.arange(
                    start_tidx*n_taxa, (end_tidx-1)*n_taxa, dtype=int))
            replicate_offset += n_taxa * self.n_dts_for_replicate[ridx]

        ret = np.ones(len(self.lhs), dtype=bool)
        ret[ridxs] = False

        if self.zero_inflation_transition_policy is not None:
            ret = ret[self.rows_to_include_zero_inflation]

        return ret

    def construct_lhs(self, keys: List[str]=[], kwargs_dict: Dict[str, Dict[str, Any]]={}, 
        index_out_perturbations: bool=False) -&gt; np.ndarray:
        &#39;&#39;&#39;Does the stacking and subtracting necessary to make the observation vector

        Parameters
        ----------
        keys : list(str)
            These are the keys of the matrices to go on the left-hand-side (lhs)
        kwargs_dict: dict
            This is a dict of dicts:
                str -&gt; (str -&gt; val)
            The first level dictionary is one of the names in the keys
            The second level dictionary are the additional arguements that are
            send to that keys `construct_lhs` function.
        index_out_perturbations : bool
            If this is True, it will index out the rows that are in the perturbation.
            This would be used for times that you want to initialize the data not
            with any perturbation periods

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        y = self.lhs.vector
        valid_indices = None
        if index_out_perturbations and self.G.perturbations is not None:
            valid_indices = self._get_non_pert_rows_of_regress_matrices()
            y = y[valid_indices]
        for x in keys:
            if x in kwargs_dict:
                kwargs = kwargs_dict[x]
            else:
                kwargs = {}
            try:
                b = self.design_matrices[x].set_to_lhs(**kwargs)
            except:
                logging.critical(&#39;Crash in `construct_lhs` making the matrix. Key: {}. {}&#39;.format(x,
                    keys))
                raise
            if valid_indices is not None:
                b = b[valid_indices]
            try:
                y = y - b
            except:
                logging.critical(&#39;Crash in `construct_lhs` subtracting the matrix.&#39; \
                    &#39; Key: {}, y.shape: {}, b.shape: {}&#39;.format(x, y.shape, b.shape))
                raise
        return y.reshape(-1,1)

    # @profile
    def construct_rhs(self, keys: List[str], kwargs_dict: Dict[str, Dict[str, Any]]={}, 
        index_out_perturbations: bool=False, toarray: bool=False) -&gt; Union[scipy.sparse.spmatrix, np.ndarray]:
        &#39;&#39;&#39;Does the stacking and subtracting necessary to make the covariate matrix.
        Default setting for this matrix is a `scipy.sparse` matrix unless you
        explicitly convert it with `toarray`.

        Parameters
        ----------
        keys : list(keys)
            These are the keys of the matrices to go on the right-hand-side (rhs)
        kwargs_dict : dict(dict)
            This is a dict of dicts: str -&gt; (str -&gt; val)
            The first level dictionary is one of the names in the keys
            The second level dictionary are the additional arguements that are send to that keys 
            `construct_lhs` function.
        index_out_perturbations : bool, Optional
            If this is True, it will index out the rows that are in the perturbation.
            This would be used for times that you want to initialize the data not
            with any perturbation periods
        toarray : bool
            If True, converts the input into a numpy C_CONTIGUOUS array

        Returns
        -------
        scipy.sparse.csc_matrix or np.ndarray
        &#39;&#39;&#39;
        v = []
        valid_indices = None
        if index_out_perturbations and self.G.perturbations is not None:
            valid_indices = self._get_non_pert_rows_of_regress_matrices() 
        for x in keys:
            if x in kwargs_dict:
                kwargs = kwargs_dict[x]
            else:
                kwargs = {}
            if x not in self.design_matrices:
                raise KeyError(&#39;Key `{}` not found. Valid keys: {}&#39;.format(
                    x, list(self.design_matrices.keys())))
            X = self.design_matrices[x].set_to_rhs(**kwargs)
            if valid_indices is not None:
                X = X[valid_indices, :]
            v.append(X)
        if len(keys) == 0:
            X =  v[0]
        else:
            try:
                X = scipy.sparse.hstack(v)
            except:
                # try:
                #     X = torch.cat(v, 1)
                #     return X
                # except:
                t = [type(a) for a in v]
                s = [a.shape for a in v]
                logging.critical(&#39;shapes: {}, types: {}&#39;.format(s,t))
                logging.critical(&#39;keys: {}&#39;.format([self.G[a].name for a in keys]))
                raise
        if toarray:
            X_ = np.zeros(shape=X.shape)
            X.toarray(out=X_)
            return X_
        return X

    def update_values(self):
        &#39;&#39;&#39;Update the values of the data (because the latent state changed)
        &#39;&#39;&#39;
        self.lhs.update_value()
        for key in self.toupdate:
            self.design_matrices[key].update_value()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.graph.DataNode" href="pylab/graph.html#mdsine2.pylab.graph.DataNode">DataNode</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.Data.construct_lhs"><code class="name flex">
<span>def <span class="ident">construct_lhs</span></span>(<span>self, keys:Â List[str]Â =Â [], kwargs_dict:Â Dict[str,Â Dict[str,Â Any]]Â =Â {}, index_out_perturbations:Â boolÂ =Â False) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Does the stacking and subtracting necessary to make the observation vector</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>keys</code></strong> :&ensp;<code>list(str)</code></dt>
<dd>These are the keys of the matrices to go on the left-hand-side (lhs)</dd>
<dt><strong><code>kwargs_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>This is a dict of dicts:
str -&gt; (str -&gt; val)
The first level dictionary is one of the names in the keys
The second level dictionary are the additional arguements that are
send to that keys <code>construct_lhs</code> function.</dd>
<dt><strong><code>index_out_perturbations</code></strong> :&ensp;<code>bool</code></dt>
<dd>If this is True, it will index out the rows that are in the perturbation.
This would be used for times that you want to initialize the data not
with any perturbation periods</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def construct_lhs(self, keys: List[str]=[], kwargs_dict: Dict[str, Dict[str, Any]]={}, 
    index_out_perturbations: bool=False) -&gt; np.ndarray:
    &#39;&#39;&#39;Does the stacking and subtracting necessary to make the observation vector

    Parameters
    ----------
    keys : list(str)
        These are the keys of the matrices to go on the left-hand-side (lhs)
    kwargs_dict: dict
        This is a dict of dicts:
            str -&gt; (str -&gt; val)
        The first level dictionary is one of the names in the keys
        The second level dictionary are the additional arguements that are
        send to that keys `construct_lhs` function.
    index_out_perturbations : bool
        If this is True, it will index out the rows that are in the perturbation.
        This would be used for times that you want to initialize the data not
        with any perturbation periods

    Returns
    -------
    np.ndarray
    &#39;&#39;&#39;
    y = self.lhs.vector
    valid_indices = None
    if index_out_perturbations and self.G.perturbations is not None:
        valid_indices = self._get_non_pert_rows_of_regress_matrices()
        y = y[valid_indices]
    for x in keys:
        if x in kwargs_dict:
            kwargs = kwargs_dict[x]
        else:
            kwargs = {}
        try:
            b = self.design_matrices[x].set_to_lhs(**kwargs)
        except:
            logging.critical(&#39;Crash in `construct_lhs` making the matrix. Key: {}. {}&#39;.format(x,
                keys))
            raise
        if valid_indices is not None:
            b = b[valid_indices]
        try:
            y = y - b
        except:
            logging.critical(&#39;Crash in `construct_lhs` subtracting the matrix.&#39; \
                &#39; Key: {}, y.shape: {}, b.shape: {}&#39;.format(x, y.shape, b.shape))
            raise
    return y.reshape(-1,1)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.construct_rhs"><code class="name flex">
<span>def <span class="ident">construct_rhs</span></span>(<span>self, keys:Â List[str], kwargs_dict:Â Dict[str,Â Dict[str,Â Any]]Â =Â {}, index_out_perturbations:Â boolÂ =Â False, toarray:Â boolÂ =Â False) â€‘>Â Union[scipy.sparse.base.spmatrix,Â numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Does the stacking and subtracting necessary to make the covariate matrix.
Default setting for this matrix is a <code>scipy.sparse</code> matrix unless you
explicitly convert it with <code>toarray</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>keys</code></strong> :&ensp;<code>list(keys)</code></dt>
<dd>These are the keys of the matrices to go on the right-hand-side (rhs)</dd>
<dt><strong><code>kwargs_dict</code></strong> :&ensp;<code>dict(dict)</code></dt>
<dd>This is a dict of dicts: str -&gt; (str -&gt; val)
The first level dictionary is one of the names in the keys
The second level dictionary are the additional arguements that are send to that keys
<code>construct_lhs</code> function.</dd>
<dt><strong><code>index_out_perturbations</code></strong> :&ensp;<code>bool, Optional</code></dt>
<dd>If this is True, it will index out the rows that are in the perturbation.
This would be used for times that you want to initialize the data not
with any perturbation periods</dd>
<dt><strong><code>toarray</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, converts the input into a numpy C_CONTIGUOUS array</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>scipy.sparse.csc_matrix</code> or <code>np.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def construct_rhs(self, keys: List[str], kwargs_dict: Dict[str, Dict[str, Any]]={}, 
    index_out_perturbations: bool=False, toarray: bool=False) -&gt; Union[scipy.sparse.spmatrix, np.ndarray]:
    &#39;&#39;&#39;Does the stacking and subtracting necessary to make the covariate matrix.
    Default setting for this matrix is a `scipy.sparse` matrix unless you
    explicitly convert it with `toarray`.

    Parameters
    ----------
    keys : list(keys)
        These are the keys of the matrices to go on the right-hand-side (rhs)
    kwargs_dict : dict(dict)
        This is a dict of dicts: str -&gt; (str -&gt; val)
        The first level dictionary is one of the names in the keys
        The second level dictionary are the additional arguements that are send to that keys 
        `construct_lhs` function.
    index_out_perturbations : bool, Optional
        If this is True, it will index out the rows that are in the perturbation.
        This would be used for times that you want to initialize the data not
        with any perturbation periods
    toarray : bool
        If True, converts the input into a numpy C_CONTIGUOUS array

    Returns
    -------
    scipy.sparse.csc_matrix or np.ndarray
    &#39;&#39;&#39;
    v = []
    valid_indices = None
    if index_out_perturbations and self.G.perturbations is not None:
        valid_indices = self._get_non_pert_rows_of_regress_matrices() 
    for x in keys:
        if x in kwargs_dict:
            kwargs = kwargs_dict[x]
        else:
            kwargs = {}
        if x not in self.design_matrices:
            raise KeyError(&#39;Key `{}` not found. Valid keys: {}&#39;.format(
                x, list(self.design_matrices.keys())))
        X = self.design_matrices[x].set_to_rhs(**kwargs)
        if valid_indices is not None:
            X = X[valid_indices, :]
        v.append(X)
    if len(keys) == 0:
        X =  v[0]
    else:
        try:
            X = scipy.sparse.hstack(v)
        except:
            # try:
            #     X = torch.cat(v, 1)
            #     return X
            # except:
            t = [type(a) for a in v]
            s = [a.shape for a in v]
            logging.critical(&#39;shapes: {}, types: {}&#39;.format(s,t))
            logging.critical(&#39;keys: {}&#39;.format([self.G[a].name for a in keys]))
            raise
    if toarray:
        X_ = np.zeros(shape=X.shape)
        X.toarray(out=X_)
        return X_
    return X</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.is_intermediate_timeindex"><code class="name flex">
<span>def <span class="ident">is_intermediate_timeindex</span></span>(<span>self, ridx:Â int, tidx:Â int) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if the given time index <code>tidx</code> for subject index <code>ridx</code> is
an intermediate time point or not</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ridx</code></strong> :&ensp;<code>int</code></dt>
<dd>Replicate index</dd>
<dt><strong><code>tidx</code></strong> :&ensp;<code>int</code></dt>
<dd>Time index</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_intermediate_timeindex(self, ridx: int, tidx: int) -&gt; bool:
    &#39;&#39;&#39;Checks if the given time index `tidx` for subject index `ridx` is
    an intermediate time point or not

    Parameters
    ----------
    ridx : int
        Replicate index
    tidx : int
        Time index

    Returns
    -------
    bool
    &#39;&#39;&#39;
    return tidx not in self.given_timeindices[ridx]</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.is_intermediate_timepoint"><code class="name flex">
<span>def <span class="ident">is_intermediate_timepoint</span></span>(<span>self, ridx:Â int, t:Â float) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if the given time <code>t</code> for subject index <code>ridx</code> is
an intermediate time point or not</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ridx</code></strong> :&ensp;<code>int</code></dt>
<dd>Replicate index</dd>
<dt><strong><code>t</code></strong> :&ensp;<code>numeric</code></dt>
<dd>Time point</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_intermediate_timepoint(self, ridx: int, t: float) -&gt; bool:
    &#39;&#39;&#39;Checks if the given time `t` for subject index `ridx` is
    an intermediate time point or not

    Parameters
    ----------
    ridx : int
        Replicate index
    t : numeric
        Time point

    Returns
    -------
    bool
    &#39;&#39;&#39;
    return t not in self._given_timepoints_set[ridx]</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.is_timepoint_structural_zero"><code class="name flex">
<span>def <span class="ident">is_timepoint_structural_zero</span></span>(<span>self, ridx:Â int, tidx:Â int, aidx:Â int) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Returns True if the replicate index <code>ridx</code>, timepoint index <code>tidx</code>, and
Taxa index <code>aidx</code> is a structural zero or not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_timepoint_structural_zero(self, ridx: int, tidx: int, aidx: int) -&gt; bool:
    &#39;&#39;&#39;Returns True if the replicate index `ridx`, timepoint index `tidx`, and
    Taxa index `aidx` is a structural zero or not
    &#39;&#39;&#39;
    if self.zero_inflation_transition_policy is None:
        raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
            &#39;is not set during initialization&#39;)
    return self._structural_zeros[ridx][aidx, tidx]</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.iter_for_building"><code class="name flex">
<span>def <span class="ident">iter_for_building</span></span>(<span>self) â€‘>Â Tuple[int,Â int,Â int]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iter_for_building(self) -&gt; Tuple[int, int, int]:
    for ridx in range(self.n_replicates):
        for tidx in range(self.n_dts_for_replicate[ridx]):
            for oidx in range(len(self.taxa)):
                yield oidx, tidx, ridx</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.make_delta_t"><code class="name flex">
<span>def <span class="ident">make_delta_t</span></span>(<span>self, sqrt:Â boolÂ =Â False) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the whole delta_t vector for each time point.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sqrt</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, return the square root of the vector. Default is False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_delta_t(self, sqrt: bool=False) -&gt; np.ndarray:
    &#39;&#39;&#39;Returns the whole delta_t vector for each time point.

    Parameters
    ----------
    sqrt : bool
        If True, return the square root of the vector. Default is False
    &#39;&#39;&#39;
    if sqrt:
        return self.sqrt_dt_vec
    else:
        return self.dt_vec</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.set_timepoints"><code class="name flex">
<span>def <span class="ident">set_timepoints</span></span>(<span>self, times:Â numpy.ndarrayÂ =Â None, timestep:Â floatÂ =Â None, ridx:Â intÂ =Â None, eps:Â floatÂ =Â None, reset_timepoints:Â boolÂ =Â False)</span>
</code></dt>
<dd>
<div class="desc"><p>Set times if you want intermediate timepoints.</p>
<p>These are the time points that you want to generate the latent state at.
If there is a time in <code>times</code> that is not in the given data, then we set
it as an intermediate time point. You can specify the times that you
want either as a vector with <code>times</code> or with a constant time-step
with the interval <code>timestep</code>. Only one of them is necessary. It will crash
if both are supplied.</p>
<p><code>eps</code> is a radius around each of the given timepoints already supplied by
the data in <code>subjects</code> where no intermediate timepoints can be set.
If a timepoint that is set is within <code>eps</code> days of a timepoint already there,
then we skip adding that timepoint. If <code>eps</code> is None then we assume
that there is no constraint. </p>
<p>If <code>reset_timepoints</code> is True, then we delete the intermediate timepoints
that may have been added at a different time and use only these. If False
then the set of timepoints added at this call is adde to the set of
timepoints that were added at a previous call. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>array</code></dt>
<dd>These are the time points to set
If there are any time points not included in here but are included
with the given data then we automatically add them in. If there
are any time points in times that are already in the given data,
it is automatically set as a given time point
You need to provide this argument if you are not providing <code>timestep</code></dd>
<dt><strong><code>timestep</code></strong> :&ensp;<code>float, int</code></dt>
<dd>This is the time steps to generate the times at until the last time
at every replicate.
A data point will only be added if there is not already a datapoint
at that time. This is only necessary if you did not pass in <code>times</code></dd>
<dt><strong><code>ridx</code></strong> :&ensp;<code>int, Optional</code></dt>
<dd>If this is given, then we only set these times for the given
replicate index. If nothing is specified then we set the time points
for all of the replicates.</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>numeric, None</code></dt>
<dd>If an intermediate timestep is within <code>eps</code> days of a given timepoint
then we do not add it. If None then there is no restriction to how close
the intermediate timepoint can be.</dd>
<dt><strong><code>reset_timepoints</code></strong> :&ensp;<code>bool</code></dt>
<dd>If this is True then we delete the previous added intermediate timepoints.
If False then we add the set of timepoints added at this call with the
intermediate timepoints from a previous call.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_timepoints(self, times: np.ndarray=None, timestep: float=None, ridx: int=None, 
    eps: float=None, reset_timepoints: bool=False):
    &#39;&#39;&#39;Set times if you want intermediate timepoints.
    
    These are the time points that you want to generate the latent state at.
    If there is a time in `times` that is not in the given data, then we set
    it as an intermediate time point. You can specify the times that you 
    want either as a vector with `times` or with a constant time-step
    with the interval `timestep`. Only one of them is necessary. It will crash
    if both are supplied.

    `eps` is a radius around each of the given timepoints already supplied by
    the data in `subjects` where no intermediate timepoints can be set.
    If a timepoint that is set is within `eps` days of a timepoint already there,
    then we skip adding that timepoint. If `eps` is None then we assume
    that there is no constraint. 

    If `reset_timepoints` is True, then we delete the intermediate timepoints
    that may have been added at a different time and use only these. If False
    then the set of timepoints added at this call is adde to the set of 
    timepoints that were added at a previous call. 

    Parameters
    ----------
    times : array
        These are the time points to set
        If there are any time points not included in here but are included
        with the given data then we automatically add them in. If there
        are any time points in times that are already in the given data,
        it is automatically set as a given time point
        You need to provide this argument if you are not providing `timestep`
    timestep : float, int
        This is the time steps to generate the times at until the last time
        at every replicate.
        A data point will only be added if there is not already a datapoint
        at that time. This is only necessary if you did not pass in `times`
    ridx : int, Optional
        If this is given, then we only set these times for the given
        replicate index. If nothing is specified then we set the time points
        for all of the replicates.
    eps : numeric, None
        If an intermediate timestep is within `eps` days of a given timepoint
        then we do not add it. If None then there is no restriction to how close
        the intermediate timepoint can be.
    reset_timepoints : bool
        If this is True then we delete the previous added intermediate timepoints.
        If False then we add the set of timepoints added at this call with the
        intermediate timepoints from a previous call.
    &#39;&#39;&#39;
    if (times is None and timestep is None) or (times is not None and timestep is not None):
        raise ValueError(&#39;Either `times` or `timestep` must be provided&#39;)
    if not pl.isbool(reset_timepoints):
        raise TypeError(&#39;`reset_timepoints` ({}) must be a bool&#39;.format(
            type(reset_timepoints)))
    if ridx is not None:
        if not pl.isint(ridx):
            raise ValueError(&#39;`ridx` ({}) must be an int&#39;.format(type(ridx)))
        ridxs = [ridx]
    else:
        ridxs = np.arange(self.n_replicates)
    
    if timestep is not None:
        if not pl.isnumeric(timestep):
            raise ValueError(&#39;`timestep` ({}) must be a numeric&#39;.format(type(timestep)))
        # get the earliest start and the latest end
        start = float(&#39;inf&#39;)
        end = -1
        for ts in self.times:
            if start &gt; ts[0]:
                start = ts[0]
            if end &lt; ts[-1]:
                end = ts[-1]
        times = np.arange(start,end,timestep)
    if not pl.isarray(times):
        raise ValueError(&#39;`times` ({}) must be an array&#39;.format(type(times)))
    
    if eps is not None:
        if not pl.isnumeric(eps):
            raise TypeError(&#39;`eps` ({}) must be a numeric&#39;.format(type(eps)))
        if eps &lt; 0:
            raise ValueError(&#39;`eps` ({}) must be &gt;= 0&#39;.format(eps))
        
    for ridx in ridxs:
        if reset_timepoints:
            new_times = np.array(self.given_timepoints[ridx])
        else:
            new_times = np.array(self.times[ridx])

        n_added = 0
        for t in times:
            if t not in new_times:
                # Check if the datapoint is within `eps` of real data
                # Get the surrounding timepoints
                if eps is None:
                    n_added += 1
                    new_times = np.append(new_times, t)
                else:
                    smallest_big = float(&#39;-inf&#39;)
                    largest_small = float(&#39;inf&#39;)
                    for tt in new_times:
                        if tt &lt; t and tt &gt; largest_small:
                            largest_small = tt
                        elif tt &gt; t and tt &lt; smallest_big:
                            smallest_big = tt
                    if np.min([t-largest_small, smallest_big-t]) &lt; eps:
                        n_added += 1
                        new_times = np.append(new_times, t)
                    
        sorted_tidxs = np.argsort(new_times)
        self.times[ridx] = new_times[sorted_tidxs]
        if reset_timepoints:
            self.data[ridx] = np.hstack((
                self.abs_data[ridx], 
                np.zeros(shape=(self.n_taxa, n_added))*np.nan))
        else:
            self.data[ridx] = np.hstack((
                self.data[ridx],
                np.zeros(shape=(self.n_taxa, n_added)) * np.nan))
        self.data[ridx] = self.data[ridx][:,sorted_tidxs]
        self.n_timepoints_for_replicate[ridx] = len(self.times[ridx])
        self.n_dts_for_replicate[ridx] = len(self.times[ridx])-1

        # redo `given_timeindices`
        self.given_timeindices[ridx] = OrderedSet()
        for tidx in range(len(self.times[ridx])):
            if self.times[ridx][tidx] in self._given_timepoints_set[ridx]:
                self.given_timeindices[ridx].add(tidx)

        # redo `data_timeindex2given_timeindex` - first delete all ones that
        # have that as the replicate and then add the new oens
        new_d = {}
        for aaa,bbb in self.data_timeindex2given_timeindex:
            if aaa == ridx:
                continue
            new_d[(aaa,bbb)] = self.data_timeindex2given_timeindex[(aaa,bbb)]
        self.data_timeindex2given_timeindex = new_d

        given_times = self.given_timepoints[ridx]
        for tidx in range(self.n_timepoints_for_replicate[ridx]):
            if tidx in self.given_timeindices[ridx]:
                # Get index where the time occurs in the given times
                t = self.times[ridx][tidx]
                found = False
                for i in range(len(given_times)):
                    if t == given_times[i]:
                        found = True
                        self.data_timeindex2given_timeindex[(ridx,tidx)] = i
                        break
                if not found:
                    raise ValueError(&#39;Not found - something is wrong&#39;)

            else:
                self.data_timeindex2given_timeindex[(ridx,tidx)] = np.nan

        # Redo the reverse indexing
        self.timepoint2index[ridx] = {}
        for tidx,t in enumerate(self.times[ridx]):
            self.timepoint2index[ridx][t] = tidx

        # redo `dt`
        self.dt[ridx] = np.zeros(self.n_timepoints_for_replicate[ridx]-1)
        for k in range(len(self.dt[ridx])):
            self.dt[ridx][k] = self.times[ridx][k+1] - self.times[ridx][k]

    # redo dt_vec
    n = 0
    for ridx in range(self.n_replicates):
        n += len(self.dt[ridx])
    n *= self.n_taxa
    n_taxa = self.n_taxa
    self.dt_vec = np.zeros(n)
    i = 0
    for ridx in range(self.n_replicates):
        for t in self.dt[ridx]:
            self.dt_vec[i:i+n_taxa] = t
            i += n_taxa
    self.sqrt_dt_vec = np.sqrt(self.dt_vec)

    self.total_n_timepoints_per_taxa = 0
    self.total_n_dts_per_taxa = 0
    for nt in self.n_timepoints_for_replicate:
        self.total_n_timepoints_per_taxa += nt
        self.total_n_dts_per_taxa += (nt - 1)


    # redo tidx arrays for perturbations if necessary
    if self.tidxs_in_perturbation is not None:
        self.tidxs_in_perturbation = []
        for ridx, subj in enumerate(self.subjects):
            self.tidxs_in_perturbation.append([])
            for perturbation in self.subjects.perturbations:
                start = perturbation.starts[subj.name]
                end = perturbation.ends[subj.name]

                if start in self.timepoint2index[ridx]:
                    # There is a measurement at the start of the perturbation
                    start_idx = self.timepoint2index[ridx][start]
                else:
                    # There is no measurement at the start of the perturbation.
                    # Get the next timepoint
                    start_idx = np.searchsorted(self.times[ridx], start)
                
                if end in self.timepoint2index[ridx]:
                    # There is a measurement at the end of the perturbation
                    end_idx = self.timepoint2index[ridx][end]
                else:
                    # There is no measurement at the end of the perturbation
                    # Get the previous timepoint
                    end_idx = np.searchsorted(self.times[ridx], end) - 1

                # Check if anything is weird
                start_idx = int(start_idx)
                end_idx = int(end_idx)
                if start_idx &gt; end_idx:
                    # raise ValueError(&#39;end time index ({}) of a perturbation less&#39; \
                    #     &#39; than the start index ({})?&#39;.format(end_idx, start_idx))
                    self.tidxs_in_perturbation[ridx].append((None, None))
                if start_idx == end_idx:
                    self.tidxs_in_perturbation[ridx].append((start_idx, start_idx + 1))
                else:
                    self.tidxs_in_perturbation[ridx].append((start_idx, end_idx))</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.set_zero_inflation"><code class="name flex">
<span>def <span class="ident">set_zero_inflation</span></span>(<span>self, turn_on:Â Iterator[Tuple[int,Â int,Â int]]Â =Â None, turn_off:Â Iterator[Tuple[int,Â int,Â int]]Â =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Set which timepoints taxa are set to be turned off. Any taxa, timepoints tuple
not in <code>d</code> is assumed to be "present" (a nonn-structural zero). <code>d</code> is an array
of 3-tuples, where:
(ridx, tidx, aidx)
ridx: replicate index (not the same as replicate name)
tidx: timepoint index (not the same as timepoint)
aidx: Taxa index (not the same as Taxa name)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>turn_on</code></strong> :&ensp;<code>list(3-tuple)</code></dt>
<dd>A list of ridx, tidx, aidx to set to being present</dd>
<dt><strong><code>turn_on</code></strong> :&ensp;<code>list(3-tuple)</code></dt>
<dd>A list of ridx, tidx, aidx to set to a structural zero</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_zero_inflation(self, turn_on: Iterator[Tuple[int, int, int]]=None, 
    turn_off: Iterator[Tuple[int, int, int]]=None):
    &#39;&#39;&#39;Set which timepoints taxa are set to be turned off. Any taxa, timepoints tuple
    not in `d` is assumed to be &#34;present&#34; (a nonn-structural zero). `d` is an array
    of 3-tuples, where:
        (ridx, tidx, aidx)
            ridx: replicate index (not the same as replicate name)
            tidx: timepoint index (not the same as timepoint)
            aidx: Taxa index (not the same as Taxa name)
    
    Parameters
    ----------
    turn_on : list(3-tuple)
        A list of ridx, tidx, aidx to set to being present
    turn_on : list(3-tuple)
        A list of ridx, tidx, aidx to set to a structural zero
    &#39;&#39;&#39;
    if self.zero_inflation_transition_policy is None:
        # raise ValueError(&#39;Cannot set set the zero infation if `zero_inflation_transition_policy` &#39; \
        #     &#39;is not set during initialization&#39;)
        logging.warning(&#39;`zero_inflation_transition_policy` is None so we are not doing anything&#39;)
        return
    if turn_on is not None:
        for i, (ridx,tidx,aidx) in enumerate(turn_on):
            if ridx &gt; self.n_replicates or ridx &lt; 0:
                raise ValueError(&#39;ridx ({}) in index `{}` ({}) is out of range. Only {} replicates&#39;.format(
                    ridx, i, (ridx,tidx,aidx), self.n_replicates))
            if tidx &gt; self.n_timepoints_for_replicate[ridx] or tidx &lt; 0:
                raise ValueError(&#39;tidx ({}) in index `{}` ({}) is out of range. Only {} timepoints in replicate {}&#39;.format(
                    tidx, i, (ridx,tidx,aidx), self.n_timepoints_for_replicate[ridx], ridx))
            if aidx &gt; len(self.taxa) or aidx &lt; 0:
                raise ValueError(&#39;aidx ({}) in index `{}` ({}) is out of range. Only {} s&#39;.format(
                    aidx, i, (ridx,tidx,aidx), len(self.taxa)))

            self._structural_zeros[ridx][aidx,tidx] = False

    if turn_off is not None:
        for i, (ridx,tidx,aidx) in enumerate(turn_off):
            if ridx &gt; self.n_replicates or ridx &lt; 0:
                raise ValueError(&#39;ridx ({}) in index `{}` ({}) is out of range. Only {} replicates&#39;.format(
                    ridx, i, (ridx,tidx,aidx), self.n_replicates))
            if tidx &gt; self.n_timepoints_for_replicate[ridx] or tidx &lt; 0:
                raise ValueError(&#39;tidx ({}) in index `{}` ({}) is out of range. Only {} timepoints in replicate {}&#39;.format(
                    tidx, i, (ridx,tidx,aidx), self.n_timepoints_for_replicate[ridx], ridx))
            if aidx &gt; len(self.taxa) or aidx &lt; 0:
                raise ValueError(&#39;aidx ({}) in index `{}` ({}) is out of range. Only {} s&#39;.format(
                    aidx, i, (ridx,tidx,aidx), len(self.taxa)))

            self._structural_zeros[ridx][aidx,tidx] = True
    self._setrows_to_include_zero_inflation()</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.Data.update_values"><code class="name flex">
<span>def <span class="ident">update_values</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the values of the data (because the latent state changed)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_values(self):
    &#39;&#39;&#39;Update the values of the data (because the latent state changed)
    &#39;&#39;&#39;
    self.lhs.update_value()
    for key in self.toupdate:
        self.design_matrices[key].update_value()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.graph.DataNode" href="pylab/graph.html#mdsine2.pylab.graph.DataNode">DataNode</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.graph.DataNode.delete" href="pylab/graph.html#mdsine2.pylab.graph.DataNode.delete">delete</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.DesignMatrix"><code class="flex name class">
<span>class <span class="ident">DesignMatrix</span></span>
<span>(</span><span>varname:Â str, G:Â <a title="mdsine2.pylab.graph.Graph" href="pylab/graph.html#mdsine2.pylab.graph.Graph">Graph</a>, update:Â boolÂ =Â False, add_to_dict:Â boolÂ =Â True)</span>
</code></dt>
<dd>
<div class="desc"><p>This is a covariate class</p>
<p>Parameters</p>
<p>varname (str)
- This is the name of the variable we are building it for
update (bool)
- If True, this matrix gets updated when Data.update_values() is
called.
add_to_dict (bool)
- If True, it adds to the design_matrices dictionary.
- Else it does not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DesignMatrix:
    &#39;&#39;&#39;This is a covariate class
    &#39;&#39;&#39;
    def __init__(self, varname: str, G: Graph, update: bool=False, add_to_dict: bool=True):
        &#39;&#39;&#39;Parameters

        varname (str)
            - This is the name of the variable we are building it for
        update (bool)
            - If True, this matrix gets updated when Data.update_values() is
              called.
        add_to_dict (bool)
            - If True, it adds to the design_matrices dictionary.
            - Else it does not
        &#39;&#39;&#39;

        name = varname + &#39;_design_matrix&#39;
        self.name = name
        self.G = G
        self.varname = varname
        if add_to_dict:
            self.G.data.design_matrices[varname] = self
        self.matrix = None
        if update:
            self.G.data.toupdate.add(varname)

    def build(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def set_to_lhs(self):
        &#39;&#39;&#39;Multiply the current value of the var with the current matrix
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def update_value(self):
        &#39;&#39;&#39;This updates the data for each design matrix
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def toarray(self, dest: np.ndarray=None, T: bool=False) -&gt; np.ndarray:
        &#39;&#39;&#39;Converts `self.matrix` into a C_CONTIGUOUS numpy matrix if 
        the matrix is sparse. If it is not sparse then it just returns
        the matrix.

        Parameters
        ----------
        dest : np.ndarray
            If this is specified, send the array into this array. Assumes
            the shapes are compatible. Else create a new array
        T : bool
            If True, set the transpose

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        return pl.toarray(self.matrix, dest=dest, T=T)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.GrowthDesignMatrix" href="#mdsine2.design_matrices.GrowthDesignMatrix">GrowthDesignMatrix</a></li>
<li><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix">InteractionsBaseDesignMatrix</a></li>
<li><a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a></li>
<li><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix">InteractionsMixingDesignMatrix</a></li>
<li><a title="mdsine2.design_matrices.PerturbationBaseDesignMatrix" href="#mdsine2.design_matrices.PerturbationBaseDesignMatrix">PerturbationBaseDesignMatrix</a></li>
<li><a title="mdsine2.design_matrices.PerturbationDesignMatrix" href="#mdsine2.design_matrices.PerturbationDesignMatrix">PerturbationDesignMatrix</a></li>
<li><a title="mdsine2.design_matrices.PerturbationMixingDesignMatrix" href="#mdsine2.design_matrices.PerturbationMixingDesignMatrix">PerturbationMixingDesignMatrix</a></li>
<li><a title="mdsine2.design_matrices.SelfInteractionDesignMatrix" href="#mdsine2.design_matrices.SelfInteractionDesignMatrix">SelfInteractionDesignMatrix</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.DesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.DesignMatrix.set_to_lhs"><code class="name flex">
<span>def <span class="ident">set_to_lhs</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Multiply the current value of the var with the current matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_lhs(self):
    &#39;&#39;&#39;Multiply the current value of the var with the current matrix
    &#39;&#39;&#39;
    raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.DesignMatrix.toarray"><code class="name flex">
<span>def <span class="ident">toarray</span></span>(<span>self, dest:Â numpy.ndarrayÂ =Â None, T:Â boolÂ =Â False) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Converts <code>self.matrix</code> into a C_CONTIGUOUS numpy matrix if
the matrix is sparse. If it is not sparse then it just returns
the matrix.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dest</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>If this is specified, send the array into this array. Assumes
the shapes are compatible. Else create a new array</dd>
<dt><strong><code>T</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, set the transpose</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def toarray(self, dest: np.ndarray=None, T: bool=False) -&gt; np.ndarray:
    &#39;&#39;&#39;Converts `self.matrix` into a C_CONTIGUOUS numpy matrix if 
    the matrix is sparse. If it is not sparse then it just returns
    the matrix.

    Parameters
    ----------
    dest : np.ndarray
        If this is specified, send the array into this array. Assumes
        the shapes are compatible. Else create a new array
    T : bool
        If True, set the transpose

    Returns
    -------
    np.ndarray
    &#39;&#39;&#39;
    return pl.toarray(self.matrix, dest=dest, T=T)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.DesignMatrix.update_value"><code class="name flex">
<span>def <span class="ident">update_value</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This updates the data for each design matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_value(self):
    &#39;&#39;&#39;This updates the data for each design matrix
    &#39;&#39;&#39;
    raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.design_matrices.GrowthDesignMatrix"><code class="flex name class">
<span>class <span class="ident">GrowthDesignMatrix</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the design matrix for the growth</p>
<p>We need two different matrices for growth, depending on if we are conditioning on the
perturbations or not. If we are setting the growth to the RHS, that means
that we are trying to learn the growth values and we have to keep the
perturbation parameters fixed, so:
a_1 * (1 + \gamma)
we need to put the perturbation parameters on the rhs matrix factored into the data matrix</p>
<p>If we are putting the growth on the LHS, that means that we are either
trying to learn the perturbations or we are marginalizing over the parameters
dependent on the cluster assignments:
a_1 + \gamma * a_1
&mdash;
The underlined part goes to the LHS.</p>
<p>If there are no perturbations, the rhs and the lhs are equal and are set to
the parameterization of the LHS</p>
<p>We build this matrix as a scipy sparse matrix, then convert it to a
numpy array if necessary. Since the shape of the sparse matrix does
not change during inference, we can premake the rows and columns during initialization,
which is done below.</p>
<p>Parameters</p>
<p>varname (str)
- This is the name of the variable we are building it for
update (bool)
- If True, this matrix gets updated when Data.update_values() is
called.
add_to_dict (bool)
- If True, it adds to the design_matrices dictionary.
- Else it does not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GrowthDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Builds the design matrix for the growth

    We need two different matrices for growth, depending on if we are conditioning on the
    perturbations or not. If we are setting the growth to the RHS, that means
    that we are trying to learn the growth values and we have to keep the
    perturbation parameters fixed, so:
        a_1 * (1 + \\gamma)
    we need to put the perturbation parameters on the rhs matrix factored into the data matrix

    If we are putting the growth on the LHS, that means that we are either
    trying to learn the perturbations or we are marginalizing over the parameters
    dependent on the cluster assignments:
        a_1 + \\gamma * a_1
        ---
    The underlined part goes to the LHS.

    If there are no perturbations, the rhs and the lhs are equal and are set to
    the parameterization of the LHS

    We build this matrix as a scipy sparse matrix, then convert it to a 
    numpy array if necessary. Since the shape of the sparse matrix does
    not change during inference, we can premake the rows and columns during initialization,
    which is done below.
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.GROWTH_VALUE, update=True, **kwargs)
        self.n_cols_master = self.G.data.n_taxa # int
        total_n_dts = self.G.data.total_n_dts_per_taxa # int
        self.n_rows_master = self.n_cols_master * total_n_dts # int
        self.master_rows = np.arange(self.n_rows_master, dtype=int) 
        self.master_cols = np.kron(
                np.ones(total_n_dts, dtype=int),
                np.arange(self.G.data.n_taxa,dtype=int))
        logging.info(&#39;Initializing growth design matrix&#39;)

    def build(self):
        &#39;&#39;&#39;Build RHS matrices with perturbations multiplied in and not multiplied in.
        &#39;&#39;&#39;
        self.build_without_perturbations()
        self.build_with_perturbations()

    def build_without_perturbations(self):
        &#39;&#39;&#39;Builds the matrix without perturbations factored in.
        &#39;&#39;&#39;
        self.cols = self.master_cols
        self.rows = self.master_rows
        self.data = np.ones(self.n_rows_master, dtype=float)

        shape = (self.n_rows_master, self.n_cols_master)

        self.matrix_without_perturbations = scipy.sparse.coo_matrix(
            (self.data,(self.rows,self.cols)), shape=shape).tocsc()
        
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix_without_perturbations = self.matrix_without_perturbations[self.G.data.rows_to_include_zero_inflation, :]

    def build_with_perturbations(self):
        &#39;&#39;&#39;Incorporate perturbation factors while building the data structure.

        a_1 * (1 + \\gamma) * x_k

        How perturbations are switched on/off:
        ------------------------------------------------------------------------
        &#39;The time ahead prediction must be included in the perturbation&#39; - Travis

        Example: Pertubtion period (2,5) - this is **3** doses

        ```
                           |--&gt;|--&gt;|--&gt;|
        perturbation on    #############
        Days           1   2   3   4   5   6
        ```

        `d1` indicates the perturbation parameter that gets added for the day that it
        should be included in.

        * x2 = x1 + ...
        * x3 = x2 + ... + d1
        * x4 = x3 + ... + d1
        * x5 = x4 + ... + d1
        * x6 = x5 + ...

        The perturbation periods that are given are in the format (start, end).
        For the above example our perturbation period would be (2, 5). Thus, we should do
        inclusion/exclusion brackets such that:
        &#39;&#39;&#39;
        self.cols = self.master_cols
        self.rows = self.master_rows

        if self.G.perturbations is None:
            self.matrix_with_perturbations = None
            return

        self.data_w_perts = np.zeros(self.n_rows_master, dtype=float)
        d = []
        for ridx in range(self.G.data.n_replicates):
            d.append(np.ones(shape=self.G.data.data[ridx].shape))

        for pidx, pert in enumerate(self.G.perturbations):
            val = (pert.item_array(only_pos_ind=True) + 1).reshape(-1,1)
            oidxs = pert.indicator.item_arg_array()

            for ridx in range(self.G.data.n_replicates):
                start,end = self.G.data.tidxs_in_perturbation[ridx][pidx]
                if len(oidxs) &gt; 0:
                    d[ridx][oidxs, start:end] *= val
        i = 0
        for ridx in range(self.G.data.n_replicates):
            l = (self.G.data.n_dts_for_replicate[ridx]) * self.G.data.n_taxa
            self.data_w_perts[i:i+l] = d[ridx][:,:-1].ravel(&#39;F&#39;)
            i += l

        shape = (self.n_rows_master, self.n_cols_master)
        self.matrix_with_perturbations = scipy.sparse.coo_matrix(
            (self.data_w_perts,(self.rows,self.cols)), shape=shape).tocsc()
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix_with_perturbations = \
                self.matrix_with_perturbations[self.G.data.rows_to_include_zero_inflation, :]
            self.matrix_with_perturbations = self.matrix_with_perturbations.tocsc()

    def set_to_lhs(self, with_perturbations: bool) -&gt; np.ndarray:
        &#39;&#39;&#39;Multiply the design matrix by the current value of
        growth
        &#39;&#39;&#39;
        if not pl.isbool(with_perturbations):
            raise ValueError(&#39;`with_perturbations` ({}) must be a bool&#39;.format(
                type(with_perturbations)))
        if with_perturbations:
            matrix = self.matrix_with_perturbations
        else:
            matrix = self.matrix_without_perturbations
        b = self.G[self.varname].value.reshape(-1,1)
        return matrix.dot(b)

    def set_to_rhs(self, with_perturbations: bool) -&gt; scipy.sparse.spmatrix:
        &#39;&#39;&#39;If `with_perturbations` is True, we return the matrix with the
        perturbation factors incorporated. If False we return the matrix
        without perturbations
        &#39;&#39;&#39;
        if not pl.isbool(with_perturbations):
            raise ValueError(&#39;`with_perturbations` ({}) must be a bool&#39;.format(
                type(with_perturbations)))
        if with_perturbations:
            matrix = self.matrix_with_perturbations
        else:
            matrix = self.matrix_without_perturbations
        return matrix

    def update_value(self):
        self.build()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.GrowthDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Build RHS matrices with perturbations multiplied in and not multiplied in.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    &#39;&#39;&#39;Build RHS matrices with perturbations multiplied in and not multiplied in.
    &#39;&#39;&#39;
    self.build_without_perturbations()
    self.build_with_perturbations()</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.GrowthDesignMatrix.build_with_perturbations"><code class="name flex">
<span>def <span class="ident">build_with_perturbations</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Incorporate perturbation factors while building the data structure.</p>
<p>a_1 * (1 + \gamma) * x_k</p>
<h2 id="how-perturbations-are-switched-onoff">How perturbations are switched on/off:</h2>
<p>'The time ahead prediction must be included in the perturbation' - Travis</p>
<p>Example: Pertubtion period (2,5) - this is <strong>3</strong> doses</p>
<pre><code>                   |--&gt;|--&gt;|--&gt;|
perturbation on    #############
Days           1   2   3   4   5   6
</code></pre>
<p><code>d1</code> indicates the perturbation parameter that gets added for the day that it
should be included in.</p>
<ul>
<li>x2 = x1 + &hellip;</li>
<li>x3 = x2 + &hellip; + d1</li>
<li>x4 = x3 + &hellip; + d1</li>
<li>x5 = x4 + &hellip; + d1</li>
<li>x6 = x5 + &hellip;</li>
</ul>
<p>The perturbation periods that are given are in the format (start, end).
For the above example our perturbation period would be (2, 5). Thus, we should do
inclusion/exclusion brackets such that:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_with_perturbations(self):
    &#39;&#39;&#39;Incorporate perturbation factors while building the data structure.

    a_1 * (1 + \\gamma) * x_k

    How perturbations are switched on/off:
    ------------------------------------------------------------------------
    &#39;The time ahead prediction must be included in the perturbation&#39; - Travis

    Example: Pertubtion period (2,5) - this is **3** doses

    ```
                       |--&gt;|--&gt;|--&gt;|
    perturbation on    #############
    Days           1   2   3   4   5   6
    ```

    `d1` indicates the perturbation parameter that gets added for the day that it
    should be included in.

    * x2 = x1 + ...
    * x3 = x2 + ... + d1
    * x4 = x3 + ... + d1
    * x5 = x4 + ... + d1
    * x6 = x5 + ...

    The perturbation periods that are given are in the format (start, end).
    For the above example our perturbation period would be (2, 5). Thus, we should do
    inclusion/exclusion brackets such that:
    &#39;&#39;&#39;
    self.cols = self.master_cols
    self.rows = self.master_rows

    if self.G.perturbations is None:
        self.matrix_with_perturbations = None
        return

    self.data_w_perts = np.zeros(self.n_rows_master, dtype=float)
    d = []
    for ridx in range(self.G.data.n_replicates):
        d.append(np.ones(shape=self.G.data.data[ridx].shape))

    for pidx, pert in enumerate(self.G.perturbations):
        val = (pert.item_array(only_pos_ind=True) + 1).reshape(-1,1)
        oidxs = pert.indicator.item_arg_array()

        for ridx in range(self.G.data.n_replicates):
            start,end = self.G.data.tidxs_in_perturbation[ridx][pidx]
            if len(oidxs) &gt; 0:
                d[ridx][oidxs, start:end] *= val
    i = 0
    for ridx in range(self.G.data.n_replicates):
        l = (self.G.data.n_dts_for_replicate[ridx]) * self.G.data.n_taxa
        self.data_w_perts[i:i+l] = d[ridx][:,:-1].ravel(&#39;F&#39;)
        i += l

    shape = (self.n_rows_master, self.n_cols_master)
    self.matrix_with_perturbations = scipy.sparse.coo_matrix(
        (self.data_w_perts,(self.rows,self.cols)), shape=shape).tocsc()
    if self.G.data.zero_inflation_transition_policy is not None:
        self.matrix_with_perturbations = \
            self.matrix_with_perturbations[self.G.data.rows_to_include_zero_inflation, :]
        self.matrix_with_perturbations = self.matrix_with_perturbations.tocsc()</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.GrowthDesignMatrix.build_without_perturbations"><code class="name flex">
<span>def <span class="ident">build_without_perturbations</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the matrix without perturbations factored in.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_without_perturbations(self):
    &#39;&#39;&#39;Builds the matrix without perturbations factored in.
    &#39;&#39;&#39;
    self.cols = self.master_cols
    self.rows = self.master_rows
    self.data = np.ones(self.n_rows_master, dtype=float)

    shape = (self.n_rows_master, self.n_cols_master)

    self.matrix_without_perturbations = scipy.sparse.coo_matrix(
        (self.data,(self.rows,self.cols)), shape=shape).tocsc()
    
    if self.G.data.zero_inflation_transition_policy is not None:
        self.matrix_without_perturbations = self.matrix_without_perturbations[self.G.data.rows_to_include_zero_inflation, :]</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.GrowthDesignMatrix.set_to_lhs"><code class="name flex">
<span>def <span class="ident">set_to_lhs</span></span>(<span>self, with_perturbations:Â bool) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Multiply the design matrix by the current value of
growth</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_lhs(self, with_perturbations: bool) -&gt; np.ndarray:
    &#39;&#39;&#39;Multiply the design matrix by the current value of
    growth
    &#39;&#39;&#39;
    if not pl.isbool(with_perturbations):
        raise ValueError(&#39;`with_perturbations` ({}) must be a bool&#39;.format(
            type(with_perturbations)))
    if with_perturbations:
        matrix = self.matrix_with_perturbations
    else:
        matrix = self.matrix_without_perturbations
    b = self.G[self.varname].value.reshape(-1,1)
    return matrix.dot(b)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.GrowthDesignMatrix.set_to_rhs"><code class="name flex">
<span>def <span class="ident">set_to_rhs</span></span>(<span>self, with_perturbations:Â bool) â€‘>Â scipy.sparse.base.spmatrix</span>
</code></dt>
<dd>
<div class="desc"><p>If <code>with_perturbations</code> is True, we return the matrix with the
perturbation factors incorporated. If False we return the matrix
without perturbations</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_rhs(self, with_perturbations: bool) -&gt; scipy.sparse.spmatrix:
    &#39;&#39;&#39;If `with_perturbations` is True, we return the matrix with the
    perturbation factors incorporated. If False we return the matrix
    without perturbations
    &#39;&#39;&#39;
    if not pl.isbool(with_perturbations):
        raise ValueError(&#39;`with_perturbations` ({}) must be a bool&#39;.format(
            type(with_perturbations)))
    if with_perturbations:
        matrix = self.matrix_with_perturbations
    else:
        matrix = self.matrix_without_perturbations
    return matrix</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.InteractionsBaseDesignMatrix"><code class="flex name class">
<span>class <span class="ident">InteractionsBaseDesignMatrix</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the base data for the design matrix of the interactions.</p>
<p>This builds the interaction matrix for each <strong>Taxa-Taxa</strong> interaction as if there
were no indicators. Note that this is not what is used during inference - we multiply
this matrix by the mixing matrix.</p>
<h2 id="see-also">See Also</h2>
<p><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix">InteractionsMixingDesignMatrix</a></code>
<code><a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a></code></p>
<p><code>Parameters</code></p>
<p><code>varname (str) - This is the name of the variable we are building it for</code>
<code>update (bool) - If True</code>, <code>this matrix gets updated when <a title="mdsine2.design_matrices.Data.update_values" href="#mdsine2.design_matrices.Data.update_values">Data.update_values()</a> is called.</code>
<code>add_to_dict (bool) - If True</code>, <code>it adds to the design_matrices dictionary. - Else it does not</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InteractionsBaseDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This is the base data for the design matrix of the interactions.

    This builds the interaction matrix for each __Taxa-Taxa__ interaction as if there
    were no indicators. Note that this is not what is used during inference - we multiply 
    this matrix by the mixing matrix.

    See Also
    --------
    mdsine2.design_matrices.InteractionsMixingDesignMatrix
    mdsine2.design_matrices.InteractionsDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        name = STRNAMES.CLUSTER_INTERACTION_VALUE+&#39;_base_data&#39;
        DesignMatrix.__init__(self,varname=name, **kwargs)

        # Initialize and set up rows and cols for base matrix
        total_n_dts = self.G.data.total_n_dts_per_taxa # int

        n_taxa = self.G.data.n_taxa # int
        self.n_rows = int(n_taxa * total_n_dts) # int
        self.n_cols = int(n_taxa * (n_taxa - 1)) # int
        self.shape = (self.n_rows, self.n_cols)

        self.master_rows = np.kron(
                np.arange(self.n_rows, dtype=int),
                np.ones(n_taxa-1, dtype=int))
        self.master_cols = np.kron(
            np.ones(total_n_dts, dtype=int),
            np.arange(self.n_cols, dtype=int))

        self.master_data = np.zeros(len(self.master_cols))
        logging.info(&#39;Initializing interactions base design matrix&#39;)

    # @profile
    def build(self):
        &#39;&#39;&#39;Build the base matrix
        &#39;&#39;&#39;
        n_taxa = self.G.data.n_taxa
        data = self.G.data.data

        self.rows = self.master_rows
        self.cols = self.master_cols
        self.data = self.master_data

        i = 0
        for ridx in range(self.G.data.n_replicates):
            i = InteractionsBaseDesignMatrix._fast_build(
                ret=self.master_data, data=data[ridx], n_taxa=n_taxa,
                n_dts=self.G.data.n_dts_for_replicate[ridx], i=i)
            
        if self.G.data.zero_inflation_transition_policy is not None:
            # All of the rows that need to be taken out will be taken out. All of the 
            # remaining nans in the matrix are effects of a structural zero on a non-structural
            # zero - making a nan. We can set this to zero because if this is the case we can say 
            # this means &#34;no effect&#34;
            self.master_data[np.isnan(self.master_data)] = 0
        else:
            if np.any(np.isnan(self.master_data)):
                raise ValueError(&#39;nans in matrix, this should not happen. check the values&#39;)
        self.matrix = scipy.sparse.coo_matrix(
            (self.master_data,(self.master_rows,self.master_cols)),shape=self.shape).tocsc()
        
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix = self.matrix[self.G.data.rows_to_include_zero_inflation, :]

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def _fast_build(ret: np.ndarray, data: np.ndarray, n_dts: int, n_taxa: int, i: int):
        &#39;&#39;&#39;About 99.5% faster than regular python looping
        &#39;&#39;&#39;
        for tidx in range(n_dts):
            for toidx in range(n_taxa):
                for soidx in range(n_taxa):
                    if toidx == soidx:
                        continue
                    ret[i] = data[soidx, tidx]
                    i = i + 1
        return i

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def _fast_build_zi_ignore(ret: np.ndarray, data: np.ndarray, n_dts: int, n_taxa: int, i: int, 
        zero_inflation: np.ndarray, zi_mask: np.ndarray):
        &#39;&#39;&#39;About 99.5% faster than regular python looping

        Only set to include if target taxa current timepoint and future timepoint are there and
        if the source taxa timepoint is there
        &#39;&#39;&#39;
        for tidx in range(n_dts):
            for toidx in range(n_taxa):
                for soidx in range(n_taxa):
                    if toidx == soidx:
                        continue

                    if not (zero_inflation[soidx, tidx] and zero_inflation[toidx, tidx] and \
                        zero_inflation[toidx, tidx+1]):
                        zi_mask[i] = False
                    else:
                        ret[i] = data[soidx, tidx]
                        zi_mask[i] = True
                    
                    i = i + 1
        return i

    def update_value(self):
        self.build()

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        return self.matrix</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.InteractionsBaseDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Build the base matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    &#39;&#39;&#39;Build the base matrix
    &#39;&#39;&#39;
    n_taxa = self.G.data.n_taxa
    data = self.G.data.data

    self.rows = self.master_rows
    self.cols = self.master_cols
    self.data = self.master_data

    i = 0
    for ridx in range(self.G.data.n_replicates):
        i = InteractionsBaseDesignMatrix._fast_build(
            ret=self.master_data, data=data[ridx], n_taxa=n_taxa,
            n_dts=self.G.data.n_dts_for_replicate[ridx], i=i)
        
    if self.G.data.zero_inflation_transition_policy is not None:
        # All of the rows that need to be taken out will be taken out. All of the 
        # remaining nans in the matrix are effects of a structural zero on a non-structural
        # zero - making a nan. We can set this to zero because if this is the case we can say 
        # this means &#34;no effect&#34;
        self.master_data[np.isnan(self.master_data)] = 0
    else:
        if np.any(np.isnan(self.master_data)):
            raise ValueError(&#39;nans in matrix, this should not happen. check the values&#39;)
    self.matrix = scipy.sparse.coo_matrix(
        (self.master_data,(self.master_rows,self.master_cols)),shape=self.shape).tocsc()
    
    if self.G.data.zero_inflation_transition_policy is not None:
        self.matrix = self.matrix[self.G.data.rows_to_include_zero_inflation, :]</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsBaseDesignMatrix.set_to_rhs"><code class="name flex">
<span>def <span class="ident">set_to_rhs</span></span>(<span>self) â€‘>Â scipy.sparse.base.spmatrix</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
    return self.matrix</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.DesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.InteractionsDesignMatrix"><code class="flex name class">
<span>class <span class="ident">InteractionsDesignMatrix</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the design matrix for the interactions:
- A_{i,j} @ M = A_{c_i,c_j}, where
- A_{i,j} is the <strong>Taxa-Taxa</strong> interaction matrix (self.base)
- M is the mixing matrix (self.M)
- A_{c_i,c_j} is the cluster-cluster interaction matrix</p>
<p>This matrix is composed of two, individual design matrices, <code>Base</code> and <code>M</code>.
To make the matrix that we use during inference, we matrix multiply <code>Base</code>@<code>M</code>,
which is what this class is for. It wraps these two base classes so that it
is more streamlined in the inference code.</p>
<ul>
<li><code>Base</code> : mdsine2.design_matrices.InteractionsBaseDesignMatrix<ul>
<li>This is an object that builds the interaction matrix as if there was no
clustering or indicators. It builds the data for all the Taxa/OTUs and
as if every interaction indicator was on. This is actually faster than
just building it for individual indicators for a few different reasons:
1) We only need to update <code>Base</code> when we do filtering or update the
values of the growth matrix because these are the only two things
that <code>Base</code> is dependent on.
2) Because we don't have to check indicators or have different shapes
when building the matrix, it is much easier to build this matrix
with Numba, which is nearly as fast as C. This speeds up building
time by ~97%.</li>
</ul>
</li>
<li><code>Mixing</code> : mdsine2.design_matrices.InteractionsMixingDesignMatrix<ul>
<li>This is the object that selects for indicators and groups taxa together
into clusters. When we change the indicators of the perturbations or
the cluster assignments of the Taxa, we only need to change this matrix,
which is a lot faster than changing everything. Because both matrices are
sparse matrices and this matrix is 98% zeros, this is a very fast operation.</li>
</ul>
</li>
</ul>
<h2 id="see-also">See Also</h2>
<p><code><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix">InteractionsBaseDesignMatrix</a></code>
<code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix">InteractionsMixingDesignMatrix</a></code></p>
<p><code>Parameters</code></p>
<p><code>varname (str) - This is the name of the variable we are building it for</code>
<code>update (bool) - If True</code>, <code>this matrix gets updated when <a title="mdsine2.design_matrices.Data.update_values" href="#mdsine2.design_matrices.Data.update_values">Data.update_values()</a> is called.</code>
<code>add_to_dict (bool) - If True</code>, <code>it adds to the design_matrices dictionary. - Else it does not</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InteractionsDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Builds the design matrix for the interactions: 
    - A_{i,j} @ M = A_{c_i,c_j}, where
        - A_{i,j} is the __Taxa-Taxa__ interaction matrix (self.base)
        - M is the mixing matrix (self.M)
        - A_{c_i,c_j} is the cluster-cluster interaction matrix

    This matrix is composed of two, individual design matrices, `Base` and `M`.
    To make the matrix that we use during inference, we matrix multiply `Base`@`M`,
    which is what this class is for. It wraps these two base classes so that it
    is more streamlined in the inference code.

    * `Base` : mdsine2.design_matrices.InteractionsBaseDesignMatrix
        - This is an object that builds the interaction matrix as if there was no
          clustering or indicators. It builds the data for all the Taxa/OTUs and
          as if every interaction indicator was on. This is actually faster than
          just building it for individual indicators for a few different reasons:
              1) We only need to update `Base` when we do filtering or update the 
                 values of the growth matrix because these are the only two things
                 that `Base` is dependent on.
              2) Because we don&#39;t have to check indicators or have different shapes
                 when building the matrix, it is much easier to build this matrix
                 with Numba, which is nearly as fast as C. This speeds up building
                 time by ~97%.
    * `Mixing` : mdsine2.design_matrices.InteractionsMixingDesignMatrix
        - This is the object that selects for indicators and groups taxa together
          into clusters. When we change the indicators of the perturbations or 
          the cluster assignments of the Taxa, we only need to change this matrix,
          which is a lot faster than changing everything. Because both matrices are
          sparse matrices and this matrix is 98% zeros, this is a very fast operation.

    See Also
    --------
    mdsine2.design_matrices.InteractionsBaseDesignMatrix
    mdsine2.design_matrices.InteractionsMixingDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.CLUSTER_INTERACTION_VALUE,
            update=True, **kwargs)

        # Initialize and set up rows and cols for base matrix
        total_n_dts = self.G.data.total_n_dts_per_taxa
        n_taxa = self.G.data.n_taxa

        self.n_rows = int(n_taxa * total_n_dts)
        self.clustering = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].clustering

        self.base = InteractionsBaseDesignMatrix(add_to_dict=False, **kwargs)
        self.base.build()
        self.M = InteractionsMixingDesignMatrix(add_to_dict=False, parent=self,**kwargs)
        self.build()
        self.interactions = self.M.interactions
        logging.info(&#39;Initializing interactions matrix&#39;)

    def build(self):
        self.matrix = self.base.matrix @ self.M.matrix
        self.n_cols = self.shape[1]

    @property
    def shape(self) -&gt; Tuple[int, int]:
        return self.matrix.shape

    def set_to_lhs(self) -&gt; np.ndarray:
        b_cicj = self.interactions.get_values(
            use_indicators=True).reshape(-1,1)
        return self.matrix.dot(b_cicj)

    def set_to_rhs(self)-&gt; scipy.sparse.spmatrix:
        return self.matrix

    def update_value(self):
        self.base.update_value()
        self.build()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="mdsine2.design_matrices.InteractionsDesignMatrix.shape"><code class="name">var <span class="ident">shape</span> :Â Tuple[int,Â int]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def shape(self) -&gt; Tuple[int, int]:
    return self.matrix.shape</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.InteractionsDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    self.matrix = self.base.matrix @ self.M.matrix
    self.n_cols = self.shape[1]</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsDesignMatrix.set_to_rhs"><code class="name flex">
<span>def <span class="ident">set_to_rhs</span></span>(<span>self) â€‘>Â scipy.sparse.base.spmatrix</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_rhs(self)-&gt; scipy.sparse.spmatrix:
    return self.matrix</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.DesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix"><code class="flex name class">
<span>class <span class="ident">InteractionsMixingDesignMatrix</span></span>
<span>(</span><span>parent:Â <a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a>, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the mixing matrix that is used along with
<code><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix">InteractionsBaseDesignMatrix</a></code> for the
<code><a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a></code>
class</p>
<p>The <code>keypair2col</code> dictionary maps a tuple of (target_taxa_idx,source_taxa_idx)
to the column they belong to in the full, non-clustered matrix.</p>
<p>This class has a few different options on how to build M, dependiing on where
it is being called in inference, some are faster than others, or build very
specific parts, or build the matrix given some specific data. </p>
<h2 id="see-also">See Also</h2>
<p><code><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix">InteractionsBaseDesignMatrix</a></code>
<code><a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a></code></p>
<p><code>Parameters</code></p>
<p><code>varname (str) - This is the name of the variable we are building it for</code>
<code>update (bool) - If True</code>, <code>this matrix gets updated when <a title="mdsine2.design_matrices.Data.update_values" href="#mdsine2.design_matrices.Data.update_values">Data.update_values()</a> is called.</code>
<code>add_to_dict (bool) - If True</code>, <code>it adds to the design_matrices dictionary. - Else it does not</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InteractionsMixingDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This is the mixing matrix that is used along with
    `InteractionsBaseDesignMatrix` for the  `InteractionsDesignMatrix`
    class



    The `keypair2col` dictionary maps a tuple of (target_taxa_idx,source_taxa_idx)
    to the column they belong to in the full, non-clustered matrix.

    This class has a few different options on how to build M, dependiing on where
    it is being called in inference, some are faster than others, or build very
    specific parts, or build the matrix given some specific data. 

    See Also
    --------
    mdsine2.design_matrices.InteractionsBaseDesignMatrix
    mdsine2.design_matrices.InteractionsDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, parent: &#34;InteractionsDesignMatrix&#34;, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.CLUSTER_INTERACTION_VALUE+&#39;mixing_matrix&#39;,
            **kwargs)

        self.parent = parent # InteractionsDesignMatrix
        n_taxa = self.G.data.n_taxa

        # mdsine2.pylab.cluster.Clustering object
        # This tells the design matrix which taxon is in which cluster
        self.clustering = self.G[STRNAMES.CLUSTERING_OBJ]

        # mdsine2.pylab.contrib.Interactions object
        # This tells the design matrix what interactions have positive indicators
        self.interactions = self.G[STRNAMES.INTERACTIONS_OBJ]

        self.n_rows = int(n_taxa * (n_taxa - 1)) # int

        # Build the keypair2col dictionary
        self.keypair2col = np.zeros(
            shape=(len(self.G.data.taxa), len(self.G.data.taxa)), dtype=int)
        i = 0
        for tidx in range(len(self.G.data.taxa)):
            for sidx in range(len(self.G.data.taxa)):
                if tidx == sidx:
                    continue
                self.keypair2col[tidx, sidx] = i
                i += 1

        self.build(build=False)
        logging.info(&#39;Initialized interactions mixing design matrix&#39;)

        # Compile and set `_get_rows` in cache - these values are dummy values that are
        # not used in inference
        a = np.zeros(1, int)
        tmems = np.asarray([1], dtype=int)
        smems = np.asarray([2], dtype=int)
        InteractionsMixingDesignMatrix.get_indices(a, self.keypair2col, tmems, smems)

    # @profile
    def build(self, build: bool=True, build_for_neg_ind: bool=False):
        &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
        from scratch slowly - it does not take advantage of the clus2clus dictionary.

        This will only build for positive indicators unless `build_for_neg_ind` is
        True, where it will also build for negative indicators as well.

        We save the castings of the sets of Taxa ids into numpy arrays so we 
        dont have to do it each iteration. This saves ~45% computation time

        Parameters
        ----------
        build : bool
            This is a flag whether we should build the parent matrix in the
            function `make_matrix`
        build_for_neg_ind : bool
            If True, builds for all the interactions and not just the positively
            indicated
        &#39;&#39;&#39;
        rows = []
        cols = []

        # interaction terms
        # Cluster 2 Cluster Interaction InDeX (c2ciidx)
        c2ciidx = 0
        d = {}

        if build_for_neg_ind:
            for interaction in self.interactions:
                d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
                c2ciidx += 1
        else:
            for tcid, scid in self.interactions.iter_valid_pairs():
                d, rows, cols = self.inner_faster(rows, cols, d, tcid, scid, c2ciidx)
                c2ciidx += 1

        rows = np.asarray(list(itertools.chain.from_iterable(rows))) #, dtype=int)
        cols = np.asarray(list(itertools.chain.from_iterable(cols))) #, dtype=int)
        self._make_matrix(rows=rows, cols=cols, n_cols=c2ciidx, build=build)

        self.rows = rows
        self.cols = cols

    # @profile
    def build_clustering(self, build: bool=True):
        &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
        from scratch slowly - it does not take advantage of the clus2clus dictionary.

        This will only build for positive indicators unless `build_for_neg_ind` is
        True, where it will also build for negative indicators as well.

        We save the castings of the sets of Taxa ids into numpy arrays so we 
        dont have to do it each iteration. This saves ~45% computation time

        Parameters
        ----------
        build : bool
            This is a flag whether we should build the parent matrix in the
            function `make_matrix`
        &#39;&#39;&#39;
        self.cols = np.zeros(400, dtype=int)
        self.rows = np.zeros(400, dtype=int)
        self.baseidx = 0


        # interaction terms
        # Cluster 2 Cluster Interaction InDeX (c2ciidx)
        c2ciidx = 0
        self.d = {}

        # print(&#39;this bitch&#39;)

        for tcid, scid in self.interactions.iter_valid_pairs():
            self.inner_faster_faster(tcid, scid, c2ciidx)
            c2ciidx += 1

        self.rows = self.rows[:self.baseidx]
        self.cols = self.cols[:self.baseidx]
        self._make_matrix(rows=self.rows, cols=self.cols, n_cols=c2ciidx, build=build)

    # @profile
    def build_for_cols(self, build: bool, cols: np.ndarray):
        &#39;&#39;&#39;This does the same as `build` but it only builds for the 
        column indices specified, in order

        NOTE - these are the indicies for the on interactions only, that means we skip 
        over the interactions that are false for enumerating them
        &#39;&#39;&#39;
        input_cols = OrderedSet(list(cols))

        rows = []
        cols = []
        d = {}

        iidx = 0
        i = 0
        for tcid,scid in self.interactions.iter_valid_pairs():
            if iidx in input_cols:
                d, rows, cols = self.inner_faster(rows, cols, d, tcid, scid, i)
                i += 1
            iidx += 1
        
        rows = np.asarray(list(itertools.chain.from_iterable(rows)))
        cols = np.asarray(list(itertools.chain.from_iterable(cols)))
        self._make_matrix(rows=rows, cols=cols, n_cols=len(input_cols), build=build)

    # @profile
    def build_for_specified(self, build: bool, idxs: np.ndarray, tcids: np.ndarray, scids: np.ndarray):
        &#39;&#39;&#39;This does the same as `build` but it only builds for the 
        pair of tcids and scids at the same index passed in
        &#39;&#39;&#39;
        # input_cols = OrderedSet(list(idxs))

        rows = []
        cols = []
        d = {}

        for i in range(len(idxs)):
            d, rows, cols = self.inner_faster(rows, cols, d, tcids[idxs[i]], scids[idxs[i]], i)

        
        rows = np.asarray(list(itertools.chain.from_iterable(rows)))
        cols = np.asarray(list(itertools.chain.from_iterable(cols)))
        self._make_matrix(rows=rows, cols=cols, n_cols=len(idxs), build=build)

    # @profile
    def build_to_and_from(self, cids: List[int], build: bool):
        &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
        from scratch for only positive interactions going to an from each 
        of the clusters in `cids`.

        Parameters
        ----------
        cids : list
            This is a list of cids that we are getting the M matrix for
        &#39;&#39;&#39;
        rows = []
        cols = []
        d = {}
        c2ciidx = 0

        cids = OrderedSet(cids)
        # print(&#39;cidxs\n&#39;, cidxs)
        # print(&#39;from data\n&#39;, self.interactions.clustering.order)

        for interaction in self.interactions:
            if not interaction.indicator:
                continue
            if interaction.target_cid in cids:
                d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
            elif interaction.source_cid in cids:
                d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
            c2ciidx += 1

        # print(&#39;interactions_used&#39;, interactions_used)
            
        rows = np.asarray(list(itertools.chain.from_iterable(rows))) #, dtype=int)
        cols = np.asarray(list(itertools.chain.from_iterable(cols))) #, dtype=int)
        self._make_matrix(rows=rows, cols=cols, n_cols=c2ciidx, build=build)

    # @profile
    def inner(self, rows: List, cols: List, d: Dict[int, Any], interaction: pl.contrib._Interaction, 
        c2ciidx: int) -&gt; Tuple[Dict[int, Any], List, List]:
        tcid = interaction.target_cid
        scid = interaction.source_cid

        if tcid not in d:
            tmems = np.asarray(list(self.clustering.clusters[tcid].members))
            d[tcid] = tmems
        else:
            tmems = d[tcid]

        if scid not in d:
            smems = np.asarray(list(self.clustering.clusters[scid].members))
            d[scid] = smems
        else:
            smems = d[scid]

        a = np.zeros(len(tmems)*len(smems), int)
        rows.append(InteractionsMixingDesignMatrix.get_indices(
            a, self.keypair2col, tmems, smems))
        cols.append(np.full(len(tmems)*len(smems), fill_value=c2ciidx))

        return d, rows, cols

    # @profile
    def inner_faster(self, rows: List, cols: List, d: Dict[int, Any], tcid: int, scid: int, 
        c2ciidx: int) -&gt; Tuple[Dict[int, Any], List, List]:
        if tcid not in d:
            tmems = np.asarray(list(self.clustering.clusters[tcid].members))
            d[tcid] = tmems
        else:
            tmems = d[tcid]

        if scid not in d:
            smems = np.asarray(list(self.clustering.clusters[scid].members))
            d[scid] = smems
        else:
            smems = d[scid]

        a = np.zeros(len(tmems)*len(smems), int)
        rows.append(InteractionsMixingDesignMatrix.get_indices(
            a, self.keypair2col, tmems, smems))
        cols.append(np.full(len(tmems)*len(smems), fill_value=c2ciidx))

        return d, rows, cols

    # @profile
    def inner_faster_faster(self, tcid: int, scid: int, c2ciidx: int):
        if tcid not in self.d:
            tmems = np.asarray(list(self.clustering.clusters[tcid].members))
            self.d[tcid] = tmems
        else:
            tmems = self.d[tcid]

        if scid not in self.d:
            smems = np.asarray(list(self.clustering.clusters[scid].members))
            self.d[scid] = smems
        else:
            smems = self.d[scid]

        end = self.baseidx + len(tmems)*len(smems)
        if end &gt; len(self.cols):
            # pad 400 to the length
            self.rows = np.append(self.rows, np.zeros(400, dtype=int))
            self.cols = np.append(self.cols, np.zeros(400, dtype=int))

        InteractionsMixingDesignMatrix.get_indices(
            self.rows[self.baseidx:end], self.keypair2col, tmems, smems)
        self.cols[self.baseidx:end] = c2ciidx
        self.baseidx = end

    # @profile
    def _make_matrix(self, rows, cols, n_cols, build):
        &#39;&#39;&#39;Builds the mixing matrix from the specified rows and columns
        (data is always going to be 1 because it is a mixing matrix)

        Rebuild after we have changed the mixing matrix if `build` is True.
        &#39;&#39;&#39;
        self.n_cols = n_cols
        # else:
        data = np.ones(len(rows), dtype=int)
        self.matrix = scipy.sparse.coo_matrix((data,(rows,cols)),
            shape=(self.n_rows, n_cols)).tocsc()
        self.shape = self.matrix.shape
        if build:
            self.parent.build()

    @staticmethod
    @numba.jit(nopython=True, cache=True)
    def get_indices(a: np.ndarray, keypair2col: np.ndarray, tmems: np.ndarray, 
        smems: np.ndarray) -&gt; np.ndarray:
        &#39;&#39;&#39;Use Just in Time compilation to reduce the &#39;getting&#39; time
        by about 95%

        Parameters
        ----------
        a : np.ndarray
            Return array
        keypair2col : np.ndarray
            Maps (target_oidx, source_oidx) pair to the place the interaction
            index would be on a full interactio design matrix on the Taxa level
        tmems, smems : np.ndarray
            These are the Taxa indices in the target cluster and the source cluster
            respectively

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        i = 0
        for tidx in tmems:
            for sidx in smems:
                a[i] = keypair2col[tidx, sidx]
                i += 1
        return a</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.get_indices"><code class="name flex">
<span>def <span class="ident">get_indices</span></span>(<span>a:Â numpy.ndarray, keypair2col:Â numpy.ndarray, tmems:Â numpy.ndarray, smems:Â numpy.ndarray) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Use Just in Time compilation to reduce the 'getting' time
by about 95%</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Return array</dd>
<dt><strong><code>keypair2col</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Maps (target_oidx, source_oidx) pair to the place the interaction
index would be on a full interactio design matrix on the Taxa level</dd>
<dt><strong><code>tmems</code></strong>, <strong><code>smems</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>These are the Taxa indices in the target cluster and the source cluster
respectively</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@numba.jit(nopython=True, cache=True)
def get_indices(a: np.ndarray, keypair2col: np.ndarray, tmems: np.ndarray, 
    smems: np.ndarray) -&gt; np.ndarray:
    &#39;&#39;&#39;Use Just in Time compilation to reduce the &#39;getting&#39; time
    by about 95%

    Parameters
    ----------
    a : np.ndarray
        Return array
    keypair2col : np.ndarray
        Maps (target_oidx, source_oidx) pair to the place the interaction
        index would be on a full interactio design matrix on the Taxa level
    tmems, smems : np.ndarray
        These are the Taxa indices in the target cluster and the source cluster
        respectively

    Returns
    -------
    np.ndarray
    &#39;&#39;&#39;
    i = 0
    for tidx in tmems:
        for sidx in smems:
            a[i] = keypair2col[tidx, sidx]
            i += 1
    return a</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, build:Â boolÂ =Â True, build_for_neg_ind:Â boolÂ =Â False)</span>
</code></dt>
<dd>
<div class="desc"><p>This makes the rows, cols, and data vectors for the mixing matrix
from scratch slowly - it does not take advantage of the clus2clus dictionary.</p>
<p>This will only build for positive indicators unless <code>build_for_neg_ind</code> is
True, where it will also build for negative indicators as well.</p>
<p>We save the castings of the sets of Taxa ids into numpy arrays so we
dont have to do it each iteration. This saves ~45% computation time</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>build</code></strong> :&ensp;<code>bool</code></dt>
<dd>This is a flag whether we should build the parent matrix in the
function <code>make_matrix</code></dd>
<dt><strong><code>build_for_neg_ind</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, builds for all the interactions and not just the positively
indicated</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self, build: bool=True, build_for_neg_ind: bool=False):
    &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
    from scratch slowly - it does not take advantage of the clus2clus dictionary.

    This will only build for positive indicators unless `build_for_neg_ind` is
    True, where it will also build for negative indicators as well.

    We save the castings of the sets of Taxa ids into numpy arrays so we 
    dont have to do it each iteration. This saves ~45% computation time

    Parameters
    ----------
    build : bool
        This is a flag whether we should build the parent matrix in the
        function `make_matrix`
    build_for_neg_ind : bool
        If True, builds for all the interactions and not just the positively
        indicated
    &#39;&#39;&#39;
    rows = []
    cols = []

    # interaction terms
    # Cluster 2 Cluster Interaction InDeX (c2ciidx)
    c2ciidx = 0
    d = {}

    if build_for_neg_ind:
        for interaction in self.interactions:
            d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
            c2ciidx += 1
    else:
        for tcid, scid in self.interactions.iter_valid_pairs():
            d, rows, cols = self.inner_faster(rows, cols, d, tcid, scid, c2ciidx)
            c2ciidx += 1

    rows = np.asarray(list(itertools.chain.from_iterable(rows))) #, dtype=int)
    cols = np.asarray(list(itertools.chain.from_iterable(cols))) #, dtype=int)
    self._make_matrix(rows=rows, cols=cols, n_cols=c2ciidx, build=build)

    self.rows = rows
    self.cols = cols</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_clustering"><code class="name flex">
<span>def <span class="ident">build_clustering</span></span>(<span>self, build:Â boolÂ =Â True)</span>
</code></dt>
<dd>
<div class="desc"><p>This makes the rows, cols, and data vectors for the mixing matrix
from scratch slowly - it does not take advantage of the clus2clus dictionary.</p>
<p>This will only build for positive indicators unless <code>build_for_neg_ind</code> is
True, where it will also build for negative indicators as well.</p>
<p>We save the castings of the sets of Taxa ids into numpy arrays so we
dont have to do it each iteration. This saves ~45% computation time</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>build</code></strong> :&ensp;<code>bool</code></dt>
<dd>This is a flag whether we should build the parent matrix in the
function <code>make_matrix</code></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_clustering(self, build: bool=True):
    &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
    from scratch slowly - it does not take advantage of the clus2clus dictionary.

    This will only build for positive indicators unless `build_for_neg_ind` is
    True, where it will also build for negative indicators as well.

    We save the castings of the sets of Taxa ids into numpy arrays so we 
    dont have to do it each iteration. This saves ~45% computation time

    Parameters
    ----------
    build : bool
        This is a flag whether we should build the parent matrix in the
        function `make_matrix`
    &#39;&#39;&#39;
    self.cols = np.zeros(400, dtype=int)
    self.rows = np.zeros(400, dtype=int)
    self.baseidx = 0


    # interaction terms
    # Cluster 2 Cluster Interaction InDeX (c2ciidx)
    c2ciidx = 0
    self.d = {}

    # print(&#39;this bitch&#39;)

    for tcid, scid in self.interactions.iter_valid_pairs():
        self.inner_faster_faster(tcid, scid, c2ciidx)
        c2ciidx += 1

    self.rows = self.rows[:self.baseidx]
    self.cols = self.cols[:self.baseidx]
    self._make_matrix(rows=self.rows, cols=self.cols, n_cols=c2ciidx, build=build)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_for_cols"><code class="name flex">
<span>def <span class="ident">build_for_cols</span></span>(<span>self, build:Â bool, cols:Â numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>This does the same as <code>build</code> but it only builds for the
column indices specified, in order</p>
<p>NOTE - these are the indicies for the on interactions only, that means we skip
over the interactions that are false for enumerating them</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_for_cols(self, build: bool, cols: np.ndarray):
    &#39;&#39;&#39;This does the same as `build` but it only builds for the 
    column indices specified, in order

    NOTE - these are the indicies for the on interactions only, that means we skip 
    over the interactions that are false for enumerating them
    &#39;&#39;&#39;
    input_cols = OrderedSet(list(cols))

    rows = []
    cols = []
    d = {}

    iidx = 0
    i = 0
    for tcid,scid in self.interactions.iter_valid_pairs():
        if iidx in input_cols:
            d, rows, cols = self.inner_faster(rows, cols, d, tcid, scid, i)
            i += 1
        iidx += 1
    
    rows = np.asarray(list(itertools.chain.from_iterable(rows)))
    cols = np.asarray(list(itertools.chain.from_iterable(cols)))
    self._make_matrix(rows=rows, cols=cols, n_cols=len(input_cols), build=build)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_for_specified"><code class="name flex">
<span>def <span class="ident">build_for_specified</span></span>(<span>self, build:Â bool, idxs:Â numpy.ndarray, tcids:Â numpy.ndarray, scids:Â numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>This does the same as <code>build</code> but it only builds for the
pair of tcids and scids at the same index passed in</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_for_specified(self, build: bool, idxs: np.ndarray, tcids: np.ndarray, scids: np.ndarray):
    &#39;&#39;&#39;This does the same as `build` but it only builds for the 
    pair of tcids and scids at the same index passed in
    &#39;&#39;&#39;
    # input_cols = OrderedSet(list(idxs))

    rows = []
    cols = []
    d = {}

    for i in range(len(idxs)):
        d, rows, cols = self.inner_faster(rows, cols, d, tcids[idxs[i]], scids[idxs[i]], i)

    
    rows = np.asarray(list(itertools.chain.from_iterable(rows)))
    cols = np.asarray(list(itertools.chain.from_iterable(cols)))
    self._make_matrix(rows=rows, cols=cols, n_cols=len(idxs), build=build)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_to_and_from"><code class="name flex">
<span>def <span class="ident">build_to_and_from</span></span>(<span>self, cids:Â List[int], build:Â bool)</span>
</code></dt>
<dd>
<div class="desc"><p>This makes the rows, cols, and data vectors for the mixing matrix
from scratch for only positive interactions going to an from each
of the clusters in <code>cids</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cids</code></strong> :&ensp;<code>list</code></dt>
<dd>This is a list of cids that we are getting the M matrix for</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_to_and_from(self, cids: List[int], build: bool):
    &#39;&#39;&#39;This makes the rows, cols, and data vectors for the mixing matrix
    from scratch for only positive interactions going to an from each 
    of the clusters in `cids`.

    Parameters
    ----------
    cids : list
        This is a list of cids that we are getting the M matrix for
    &#39;&#39;&#39;
    rows = []
    cols = []
    d = {}
    c2ciidx = 0

    cids = OrderedSet(cids)
    # print(&#39;cidxs\n&#39;, cidxs)
    # print(&#39;from data\n&#39;, self.interactions.clustering.order)

    for interaction in self.interactions:
        if not interaction.indicator:
            continue
        if interaction.target_cid in cids:
            d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
        elif interaction.source_cid in cids:
            d, rows, cols = self.inner(rows, cols, d, interaction, c2ciidx)
        c2ciidx += 1

    # print(&#39;interactions_used&#39;, interactions_used)
        
    rows = np.asarray(list(itertools.chain.from_iterable(rows))) #, dtype=int)
    cols = np.asarray(list(itertools.chain.from_iterable(cols))) #, dtype=int)
    self._make_matrix(rows=rows, cols=cols, n_cols=c2ciidx, build=build)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner"><code class="name flex">
<span>def <span class="ident">inner</span></span>(<span>self, rows:Â List, cols:Â List, d:Â Dict[int,Â Any], interaction:Â mdsine2.pylab.contrib._Interaction, c2ciidx:Â int) â€‘>Â Tuple[Dict[int,Â Any],Â List,Â List]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inner(self, rows: List, cols: List, d: Dict[int, Any], interaction: pl.contrib._Interaction, 
    c2ciidx: int) -&gt; Tuple[Dict[int, Any], List, List]:
    tcid = interaction.target_cid
    scid = interaction.source_cid

    if tcid not in d:
        tmems = np.asarray(list(self.clustering.clusters[tcid].members))
        d[tcid] = tmems
    else:
        tmems = d[tcid]

    if scid not in d:
        smems = np.asarray(list(self.clustering.clusters[scid].members))
        d[scid] = smems
    else:
        smems = d[scid]

    a = np.zeros(len(tmems)*len(smems), int)
    rows.append(InteractionsMixingDesignMatrix.get_indices(
        a, self.keypair2col, tmems, smems))
    cols.append(np.full(len(tmems)*len(smems), fill_value=c2ciidx))

    return d, rows, cols</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner_faster"><code class="name flex">
<span>def <span class="ident">inner_faster</span></span>(<span>self, rows:Â List, cols:Â List, d:Â Dict[int,Â Any], tcid:Â int, scid:Â int, c2ciidx:Â int) â€‘>Â Tuple[Dict[int,Â Any],Â List,Â List]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inner_faster(self, rows: List, cols: List, d: Dict[int, Any], tcid: int, scid: int, 
    c2ciidx: int) -&gt; Tuple[Dict[int, Any], List, List]:
    if tcid not in d:
        tmems = np.asarray(list(self.clustering.clusters[tcid].members))
        d[tcid] = tmems
    else:
        tmems = d[tcid]

    if scid not in d:
        smems = np.asarray(list(self.clustering.clusters[scid].members))
        d[scid] = smems
    else:
        smems = d[scid]

    a = np.zeros(len(tmems)*len(smems), int)
    rows.append(InteractionsMixingDesignMatrix.get_indices(
        a, self.keypair2col, tmems, smems))
    cols.append(np.full(len(tmems)*len(smems), fill_value=c2ciidx))

    return d, rows, cols</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner_faster_faster"><code class="name flex">
<span>def <span class="ident">inner_faster_faster</span></span>(<span>self, tcid:Â int, scid:Â int, c2ciidx:Â int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inner_faster_faster(self, tcid: int, scid: int, c2ciidx: int):
    if tcid not in self.d:
        tmems = np.asarray(list(self.clustering.clusters[tcid].members))
        self.d[tcid] = tmems
    else:
        tmems = self.d[tcid]

    if scid not in self.d:
        smems = np.asarray(list(self.clustering.clusters[scid].members))
        self.d[scid] = smems
    else:
        smems = self.d[scid]

    end = self.baseidx + len(tmems)*len(smems)
    if end &gt; len(self.cols):
        # pad 400 to the length
        self.rows = np.append(self.rows, np.zeros(400, dtype=int))
        self.cols = np.append(self.cols, np.zeros(400, dtype=int))

    InteractionsMixingDesignMatrix.get_indices(
        self.rows[self.baseidx:end], self.keypair2col, tmems, smems)
    self.cols[self.baseidx:end] = c2ciidx
    self.baseidx = end</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.DesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.LHSVector"><code class="flex name class">
<span>class <span class="ident">LHSVector</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This builds the Left-Hand-Side (LHS) vector</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LHSVector(ObservationVector):
    &#39;&#39;&#39;This builds the Left-Hand-Side (LHS) vector
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        ObservationVector.__init__(self, **kwargs)
        logging.info(&#39;Initializing LHS vector&#39;)

    def build(self, subjects: Union[List[int], int, str]=&#39;all&#39;):
        &#39;&#39;&#39;Build the observation vector

        (log(x_{k+1}) - log(x_{k}))/dt

        Parameters
        ----------
        subjects : str, array(int), int
            These are the subjects to build the vector for. If &#39;all&#39;, we build it
            for all the subjects. If you want to pass in an array, we do it with 
            the subject index
        &#39;&#39;&#39;
        if pl.isint(subjects):
            subjects = [subjects]
        if subjects == &#39;all&#39;:
            subjects = np.arange(self.G.data.n_replicates)
            n_dts = self.G.data.total_n_dts_per_taxa
        else:
            n_dts = 0
            for sidx in subjects:
                n_dts += self.G.dta.n_dts_for_replicate[sidx]
        self.vector = np.zeros(self.G.data.n_taxa * n_dts, dtype=float)
        i = 0
        for ridx in range(self.G.data.n_replicates):
            if ridx not in subjects:
                # skip subject
                continue
            l = self.G.data.n_dts_for_replicate[ridx] * self.G.data.n_taxa
            LHSVector._fast_build_log(
                ret=self.vector[i:i+l],
                data=self.G.data.data[ridx],
                dt=self.G.data.dt[ridx],
                n_ts=self.G.data.n_dts_for_replicate[ridx],
                n_taxa=self.G.data.n_taxa)
            i += l

        if self.G.data.zero_inflation_transition_policy is not None:
            self.vector = self.vector[self.G.data.rows_to_include_zero_inflation]
        self.vector = self.vector.reshape(-1,1)

    def __len__(self) -&gt; int:
        return len(self.vector)

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def _fast_build_log(ret: np.ndarray, data: np.ndarray, dt: np.ndarray, n_ts: int, 
        n_taxa: int):
        &#39;&#39;&#39;About 99.4% faster than regular python looping
        &#39;&#39;&#39;
        i = 0
        for tidx in range(n_ts):
            for oidx in range(n_taxa):
                ret[i] = (np.log(data[oidx, tidx+1]) - np.log(data[oidx,tidx]))/dt[tidx]
                i += 1

    def update_value(self):
        self.build()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.ObservationVector" href="#mdsine2.design_matrices.ObservationVector">ObservationVector</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.LHSVector.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, subjects:Â Union[List[int],Â int,Â str]Â =Â 'all')</span>
</code></dt>
<dd>
<div class="desc"><p>Build the observation vector</p>
<p>(log(x_{k+1}) - log(x_{k}))/dt</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>subjects</code></strong> :&ensp;<code>str, array(int), int</code></dt>
<dd>These are the subjects to build the vector for. If 'all', we build it
for all the subjects. If you want to pass in an array, we do it with
the subject index</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self, subjects: Union[List[int], int, str]=&#39;all&#39;):
    &#39;&#39;&#39;Build the observation vector

    (log(x_{k+1}) - log(x_{k}))/dt

    Parameters
    ----------
    subjects : str, array(int), int
        These are the subjects to build the vector for. If &#39;all&#39;, we build it
        for all the subjects. If you want to pass in an array, we do it with 
        the subject index
    &#39;&#39;&#39;
    if pl.isint(subjects):
        subjects = [subjects]
    if subjects == &#39;all&#39;:
        subjects = np.arange(self.G.data.n_replicates)
        n_dts = self.G.data.total_n_dts_per_taxa
    else:
        n_dts = 0
        for sidx in subjects:
            n_dts += self.G.dta.n_dts_for_replicate[sidx]
    self.vector = np.zeros(self.G.data.n_taxa * n_dts, dtype=float)
    i = 0
    for ridx in range(self.G.data.n_replicates):
        if ridx not in subjects:
            # skip subject
            continue
        l = self.G.data.n_dts_for_replicate[ridx] * self.G.data.n_taxa
        LHSVector._fast_build_log(
            ret=self.vector[i:i+l],
            data=self.G.data.data[ridx],
            dt=self.G.data.dt[ridx],
            n_ts=self.G.data.n_dts_for_replicate[ridx],
            n_taxa=self.G.data.n_taxa)
        i += l

    if self.G.data.zero_inflation_transition_policy is not None:
        self.vector = self.vector[self.G.data.rows_to_include_zero_inflation]
    self.vector = self.vector.reshape(-1,1)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.ObservationVector" href="#mdsine2.design_matrices.ObservationVector">ObservationVector</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.ObservationVector.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.update_value" href="#mdsine2.design_matrices.ObservationVector.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.ObservationVector"><code class="flex name class">
<span>class <span class="ident">ObservationVector</span></span>
<span>(</span><span>name:Â str, G:Â <a title="mdsine2.pylab.graph.Graph" href="pylab/graph.html#mdsine2.pylab.graph.Graph">Graph</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the left hand side (lhs) vector</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ObservationVector(Node):
    &#39;&#39;&#39;This is the left hand side (lhs) vector
    &#39;&#39;&#39;
    def __init__(self, name: str, G: Graph):
        self.G = G
        self.name = name
        self.G.data.lhs = self
        self.vector = None

    def build(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def update_value(self):
        &#39;&#39;&#39;This updates the data for each design matrix
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.LHSVector" href="#mdsine2.design_matrices.LHSVector">LHSVector</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.ObservationVector.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.ObservationVector.update_value"><code class="name flex">
<span>def <span class="ident">update_value</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This updates the data for each design matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_value(self):
    &#39;&#39;&#39;This updates the data for each design matrix
    &#39;&#39;&#39;
    raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.graph.Node.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.graph.Node.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.PerturbationBaseDesignMatrix"><code class="flex name class">
<span>class <span class="ident">PerturbationBaseDesignMatrix</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the base data for the perturbations.</p>
<p>This creates the baseline perturbation effects for each <strong>Taxa</strong>, for every indicator.
This class used in conjungtion with <code><a title="mdsine2.design_matrices.PerturbationMixingDesignMatrix" href="#mdsine2.design_matrices.PerturbationMixingDesignMatrix">PerturbationMixingDesignMatrix</a></code> and should
be accessed through <code><a title="mdsine2.design_matrices.PerturbationDesignMatrix" href="#mdsine2.design_matrices.PerturbationDesignMatrix">PerturbationDesignMatrix</a></code>.</p>
<p>Note that this is not what is used during inference - we multiply this matrix by the
mixing matrix</p>
<h2 id="parameterization">Parameterization</h2>
<p>We parameterize the MDSINE2 model with multiplicative perturbations
[ \frac {log(x_{i,k+1}) - log(x_{i,k})} {t_{k+1} - t_{k}} =
a_{1,i} (1 + \sum_{p=1}^P u_p(k) \gamma_{i,p} ) + \sum_{j} b_{ij} x{j,k} ]
where:
:math:<code>x_{i,k}</code> : abundance for Taxa :math:<code>i</code> at time :math:<code>t_k</code>
:math:<code>t_k</code> : time at k
:math:<code>a_{1,i}</code> : growth for Taxa :math:<code>i</code>
:math:<code>b_{ij}</code> : interactions from :math:<code>i</code> to :math:<code>j</code>
:math:<code>b_{ii}</code> : self interactions for :math:<code>i</code>
:math:<code>u_p(k)</code> : step function for perturbation :math:<code>p</code> at time :math:<code>t_k</code>
:math:<code>\gamma_{i,p}</code> : perturbation value for perturbation :math:<code>p</code> for taxon :math:<code>i</code>
Here the perturbation has an "effect" on the growth rates</p>
<h2 id="see-also">See Also</h2>
<p><code>mdsine2.data_matrices.PerturbationMixingDesignMatrix</code>
<code>mdsine2.data_matrices.PerturbationDesignMatrix</code></p>
<p><code>Parameters</code></p>
<p><code>varname (str) - This is the name of the variable we are building it for</code>
<code>update (bool) - If True</code>, <code>this matrix gets updated when <a title="mdsine2.design_matrices.Data.update_values" href="#mdsine2.design_matrices.Data.update_values">Data.update_values()</a> is called.</code>
<code>add_to_dict (bool) - If True</code>, <code>it adds to the design_matrices dictionary. - Else it does not</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PerturbationBaseDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This is the base data for the perturbations.

    This creates the baseline perturbation effects for each __Taxa__, for every indicator.
    This class used in conjungtion with `PerturbationMixingDesignMatrix` and should
    be accessed through `PerturbationDesignMatrix`.

    Note that this is not what is used during inference - we multiply this matrix by the
    mixing matrix

    Parameterization
    ----------------
    We parameterize the MDSINE2 model with multiplicative perturbations
    .. math::
        \\frac {log(x_{i,k+1}) - log(x_{i,k})} {t_{k+1} - t_{k}} =
            a_{1,i} (1 + \sum_{p=1}^P u_p(k) \gamma_{i,p} ) + \sum_{j} b_{ij} x{j,k} 
    where:
        :math:`x_{i,k}` : abundance for Taxa :math:`i` at time :math:`t_k`
        :math:`t_k` : time at k
        :math:`a_{1,i}` : growth for Taxa :math:`i`
        :math:`b_{ij}` : interactions from :math:`i` to :math:`j`
        :math:`b_{ii}` : self interactions for :math:`i`
        :math:`u_p(k)` : step function for perturbation :math:`p` at time :math:`t_k`
        :math:`\gamma_{i,p}` : perturbation value for perturbation :math:`p` for taxon :math:`i`
        Here the perturbation has an &#34;effect&#34; on the growth rates

    See Also
    --------
    mdsine2.data_matrices.PerturbationMixingDesignMatrix
    mdsine2.data_matrices.PerturbationDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        name = STRNAMES.PERT_VALUE+&#39;_base_data&#39;
        DesignMatrix.__init__(self, varname=name, **kwargs)
        if self.G.data.zero_inflation_transition_policy is not None:
            raise NotImplementedError(&#39;Not Implemented&#39;)

        self.perturbations = self.G.perturbations # pylab.base.Perturbations object
        self.n_perturbations = len(self.perturbations) # int
        self.n_replicates = self.G.data.n_replicates # int
        self.n_taxa = len(self.G.data.taxa) # int
        self.growths = self.G[STRNAMES.GROWTH_VALUE] # This is the pointer to the growth variable learned in inference

        self.starts = [] # list[list[int]] top index indexes the subject, bottom index indexes the perturbation
        self.ends = [] # list[list[int]] top index indexes the subject, bottom index indexes the perturbation
        self.tidxs_in_pert_per_replicate = []

        self.tidxs_in_perturbation = np.zeros(shape=(self.n_replicates,
            self.n_perturbations, 2), dtype=int) - 1

        # Get the total number of timepoints in perturbations
        total_tidxs = 0
        for ridx, subj in enumerate(self.G.data.subjects):
            self.starts.append([]) # indices where the perturbation starts
            self.ends.append([]) # indices where the perturbation ends
            i = 0
            for pidx in range(self.n_perturbations):
                start, end = self.G.data.tidxs_in_perturbation[ridx][pidx]
                if start is None:
                    continue
                self.tidxs_in_perturbation[ridx,pidx,0] = start
                self.tidxs_in_perturbation[ridx,pidx,1] = end
                self.starts[-1].append(start)
                self.ends[-1].append(end)
                i += end-start
                total_tidxs += i

            self.tidxs_in_pert_per_replicate.append(i)
            self.starts[-1] = np.asarray(self.starts[-1], dtype=int)
            self.ends[-1] = np.asarray(self.ends[-1], dtype=int)

        # Set rows and cols
        self.total_len = int(total_tidxs * self.n_taxa)
        self.tidxs_in_pert_per_replicate = np.asarray(self.tidxs_in_pert_per_replicate, dtype=int)
        self.rows = np.zeros(self.total_len, dtype=int)
        self.cols = np.zeros(self.total_len, dtype=int)
        self.data = np.zeros(self.total_len)

        # Make the rows and columns for the data matrix
        PerturbationBaseDesignMatrix.init(
            rows=self.rows, 
            cols=self.cols, 
            n_perturbations=self.n_perturbations, 
            n_taxa=self.n_taxa, 
            n_replicates=self.n_replicates, 
            tidxs_in_perturbation=self.tidxs_in_perturbation, 
            n_dts_for_replicate=self.G.data.n_dts_for_replicate)

        # Initialize the rows and cols for the data
        self.n_rows = self.G.data.total_n_dts_per_taxa * self.G.data.n_taxa
        self.n_cols = self.n_taxa * self.n_perturbations
        self.shape = (self.n_rows, self.n_cols)

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def init(rows: np.ndarray, cols: np.ndarray, n_perturbations: int, n_taxa: int, 
        n_replicates: int, tidxs_in_perturbation: np.ndarray, n_dts_for_replicate: np.ndarray):

        i = 0
        base_row_idx = 0
        for ridx in range(n_replicates):
            for pidx in range(n_perturbations):
                start = tidxs_in_perturbation[ridx,pidx,0]
                end = tidxs_in_perturbation[ridx,pidx,1]
                if start == -1:
                    continue
                base_col_idx = pidx * n_taxa
                for oidx in range(n_taxa):
                    col = oidx + base_col_idx
                    for tidx in range(start, end):
                        rows[i] = oidx + tidx * n_taxa + base_row_idx
                        cols[i] = col
                        i += 1

            base_row_idx = base_row_idx + n_taxa * n_dts_for_replicate[ridx]

    @staticmethod
    @numba.jit(nopython=True, cache=True, fastmath=True)
    def fast_build(ret: np.ndarray, n_perturbations: int, n_taxa: int, n_replicates: int, 
        tidxs_in_perturbation: np.ndarray, growths: np.ndarray, data: np.ndarray):

        i = 0
        for pidx in range(n_perturbations):
            start, end = tidxs_in_perturbation[pidx]
            if start == -1:
                continue
            for oidx in range(n_taxa):
                growth = growths[oidx]
                ret[i:(i+end-start)] = growth
                i += end-start

    def build(self):
        growths = self.growths.value # these are the current values of the growth parameters for each taxa
        i = 0
        for ridx in range(self.n_replicates):
            l = self.tidxs_in_pert_per_replicate[ridx] * self.n_taxa
            PerturbationBaseDesignMatrix.fast_build(
                ret=self.data[i:i+l], 
                n_perturbations=self.n_perturbations, 
                n_taxa=self.n_taxa, 
                n_replicates=self.n_replicates, 
                tidxs_in_perturbation=self.tidxs_in_perturbation[ridx], 
                growths=growths, 
                data=self.G.data.data[ridx])
            i += l

        self.matrix = scipy.sparse.coo_matrix(
            (self.data,(self.rows,self.cols)),shape=self.shape).tocsc()

    def update_value(self):
        self.build()

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        return self.matrix</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="mdsine2.design_matrices.PerturbationBaseDesignMatrix.fast_build"><code class="name flex">
<span>def <span class="ident">fast_build</span></span>(<span>ret:Â numpy.ndarray, n_perturbations:Â int, n_taxa:Â int, n_replicates:Â int, tidxs_in_perturbation:Â numpy.ndarray, growths:Â numpy.ndarray, data:Â numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@numba.jit(nopython=True, cache=True, fastmath=True)
def fast_build(ret: np.ndarray, n_perturbations: int, n_taxa: int, n_replicates: int, 
    tidxs_in_perturbation: np.ndarray, growths: np.ndarray, data: np.ndarray):

    i = 0
    for pidx in range(n_perturbations):
        start, end = tidxs_in_perturbation[pidx]
        if start == -1:
            continue
        for oidx in range(n_taxa):
            growth = growths[oidx]
            ret[i:(i+end-start)] = growth
            i += end-start</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.PerturbationBaseDesignMatrix.init"><code class="name flex">
<span>def <span class="ident">init</span></span>(<span>rows:Â numpy.ndarray, cols:Â numpy.ndarray, n_perturbations:Â int, n_taxa:Â int, n_replicates:Â int, tidxs_in_perturbation:Â numpy.ndarray, n_dts_for_replicate:Â numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@numba.jit(nopython=True, cache=True, fastmath=True)
def init(rows: np.ndarray, cols: np.ndarray, n_perturbations: int, n_taxa: int, 
    n_replicates: int, tidxs_in_perturbation: np.ndarray, n_dts_for_replicate: np.ndarray):

    i = 0
    base_row_idx = 0
    for ridx in range(n_replicates):
        for pidx in range(n_perturbations):
            start = tidxs_in_perturbation[ridx,pidx,0]
            end = tidxs_in_perturbation[ridx,pidx,1]
            if start == -1:
                continue
            base_col_idx = pidx * n_taxa
            for oidx in range(n_taxa):
                col = oidx + base_col_idx
                for tidx in range(start, end):
                    rows[i] = oidx + tidx * n_taxa + base_row_idx
                    cols[i] = col
                    i += 1

        base_row_idx = base_row_idx + n_taxa * n_dts_for_replicate[ridx]</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.PerturbationBaseDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    growths = self.growths.value # these are the current values of the growth parameters for each taxa
    i = 0
    for ridx in range(self.n_replicates):
        l = self.tidxs_in_pert_per_replicate[ridx] * self.n_taxa
        PerturbationBaseDesignMatrix.fast_build(
            ret=self.data[i:i+l], 
            n_perturbations=self.n_perturbations, 
            n_taxa=self.n_taxa, 
            n_replicates=self.n_replicates, 
            tidxs_in_perturbation=self.tidxs_in_perturbation[ridx], 
            growths=growths, 
            data=self.G.data.data[ridx])
        i += l

    self.matrix = scipy.sparse.coo_matrix(
        (self.data,(self.rows,self.cols)),shape=self.shape).tocsc()</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.PerturbationBaseDesignMatrix.set_to_rhs"><code class="name flex">
<span>def <span class="ident">set_to_rhs</span></span>(<span>self) â€‘>Â scipy.sparse.base.spmatrix</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
    return self.matrix</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.DesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.PerturbationDesignMatrix"><code class="flex name class">
<span>class <span class="ident">PerturbationDesignMatrix</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the design matrix for the perturbations.</p>
<p>This matrix is composed of two, individual design matrices, <code>Base</code> and <code>M</code>.
To make the matrix that we use during inference, we matrix multiply <code>Base</code>@<code>M</code>,
which is what this class is for. It wraps these two base classes so that it
is more streamlined in the inference code.</p>
<p><code>Base</code> : mdsine2.design_matrices.PerturbationBaseDesignMatrix
This is an object that builds the perturbation matrix as if there was no
clustering or indicators. It builds the data for all the Taxas and
as if every perturbation indicator was on. This is actually faster than
just building it for individual indicators for a few different reasons:
1) We only need to update <code>Base</code> when we do filtering or update the
values of the growth matrix because these are the only two things
that <code>Base</code> is dependent on.
2) Because we don't have to check indicators or have different shapes
when building the matrix, it is much easier to build this matrix
with Numba, which is nearly as fast as C.
<code>Mixing</code> : mdsine2.design_matrices.PerturbationMixingDesignMatrix
This is the object that selects for indicators and groups taxa together
into clusters. When we change the indicators of the perturbations or
the cluster assignments of the taxa, we only need to change this matrix,
which is a lot faster than changing everything.</p>
<h2 id="see-also">See Also</h2>
<p><code>mdsine2.data_matrices.PerturbationBaseDesignMatrix</code>
<code>mdsine2.data_matrices.PerturbationBaseDesignMatrix</code></p>
<p><code>Parameters</code></p>
<p><code>varname (str) - This is the name of the variable we are building it for</code>
<code>update (bool) - If True</code>, <code>this matrix gets updated when <a title="mdsine2.design_matrices.Data.update_values" href="#mdsine2.design_matrices.Data.update_values">Data.update_values()</a> is called.</code>
<code>add_to_dict (bool) - If True</code>, <code>it adds to the design_matrices dictionary. - Else it does not</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PerturbationDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Builds the design matrix for the perturbations.

    This matrix is composed of two, individual design matrices, `Base` and `M`.
    To make the matrix that we use during inference, we matrix multiply `Base`@`M`,
    which is what this class is for. It wraps these two base classes so that it
    is more streamlined in the inference code.

    `Base` : mdsine2.design_matrices.PerturbationBaseDesignMatrix
        This is an object that builds the perturbation matrix as if there was no
        clustering or indicators. It builds the data for all the Taxas and
        as if every perturbation indicator was on. This is actually faster than
        just building it for individual indicators for a few different reasons:
            1) We only need to update `Base` when we do filtering or update the 
               values of the growth matrix because these are the only two things
               that `Base` is dependent on.
            2) Because we don&#39;t have to check indicators or have different shapes
               when building the matrix, it is much easier to build this matrix
               with Numba, which is nearly as fast as C.
    `Mixing` : mdsine2.design_matrices.PerturbationMixingDesignMatrix
        This is the object that selects for indicators and groups taxa together
        into clusters. When we change the indicators of the perturbations or 
        the cluster assignments of the taxa, we only need to change this matrix,
        which is a lot faster than changing everything.

    See Also
    --------
    mdsine2.data_matrices.PerturbationBaseDesignMatrix
    mdsine2.data_matrices.PerturbationBaseDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self, varname=STRNAMES.PERT_VALUE, **kwargs)

        self.n_rows = self.G.data.total_n_dts_per_taxa * self.G.data.n_taxa
        self.n_cols = None

        self.base = PerturbationBaseDesignMatrix(add_to_dict=False, **kwargs)
        self.M = PerturbationMixingDesignMatrix(add_to_dict=False, parent=self, **kwargs)

    def set_to_lhs(self) -&gt; np.ndarray:
        # Make the perturbation vector
        b = self.G[STRNAMES.PERT_VALUE].toarray().reshape(-1,1)

        return self.matrix.dot(b)

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        return self.matrix

    def update_values(self):
        # self.build()
        self.base.update_value()
        self.build()

    def build(self):
        self.matrix = self.base.matrix @ self.M.matrix
        self.n_cols = self.matrix.shape[1]
        self.shape = self.matrix.shape</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.PerturbationDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    self.matrix = self.base.matrix @ self.M.matrix
    self.n_cols = self.matrix.shape[1]
    self.shape = self.matrix.shape</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.PerturbationDesignMatrix.set_to_rhs"><code class="name flex">
<span>def <span class="ident">set_to_rhs</span></span>(<span>self) â€‘>Â scipy.sparse.base.spmatrix</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
    return self.matrix</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.PerturbationDesignMatrix.update_values"><code class="name flex">
<span>def <span class="ident">update_values</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_values(self):
    # self.build()
    self.base.update_value()
    self.build()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.DesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.PerturbationMixingDesignMatrix"><code class="flex name class">
<span>class <span class="ident">PerturbationMixingDesignMatrix</span></span>
<span>(</span><span>parent:Â <a title="mdsine2.design_matrices.PerturbationDesignMatrix" href="#mdsine2.design_matrices.PerturbationDesignMatrix">PerturbationDesignMatrix</a>, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This class creates the permutation matrix required for mixing the base matrix into
cluster effects</p>
<h2 id="see-also">See Also</h2>
<p><code>mdsine2.data_matrices.PerturbationBaseDesignMatrix</code>
<code>mdsine2.data_matrices.PerturbationDesignMatrix</code></p>
<p><code>Parameters</code></p>
<p><code>varname (str) - This is the name of the variable we are building it for</code>
<code>update (bool) - If True</code>, <code>this matrix gets updated when <a title="mdsine2.design_matrices.Data.update_values" href="#mdsine2.design_matrices.Data.update_values">Data.update_values()</a> is called.</code>
<code>add_to_dict (bool) - If True</code>, <code>it adds to the design_matrices dictionary. - Else it does not</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PerturbationMixingDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;This class creates the permutation matrix required for mixing the base matrix into
    cluster effects

    See Also
    --------
    mdsine2.data_matrices.PerturbationBaseDesignMatrix
    mdsine2.data_matrices.PerturbationDesignMatrix
    &#39;&#39;&#39;
    def __init__(self, parent: &#34;PerturbationDesignMatrix&#34;, **kwargs):
        DesignMatrix.__init__(self,
            varname=STRNAMES.PERT_VALUE+&#39;mixing_matrix&#39;,
            **kwargs)

        self.parent = parent # This is the PerturbationDesignMatrix object
        self.perturbations = self.G.perturbations # pylab.base.Perturbations
        self.n_perturbations = len(self.perturbations) # int
        self.n_taxa = len(self.G.data.taxa) # int
        self.n_rows = self.n_perturbations * self.n_taxa # int

        # Maps a taxa and a perturbation to the column it corresponds to in `base`
        self.keypair2col = np.zeros(shape=(self.n_taxa, self.n_perturbations), dtype=int)
        i = 0
        for pidx in range(self.n_perturbations):
            for oidx in range(self.n_taxa):
                self.keypair2col[oidx, pidx] = i
                i += 1
        self.build(build=False)

    # @profile
    def build(self, build: bool=True, build_for_neg_ind: bool=False, only_cids: List[int]=None):
        &#39;&#39;&#39;Build the matrix

        Parameters
        ----------
        build : bool
            If True, the parent will re-build as well
        build_for_neg_ind : bool
            If True, it will build for negative indicators as well
        only_cids : list, None
            If specified, it will only build for the cids specified.
        &#39;&#39;&#39;
        if only_cids is not None:
            oc = OrderedSet(list(only_cids))
        else:
            oc = None
        keypair2col = self.keypair2col
        rows = []
        cols = []
        col = 0
        for pidx, perturbation in enumerate(self.G.perturbations):
            ind = perturbation.indicator.value
            order = perturbation.clustering.order
            for cid in order:
                if oc is not None:
                    if cid not in oc:
                        continue
                if ind[cid] or build_for_neg_ind:
                    for oidx in perturbation.clustering[cid].members:
                        rows.append(keypair2col[oidx, pidx])
                        cols.append(col)
                    col += 1
        self._make_matrix(rows=rows, cols=cols, n_cols=col, build=build)

    # @profile
    def _make_matrix(self, rows: np.ndarray, cols: np.ndarray, n_cols: int, build: bool):
        &#39;&#39;&#39;Builds the mixing matrix from the specified rows and columns
        (data is always going to be 1 because it is a mixing matrix)

        Rebuild after we have changed the mixing matrix if `build` is True
        &#39;&#39;&#39;
        data = np.ones(len(rows), dtype=np.float64)
        self.matrix = scipy.sparse.coo_matrix((data,(rows,cols)),
            shape=(self.n_rows, n_cols)).tocsc()
        self.shape = self.matrix.shape
        self.n_rows = self.shape[0]
        self.n_cols = self.shape[1]
        if build:
            self.parent.build()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.PerturbationMixingDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, build:Â boolÂ =Â True, build_for_neg_ind:Â boolÂ =Â False, only_cids:Â List[int]Â =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Build the matrix</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>build</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, the parent will re-build as well</dd>
<dt><strong><code>build_for_neg_ind</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, it will build for negative indicators as well</dd>
<dt><strong><code>only_cids</code></strong> :&ensp;<code>list, None</code></dt>
<dd>If specified, it will only build for the cids specified.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self, build: bool=True, build_for_neg_ind: bool=False, only_cids: List[int]=None):
    &#39;&#39;&#39;Build the matrix

    Parameters
    ----------
    build : bool
        If True, the parent will re-build as well
    build_for_neg_ind : bool
        If True, it will build for negative indicators as well
    only_cids : list, None
        If specified, it will only build for the cids specified.
    &#39;&#39;&#39;
    if only_cids is not None:
        oc = OrderedSet(list(only_cids))
    else:
        oc = None
    keypair2col = self.keypair2col
    rows = []
    cols = []
    col = 0
    for pidx, perturbation in enumerate(self.G.perturbations):
        ind = perturbation.indicator.value
        order = perturbation.clustering.order
        for cid in order:
            if oc is not None:
                if cid not in oc:
                    continue
            if ind[cid] or build_for_neg_ind:
                for oidx in perturbation.clustering[cid].members:
                    rows.append(keypair2col[oidx, pidx])
                    cols.append(col)
                col += 1
    self._make_matrix(rows=rows, cols=cols, n_cols=col, build=build)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.DesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.design_matrices.SelfInteractionDesignMatrix"><code class="flex name class">
<span>class <span class="ident">SelfInteractionDesignMatrix</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Base matrix class for growth and self interactions
Since the dynamics subtract the self-interaction parameter, we set the
parameter to positive, which means our data is negative.</p>
<p>We build this matrix as a scipy sparse matrix, then convert it to a
numpy array if necessary. Since the shape of the sparse matrix does
not change during inference, we can premake the rows and columns during initialization,
which is done below.</p>
<p>Parameters</p>
<p>varname (str)
- This is the name of the variable we are building it for
update (bool)
- If True, this matrix gets updated when Data.update_values() is
called.
add_to_dict (bool)
- If True, it adds to the design_matrices dictionary.
- Else it does not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SelfInteractionDesignMatrix(DesignMatrix):
    &#39;&#39;&#39;Base matrix class for growth and self interactions
    Since the dynamics subtract the self-interaction parameter, we set the
    parameter to positive, which means our data is negative.

    We build this matrix as a scipy sparse matrix, then convert it to a 
    numpy array if necessary. Since the shape of the sparse matrix does
    not change during inference, we can premake the rows and columns during initialization,
    which is done below.
    &#39;&#39;&#39;
    def __init__(self, **kwargs):
        DesignMatrix.__init__(self, varname=STRNAMES.SELF_INTERACTION_VALUE,
            update=True, **kwargs)
        self.n_cols_master = self.G.data.n_taxa # 
        total_n_dts = self.G.data.total_n_dts_per_taxa
        self.n_rows_master = self.n_cols_master * total_n_dts
        self.master_rows = np.arange(self.n_rows_master, dtype=int)
        self.master_cols = np.kron(
                np.ones(total_n_dts, dtype=int),
                np.arange(self.G.data.n_taxa,dtype=int))
        logging.info(&#39;Initializing self-interactions design matrix&#39;)

    def build(self):
        &#39;&#39;&#39;Builds the matrix. Flatten Fortran style
        &#39;&#39;&#39;
        self.rows = self.master_rows
        self.cols = self.master_cols

        self.data = np.zeros(self.n_rows_master, dtype=float)
        data = self.G.data.data
        i = 0
        for ridx in range(self.G.data.n_replicates):
            l = (self.G.data.n_dts_for_replicate[ridx]) * self.G.data.n_taxa
            self.data[i:i+l] = -data[ridx][:,:-1].ravel(&#39;F&#39;)
            i += l
            
        shape = (self.n_rows_master, self.n_cols_master)
        self.matrix = scipy.sparse.coo_matrix(
            (self.data,(self.rows,self.cols)), shape=shape).tocsc()
        if self.G.data.zero_inflation_transition_policy is not None:
            self.matrix = self.matrix[self.G.data.rows_to_include_zero_inflation, :]


    def set_to_lhs(self) -&gt; np.ndarray:
        &#39;&#39;&#39;Multiply self.matrix by the current value of
        growth/self interaction
        &#39;&#39;&#39;
        b = self.G[self.varname].value.reshape(-1,1)
        return self.matrix.dot(b)

    def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
        &#39;&#39;&#39;Add in perturbations
        &#39;&#39;&#39;
        return self.matrix

    def update_value(self):
        self.build()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.design_matrices.SelfInteractionDesignMatrix.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the matrix. Flatten Fortran style</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self):
    &#39;&#39;&#39;Builds the matrix. Flatten Fortran style
    &#39;&#39;&#39;
    self.rows = self.master_rows
    self.cols = self.master_cols

    self.data = np.zeros(self.n_rows_master, dtype=float)
    data = self.G.data.data
    i = 0
    for ridx in range(self.G.data.n_replicates):
        l = (self.G.data.n_dts_for_replicate[ridx]) * self.G.data.n_taxa
        self.data[i:i+l] = -data[ridx][:,:-1].ravel(&#39;F&#39;)
        i += l
        
    shape = (self.n_rows_master, self.n_cols_master)
    self.matrix = scipy.sparse.coo_matrix(
        (self.data,(self.rows,self.cols)), shape=shape).tocsc()
    if self.G.data.zero_inflation_transition_policy is not None:
        self.matrix = self.matrix[self.G.data.rows_to_include_zero_inflation, :]</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.SelfInteractionDesignMatrix.set_to_lhs"><code class="name flex">
<span>def <span class="ident">set_to_lhs</span></span>(<span>self) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Multiply self.matrix by the current value of
growth/self interaction</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_lhs(self) -&gt; np.ndarray:
    &#39;&#39;&#39;Multiply self.matrix by the current value of
    growth/self interaction
    &#39;&#39;&#39;
    b = self.G[self.varname].value.reshape(-1,1)
    return self.matrix.dot(b)</code></pre>
</details>
</dd>
<dt id="mdsine2.design_matrices.SelfInteractionDesignMatrix.set_to_rhs"><code class="name flex">
<span>def <span class="ident">set_to_rhs</span></span>(<span>self) â€‘>Â scipy.sparse.base.spmatrix</span>
</code></dt>
<dd>
<div class="desc"><p>Add in perturbations</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_rhs(self) -&gt; scipy.sparse.spmatrix:
    &#39;&#39;&#39;Add in perturbations
    &#39;&#39;&#39;
    return self.matrix</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#main-classes">Main classes</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mdsine2" href="index.html">mdsine2</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mdsine2.design_matrices.Data" href="#mdsine2.design_matrices.Data">Data</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.Data.construct_lhs" href="#mdsine2.design_matrices.Data.construct_lhs">construct_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.construct_rhs" href="#mdsine2.design_matrices.Data.construct_rhs">construct_rhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.is_intermediate_timeindex" href="#mdsine2.design_matrices.Data.is_intermediate_timeindex">is_intermediate_timeindex</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.is_intermediate_timepoint" href="#mdsine2.design_matrices.Data.is_intermediate_timepoint">is_intermediate_timepoint</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.is_timepoint_structural_zero" href="#mdsine2.design_matrices.Data.is_timepoint_structural_zero">is_timepoint_structural_zero</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.iter_for_building" href="#mdsine2.design_matrices.Data.iter_for_building">iter_for_building</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.make_delta_t" href="#mdsine2.design_matrices.Data.make_delta_t">make_delta_t</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.set_timepoints" href="#mdsine2.design_matrices.Data.set_timepoints">set_timepoints</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.set_zero_inflation" href="#mdsine2.design_matrices.Data.set_zero_inflation">set_zero_inflation</a></code></li>
<li><code><a title="mdsine2.design_matrices.Data.update_values" href="#mdsine2.design_matrices.Data.update_values">update_values</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.DesignMatrix" href="#mdsine2.design_matrices.DesignMatrix">DesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.DesignMatrix.build" href="#mdsine2.design_matrices.DesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.DesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.toarray" href="#mdsine2.design_matrices.DesignMatrix.toarray">toarray</a></code></li>
<li><code><a title="mdsine2.design_matrices.DesignMatrix.update_value" href="#mdsine2.design_matrices.DesignMatrix.update_value">update_value</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.GrowthDesignMatrix" href="#mdsine2.design_matrices.GrowthDesignMatrix">GrowthDesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.GrowthDesignMatrix.build" href="#mdsine2.design_matrices.GrowthDesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.GrowthDesignMatrix.build_with_perturbations" href="#mdsine2.design_matrices.GrowthDesignMatrix.build_with_perturbations">build_with_perturbations</a></code></li>
<li><code><a title="mdsine2.design_matrices.GrowthDesignMatrix.build_without_perturbations" href="#mdsine2.design_matrices.GrowthDesignMatrix.build_without_perturbations">build_without_perturbations</a></code></li>
<li><code><a title="mdsine2.design_matrices.GrowthDesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.GrowthDesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.GrowthDesignMatrix.set_to_rhs" href="#mdsine2.design_matrices.GrowthDesignMatrix.set_to_rhs">set_to_rhs</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix">InteractionsBaseDesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix.build" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsBaseDesignMatrix.set_to_rhs" href="#mdsine2.design_matrices.InteractionsBaseDesignMatrix.set_to_rhs">set_to_rhs</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.InteractionsDesignMatrix" href="#mdsine2.design_matrices.InteractionsDesignMatrix">InteractionsDesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.InteractionsDesignMatrix.build" href="#mdsine2.design_matrices.InteractionsDesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsDesignMatrix.set_to_rhs" href="#mdsine2.design_matrices.InteractionsDesignMatrix.set_to_rhs">set_to_rhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsDesignMatrix.shape" href="#mdsine2.design_matrices.InteractionsDesignMatrix.shape">shape</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix">InteractionsMixingDesignMatrix</a></code></h4>
<ul class="two-column">
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_clustering" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_clustering">build_clustering</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_for_cols" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_for_cols">build_for_cols</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_for_specified" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_for_specified">build_for_specified</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_to_and_from" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.build_to_and_from">build_to_and_from</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.get_indices" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.get_indices">get_indices</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner">inner</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner_faster" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner_faster">inner_faster</a></code></li>
<li><code><a title="mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner_faster_faster" href="#mdsine2.design_matrices.InteractionsMixingDesignMatrix.inner_faster_faster">inner_faster_faster</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.LHSVector" href="#mdsine2.design_matrices.LHSVector">LHSVector</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.LHSVector.build" href="#mdsine2.design_matrices.LHSVector.build">build</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.ObservationVector" href="#mdsine2.design_matrices.ObservationVector">ObservationVector</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.ObservationVector.build" href="#mdsine2.design_matrices.ObservationVector.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.ObservationVector.update_value" href="#mdsine2.design_matrices.ObservationVector.update_value">update_value</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.PerturbationBaseDesignMatrix" href="#mdsine2.design_matrices.PerturbationBaseDesignMatrix">PerturbationBaseDesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.PerturbationBaseDesignMatrix.build" href="#mdsine2.design_matrices.PerturbationBaseDesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.PerturbationBaseDesignMatrix.fast_build" href="#mdsine2.design_matrices.PerturbationBaseDesignMatrix.fast_build">fast_build</a></code></li>
<li><code><a title="mdsine2.design_matrices.PerturbationBaseDesignMatrix.init" href="#mdsine2.design_matrices.PerturbationBaseDesignMatrix.init">init</a></code></li>
<li><code><a title="mdsine2.design_matrices.PerturbationBaseDesignMatrix.set_to_rhs" href="#mdsine2.design_matrices.PerturbationBaseDesignMatrix.set_to_rhs">set_to_rhs</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.PerturbationDesignMatrix" href="#mdsine2.design_matrices.PerturbationDesignMatrix">PerturbationDesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.PerturbationDesignMatrix.build" href="#mdsine2.design_matrices.PerturbationDesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.PerturbationDesignMatrix.set_to_rhs" href="#mdsine2.design_matrices.PerturbationDesignMatrix.set_to_rhs">set_to_rhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.PerturbationDesignMatrix.update_values" href="#mdsine2.design_matrices.PerturbationDesignMatrix.update_values">update_values</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.PerturbationMixingDesignMatrix" href="#mdsine2.design_matrices.PerturbationMixingDesignMatrix">PerturbationMixingDesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.PerturbationMixingDesignMatrix.build" href="#mdsine2.design_matrices.PerturbationMixingDesignMatrix.build">build</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.design_matrices.SelfInteractionDesignMatrix" href="#mdsine2.design_matrices.SelfInteractionDesignMatrix">SelfInteractionDesignMatrix</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.design_matrices.SelfInteractionDesignMatrix.build" href="#mdsine2.design_matrices.SelfInteractionDesignMatrix.build">build</a></code></li>
<li><code><a title="mdsine2.design_matrices.SelfInteractionDesignMatrix.set_to_lhs" href="#mdsine2.design_matrices.SelfInteractionDesignMatrix.set_to_lhs">set_to_lhs</a></code></li>
<li><code><a title="mdsine2.design_matrices.SelfInteractionDesignMatrix.set_to_rhs" href="#mdsine2.design_matrices.SelfInteractionDesignMatrix.set_to_rhs">set_to_rhs</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>