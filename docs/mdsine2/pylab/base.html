<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>mdsine2.pylab.base API documentation</title>
<meta name="description" content="These are base classes that are used throughout the rest of Pylab" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mdsine2.pylab.base</code></h1>
</header>
<section id="section-intro">
<p>These are base classes that are used throughout the rest of Pylab</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;These are base classes that are used throughout the rest of Pylab

&#39;&#39;&#39;

import numpy as np
import collections
import pickle
import scipy.spatial.distance
import pandas as pd
import logging
import os
import os.path
import copy

# Typing
from typing import TypeVar, Generic, Any, Union, Dict, Iterator, Tuple

from . import util as plutil
from .errors import NeedToImplementError
from . import diversity

# Constants
DEFAULT_TAXLEVEL_NAME = &#39;NA&#39;
SEQUENCE_COLUMN_LABEL = &#39;sequence&#39;
TAX_IDXS = {&#39;kingdom&#39;: 0, &#39;phylum&#39;: 1, &#39;class&#39;: 2,  &#39;order&#39;: 3, &#39;family&#39;: 4, 
    &#39;genus&#39;: 5, &#39;species&#39;: 6, &#39;asv&#39;: 7}
TAX_LEVELS = [&#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;, &#39;species&#39;, &#39;asv&#39;]

# Constants
NAME_FORMATTER = &#39;%(name)s&#39;
ID_FORMATTER = &#39;%(id)s&#39;
INDEX_FORMATTER = &#39;%(index)s&#39;
SPECIES_FORMATTER = &#39;%(species)s&#39;
GENUS_FORMATTER = &#39;%(genus)s&#39;
FAMILY_FORMATTER = &#39;%(family)s&#39;
CLASS_FORMATTER = &#39;%(class)s&#39;
ORDER_FORMATTER = &#39;%(order)s&#39;
PHYLUM_FORMATTER = &#39;%(phylum)s&#39;
KINGDOM_FORMATTER = &#39;%(kingdom)s&#39;
PAPER_FORMATTER = &#39;%(paperformat)s&#39;

_TAXFORMATTERS = [&#39;%(species)s&#39;, &#39;%(genus)s&#39;, &#39;%(family)s&#39;, &#39;%(class)s&#39;, &#39;%(order)s&#39;, &#39;%(phylum)s&#39;, &#39;%(kingdom)s&#39;]
TAXANAME_PAPER_FORMAT = float(&#39;inf&#39;)

def isqpcrdata(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of qPCRData

    Parameters
    ----------
    x : any
        Input instance to check the type of qPCRData
    
    Returns
    -------
    bool
        True if `x` is of type qPCRData, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, qPCRdata)

def istaxaset(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of TaxaSet

    Parameters
    ----------
    x : any
        Input instance to check the type of TaxaSet
    
    Returns
    -------
    bool
        True if `x` is of type TaxaSet, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, TaxaSet)

def issavable(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Savable

    Parameters
    ----------
    x : any
        Input instance to check the type of Savable
    
    Returns
    -------
    bool
        True if `x` is of type Savable, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Saveable)

def isclusterable(x: Any) -&gt; bool:
    &#39;&#39;&#39;Determines whether the input is a subclass of Clusterable

    Parameters
    ----------
    x : any
        Input instance to check the type of Clusterable
    
    Returns
    -------
    bool
        True if `x` is of type Clusterable, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Clusterable)

def istraceable(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Traceable

    Parameters
    ----------
    x : any
        Input instance to check the type of Traceable
    
    Returns
    -------
    bool
        True if `x` is of type Traceable, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Traceable)

def istaxon(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Taxon

    Parameters
    ----------
    x : any
        Input instance to check the type of Taxon
    
    Returns
    -------
    bool
        True if `x` is of type Taxon, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Taxon)

def isotu(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of OTU

    Parameters
    ----------
    x : any
        Input instance to check the type of OTU
    
    Returns
    -------
    bool
        True if `x` is of type OTU, else False
    &#39;&#39;&#39;
    return issubclass(x.__class__, OTU)

def istaxontype(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of OTU or Taxon

    Parameters
    ----------
    x : any
        Input instance to check the type of OTU or Taxon
    
    Returns
    -------
    bool
        True if `x` is of type OTU or Taxon, else False
    &#39;&#39;&#39;
    return istaxon(x) or isotu(x)

def issubject(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Subject

    Parameters
    ----------
    x : any
        Input instance to check the type of Subject
    
    Returns
    -------
    bool
        True if `x` is of type Subject, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Subject)

def isstudy(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Study

    Parameters
    ----------
    x : any
        Input instance to check the type of Study
    
    Returns
    -------
    bool
        True if `x` is of type Study, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Study)

def isperturbation(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of BasePerturbation

    Parameters
    ----------
    x : any
        Input instance to check the type of BasePerturbation
    
    Returns
    -------
    bool
        True if `x` is of type BasePerturbation, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, BasePerturbation)

def condense_matrix_with_taxonomy(M: Union[pd.DataFrame, np.ndarray], taxa: &#39;TaxaSet&#39;, fmt: str) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Condense the specified matrix M thats on the asv level
    to a taxonomic label specified with `fmt`. If `M` 
    is a pandas.DataFrame then we assume the index are the Taxon
    names. If `M` is a numpy.ndarray, then we assume that the 
    order of the matrix mirrors the order of the taxa. `fmt` is
    passed through `pylab.base.taxaname_formatter` to get the label.

    Parameters
    ----------
    M : numpy.ndarray, pandas.DataFrame
        Matrix to condense
    taxa : pylab.base.TaxaSet
        Set of Taxa with the relevant taxonomic information
    taxlevel : str
        This is the taxonomic level to condense to

    Returns
    -------
    pandas.DataFrame
        The index are the taxonomic classes. If M was a pandas.DataFrame, then
        the columns in M correspond to these columns. If `M` was a 
        numpy.ndarray, then the order of the columsn correspond and no names
        are sent.
    &#39;&#39;&#39;
    if not istaxaset(taxa):
        raise TypeError(&#39;`taxa` ({}) must be a pylab.base.TaxaSet&#39;.format(type(taxa)))
    if not plutil.isstr(fmt):
        raise TypeError(&#39;`fmt` ({}) must be a str&#39;.format(type(fmt)))

    if type(M) == pd.DataFrame:
        for idx in M.index:
            if idx not in taxa:
                raise ValueError(&#39;row `{}` not found in taxa&#39;.format(idx))
        names = M.index
    elif plutil.isarray(M):
        if M.shape[0] != len(taxa):
            raise ValueError(&#39;Number of rows in M ({}) not equal to number of taxa ({})&#39;.format(
                M.shape[0], len(taxa)))
        names = taxa.names.order
    else:
        raise TypeError(&#39;`M` ({}) type not recognized&#39;.format(type(M)))

    # Get the rows that correspond to each row
    d = {}
    for row, name in enumerate(names):
        taxon = taxa[name]
        tax = taxaname_formatter(format=fmt, taxon=taxon, taxa=taxa)
        if tax not in d:
            d[tax] = []
        d[tax].append(row)

    # Add all of the rows for each taxon
    Ms = ()
    index = []
    columns = None
    if not plutil.isarray(M):
        columns = M.columns
    for taxname, rows, in d.items():
        index.append(taxname)
        if plutil.isarray(M):
            temp = np.sum(M[rows, ...], axis=0).reshape(1,-1)
        else:
            temp = np.sum(M.iloc[rows], axis=0).reshape(1,-1)
        Ms = Ms + (temp, )
    matrix = np.vstack(Ms)
    df = pd.DataFrame(matrix, index=index, columns=columns)
    df = df.sort_index(axis=&#39;index&#39;)
    return df

def taxaname_for_paper(taxon: Union[&#34;Taxon&#34;, &#34;OTU&#34;], taxa: &#34;TaxaSet&#34;) -&gt; str:
    &#39;&#39;&#39;Makes the name in the format needed for the paper

    Parameters
    ----------
    taxon : pylab.base.Taxon/pylab.base.OTU
        This is the taxon we are making the name for
    taxa : pylab.base.TaxaSet
        This is the TaxaSet object that contains the taxon objects

    Returns
    -------
    str
    &#39;&#39;&#39;
    taxon = taxa[taxon]
    if taxon.tax_is_defined(&#39;species&#39;):
        species = taxon.taxonomy[&#39;species&#39;]
        species = species.split(&#39;/&#39;)
        if len(species) &gt;= 3:
            species = species[:2]
        species = &#39;/&#39;.join(species)
        label = taxaname_formatter(
            format=&#39;%(genus)s {spec} %(name)s&#39;.format(
                spec=species), 
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;genus&#39;):
        label = taxaname_formatter(
            format=&#39;* %(genus)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;family&#39;):
        label = taxaname_formatter(
            format=&#39;** %(family)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;order&#39;):
        label = taxaname_formatter(
            format=&#39;*** %(order)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;class&#39;):
        label = taxaname_formatter(
            format=&#39;**** %(class)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;phylum&#39;):
        label = taxaname_formatter(
            format=&#39;***** %(phylum)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;kingdom&#39;):
        label = taxaname_formatter(
            format=&#39;****** %(kingdom)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    else:
        logging.debug(&#39;Something went wrong - no taxnonomy: {}&#39;.format(str(taxon)))
        label = &#39;NA {}&#39;.format(taxa[taxon].name)

    return label

def taxaname_formatter(format: str, taxon: Union[&#34;Taxon&#34;, &#34;OTU&#34;], taxa: &#34;TaxaSet&#34;) -&gt; str:
    &#39;&#39;&#39;Format the label of a taxon. Specify the taxon by its index in the TaxaSet `taxa`.

    If `format == mdsine.TAXANAME_PAPER_FORMAT`, then we call the function
    `taxaname_for_paper`.

    Example:
        taxon is an Taxon object at index 0 where:
        ```
        taxon.genus = &#39;A&#39;
        taxon.id = 1234532
        ```
        In[1]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(genus)s: %(index)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;A: 0&#39;
        ```
        In[2]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(genus)s: %(genus)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;A: A&#39;
        ```
        In[3]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(index)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;0&#39;
        ```
        In[4]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(geNus)s: %(genus)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;%(geNus)s: A&#39;
        ```

    Parameters
    ----------
    format : str
        - This is the format for us to do the labels. Options:
            - &#39;%(paperformat)s&#39;
                * Return the `taxaname_for_paper`
            - &#39;%(name)s&#39;
                * Name of the taxon (pylab.base..name)
            - &#39;%(id)s&#39;
                * ID of the taxon (pylab.base..id)
            - &#39;%(index)s&#39;
                * The order that this appears in the TaxaSet
            - &#39;%(species)s&#39;
                * `&#39;species&#39;` taxonomic classification of the taxon
            - &#39;%(genus)s&#39;
                * `&#39;genus&#39;` taxonomic classification of the taxon
            - &#39;%(family)s&#39;
                * `&#39;family&#39;` taxonomic classification of the taxon
            - &#39;%(class)s&#39;
                * `&#39;class&#39;` taxonomic classification of the taxon
            - &#39;%(order)s&#39;
                * `&#39;order&#39;` taxonomic classification of the taxon
            - &#39;%(phylum)s&#39;
                * `&#39;phylum&#39;` taxonomic classification of the taxon
            - &#39;%(kingdom)s&#39;
                * `&#39;kingdom&#39;` taxonomic classification of the taxon
    taxon : str, int, Taxon, OTU
        Taxon/OTU object or identifier (name, ID, index)
    taxa : pylab.base.TaxaSet
        Dataset containing all of the information for the taxa

    Returns
    -------
    str
    &#39;&#39;&#39;
    if format == TAXANAME_PAPER_FORMAT:
        return taxaname_for_paper(taxon=taxon, taxa=taxa)
    taxon = taxa[taxon]
    index = taxon.idx
    label = format.replace(NAME_FORMATTER, str(taxon.name))
    label = label.replace(ID_FORMATTER, str(taxon.id))
    label = label.replace(INDEX_FORMATTER,  str(index))

    if PAPER_FORMATTER in label:
        label = label.replace(PAPER_FORMATTER, &#39;%(temp)s&#39;)
        label = label.replace(&#39;%(temp)s&#39;, taxaname_for_paper(taxon=taxon, taxa=taxa))
    
    for i in range(len(TAX_LEVELS)-1):
        taxlevel = TAX_LEVELS[i]
        fmt = _TAXFORMATTERS[i]
        try:
            label = label.replace(fmt, str(taxon.get_taxonomy(taxlevel)))
        except:
            logging.critical(&#39;taxon: {}&#39;.format(taxon))
            logging.critical(&#39;fmt: {}&#39;.format(fmt))
            logging.critical(&#39;label: {}&#39;.format(label))
            raise

    return label


class Saveable:
    &#39;&#39;&#39;Implements baseline saving classes with pickle for classes
    &#39;&#39;&#39;
    def save(self, filename: str=None):
        &#39;&#39;&#39;Pickle the object

        Paramters
        ---------
        filename : str
            This is the location to store the file. Overrides the location if
            it is set using `pylab.base.Saveable.set_save_location`. If None
            it means that we are using the file location set in 
            set_location. 
        &#39;&#39;&#39;
        if filename is None:
            if not hasattr(self, &#39;_save_loc&#39;):
                raise TypeError(&#39;`filename` must be specified if you have not &#39; \
                    &#39;set the save location&#39;)
            filename = self._save_loc
        
        try:
            with open(str(filename), &#39;wb&#39;) as output:  # Overwrites any existing file.
                pickle.dump(self, output, protocol=pickle.HIGHEST_PROTOCOL)
        except:
            os.system(&#39;rm {}&#39;.format(filename))
            with open(str(filename), &#39;wb&#39;) as output:  # Overwrites any existing file.
                pickle.dump(self, output, protocol=pickle.HIGHEST_PROTOCOL)

    @classmethod
    def load(cls, filename: str):
        &#39;&#39;&#39;Unpickle the object

        Paramters
        ---------
        cls : type
            Type
        filename : str
            This is the location of the file to unpickle
        &#39;&#39;&#39;
        with open(str(filename), &#39;rb&#39;) as handle:
            b = pickle.load(handle)
        
        # redo the filename to the new path if it has a save location
        if not hasattr(b, &#39;_save_loc&#39;):
            filename = os.path.abspath(filename)
            b._save_loc = filename

        return b

    def set_save_location(self, filename: str):
        &#39;&#39;&#39;Set the save location for the object.

        Internally converts this to the absolute path

        Parameters
        ----------
        filename : str
            This is the path to set it to
        &#39;&#39;&#39;
        if not plutil.isstr(filename):
            raise TypeError(&#39;`filename` ({}) must be a str&#39;.format(type(filename)))
        filename = os.path.abspath(filename)
        self._save_loc = filename

    def get_save_location(self) -&gt; str:
        try:
            return self._save_loc
        except:
            raise AttributeError(&#39;Save location is not set.&#39;)


class Traceable:
    &#39;&#39;&#39;Defines the functionality for a Node to interact with the Graph tracer object
    &#39;&#39;&#39;

    def set_trace(self):
        &#39;&#39;&#39;Initialize the trace arrays for the variable in the Tracer object. 

        It will initialize a buffer the size of the checkpoint size in Tracer
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;User needs to define this function&#39;)

    def add_trace(self):
        &#39;&#39;&#39;Adds the current value to the trace. If the buffer is full
        it will end it to disk
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;User needs to define this function&#39;)

    def get_trace_from_disk(self, section: str = &#39;posterior&#39;, slices: slice = None) -&gt; np.ndarray:
        &#39;&#39;&#39;Returns the entire trace (after burnin) writen on the disk. NOTE: This may/may not 
        include the samples in the local buffer trace and could be very large

        Parameters
        ----------
        section : str
            Which part of the trace to return - description above
        slices : list(slice), slice
            A list of slicing objects or a slice object.

            slice(start, stop, step)
            Example, single dimension:
                slice(None) == :
                slice(5) == :5
                slice(4, None, None) == 4:
                slice(9, 22,None) == 9:22
            Example, multiple dimensions:
                [slice(None), slice(4, None, None)] == :, 4:
                [slice(None), 4, 5] == :, 4, 5

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        return self.G.tracer.get_trace(name=self.name, section=section, slices=slices)

    def overwrite_entire_trace_on_disk(self, data: np.ndarray, **kwargs):
        &#39;&#39;&#39;Overwrites the entire trace of the variable with the given data.

        Parameters
        ----------
        data : np.ndarray
            Data you are overwriting the trace with.
        &#39;&#39;&#39;
        self.G.tracer.overwrite_entire_trace_on_disk(
            name=self.name, data=data, dtype=self.dtype, **kwargs)

    def get_iter(self) -&gt; int:
        &#39;&#39;&#39;Get the number of iterations saved to the hdf5 file of the variable

        Returns
        -------
        int
        &#39;&#39;&#39;
        return self.G.tracer.get_iter(name=self.name)


class BasePerturbation:
    &#39;&#39;&#39;Base perturbation class. 

    Does not have to be applied to all subjects, and each subject can have a different start and
    end time to each other.

    Parameters
    ----------
    name : str, None
        - This is the name of the perturabtion. If nothing is given then the name will be
          set to the perturbation index
    starts, ends : dict, None
        - This is a map to the start and end times for the subject that have this perturbation
    &#39;&#39;&#39;
    def __init__(self, name: str, starts: Dict[str, float]=None, ends: Dict[str, float]=None):
        if not plutil.isstr(name):
            raise TypeError(&#39;`name` ({}) must be a str&#39;.format(type(name)))
        if (starts is not None and ends is None) or (starts is None and ends is not None):
            raise ValueError(&#39;If `starts` or `ends` is specified, the other must be specified.&#39;)
        if starts is not None:
            if not plutil.isdict(starts):
                raise TypeError(&#39;`starts` ({}) must be a dict&#39;.format(starts))
            if not plutil.isdict(ends):
                raise TypeError(&#39;`ends` ({}) must be a dict&#39;.format(ends))

        self.starts = starts
        self.ends = ends
        self.name = name

    def __str__(self) -&gt; str:
        s = &#39;Perturbation {}:\n&#39;.format(self.name)
        if self.starts is not None:
            for subj in self.starts:
                s += &#39;\tSubject {}: ({}, {})\n&#39;.format(subj, self.starts[subj], 
                    self.ends[subj])
        return s

    def __contains__(self, a: Union[str]) -&gt; bool:
        &#39;&#39;&#39;Checks if subject name `a` is in this perturbation
        &#39;&#39;&#39;
        if issubject(a):
            a = a.name
        return a in self.starts

    def isactive(self, time: Union[float, int], subj: str) -&gt; bool:
        &#39;&#39;&#39;Returns a `bool` if the perturbation is on at time `time`.

        Parameters
        ----------
        time : float, int
            Time to check
        subj : str
            Subject to check

        Returns
        -------
        bool

        Raises
        ------
        ValueError
            If there are no start and end times set
        &#39;&#39;&#39;
        if self.starts is None:
            raise ValueError(&#39;`start` is not set in {}&#39;.format(self.name))
        try:
            start = self.starts[subj]
            end = self.ends[subj]
        except:
            raise KeyError(&#39;`subj` {} not specified for {}&#39;.format(subj, self.name))

        return time &gt; start and time &lt;= end


class Perturbations:
    &#39;&#39;&#39;Aggregator for individual perturbation obejcts
    &#39;&#39;&#39;
    def __init__(self):
        self._d = {}
        self._rev_idx = []

    def __len__(self) -&gt; int:
        return len(self._d)

    def __getitem__(self, a: Union[BasePerturbation, int, str]) -&gt; BasePerturbation:
        &#39;&#39;&#39;Get the perturbation either by index, name, or object
        &#39;&#39;&#39;
        if isperturbation(a):
            if a.name in self:
                return a
            else:
                raise KeyError(&#39;`a` ({}) not contained in this Set&#39;.format(a))
        if plutil.isstr(a):
            return self._d[a]
        elif plutil.isint(a):
            return self._d[self._rev_idx[a]]
        else:
            raise KeyError(&#39;`a` {} ({}) not recognized&#39;.format(a, type(a)))

    def __contains__(self, a: Union[BasePerturbation, str, int]) -&gt; bool:
        try:
            _ = self[a]
            return True
        except:
            False

    def __iter__(self):
        for a in self._d:
            yield self._d[a]

    def append(self, a: BasePerturbation):
        &#39;&#39;&#39;Add a perturbation

        a : mdsine2.BasePertubration
            Perturbation to add
        &#39;&#39;&#39;
        if not isperturbation(a):
            raise TypeError(&#39;`a` ({}) must be a perturbation&#39;.format(type(a)))
        self._d[a.name] = a
        self._rev_idx.append(a.name)

    def remove(self, a: Union[BasePerturbation, str, int]):
        &#39;&#39;&#39;Remove the perturbation `a`. Can be either the name, index, or 
        the object itself.

        Parameters
        ----------
        a : str, int, mdsine2.BasePerturbation
            Perturbation to remove
        
        Returns
        -------
        mdsine2.BasePerturbation
        &#39;&#39;&#39;
        a = self[a]
        self._d.pop(a.name, None)
        self._rev_idx = []
        for mer in self._d:
            self._rev_idx.append(mer.name)
        return a


class ClusterItem:
    &#39;&#39;&#39;These are single points that get clustered

    It must have the parameter
        &#39;name&#39;
    &#39;&#39;&#39;
    def __init__(self, name: str):
        self.name = name

    def cluster_str(self) -&gt; str:
        return self.name


class Taxon(ClusterItem):
    &#39;&#39;&#39;Wrapper class for a single Taxon

    Parameters
    ----------
    name : str
        Name given to the Taxon
    sequence : str
        Base Pair sequence
    idx : int
        The index that the asv occurs
    &#39;&#39;&#39;
    def __init__(self, name: str, idx: int, sequence: Iterator[str]=None):
        ClusterItem.__init__(self, name=name)
        self.sequence = sequence
        self.idx = idx
        # Initialize the taxonomies to nothing
        self.taxonomy = {
            &#39;kingdom&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;phylum&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;class&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;order&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;family&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;genus&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;species&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;asv&#39;: self.name}
        self.id = id(self)

    def __eq__(self, val: Any) -&gt; bool:
        &#39;&#39;&#39;Compares different taxa between each other. Checks all of the attributes but the id

        Parameters
        ----------
        val : any
            This is what we are checking if they are equivalent
        &#39;&#39;&#39;
        if not istaxon(val):
            return False
        if self.name != val.name:
            return False
        if self.sequence != val.sequence:
            return False
        for k,v in self.taxonomy.items():
            if v != val.taxonomy[k]:
                return False
        return True

    def __str__(self) -&gt; str:
        return &#39;Taxon\n\tid: {}\n\tidx: {}\n\tname: {}\n&#39; \
            &#39;\ttaxonomy:\n\t\tkingdom: {}\n\t\tphylum: {}\n&#39; \
            &#39;\t\tclass: {}\n\t\torder: {}\n\t\tfamily: {}\n&#39; \
            &#39;\t\tgenus: {}\n\t\tspecies: {}&#39;.format(
            self.id, self.idx, self.name,
            self.taxonomy[&#39;kingdom&#39;], self.taxonomy[&#39;phylum&#39;],
            self.taxonomy[&#39;class&#39;], self.taxonomy[&#39;order&#39;],
            self.taxonomy[&#39;family&#39;], self.taxonomy[&#39;genus&#39;],
            self.taxonomy[&#39;species&#39;])

    def set_taxonomy(self, tax_kingdom: str=None, tax_phylum: str=None, tax_class: str=None,
        tax_order: str=None, tax_family: str=None, tax_genus: str=None, tax_species: str=None):
        &#39;&#39;&#39;Sets the taxonomy of the parts that are specified

        Parameters
        ----------
        tax_kingdom, tax_phylum, tax_class, tax_order, tax_family, tax_genus : str
            &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;
            Name of the taxon for each respective level
        &#39;&#39;&#39;
        if tax_kingdom is not None and tax_kingdom != &#39;&#39; and plutil.isstr(tax_kingdom):
            self.taxonomy[&#39;kingdom&#39;] = tax_kingdom
        if tax_phylum is not None and tax_phylum != &#39;&#39; and plutil.isstr(tax_phylum):
            self.taxonomy[&#39;phylum&#39;] = tax_phylum
        if tax_class is not None and tax_class != &#39;&#39; and plutil.isstr(tax_class):
            self.taxonomy[&#39;class&#39;] = tax_class
        if tax_order is not None and tax_order != &#39;&#39; and plutil.isstr(tax_order):
            self.taxonomy[&#39;order&#39;] = tax_order
        if tax_family is not None and tax_family != &#39;&#39; and plutil.isstr(tax_family):
            self.taxonomy[&#39;family&#39;] = tax_family
        if tax_genus is not None and tax_genus != &#39;&#39; and plutil.isstr(tax_genus):
            self.taxonomy[&#39;genus&#39;] = tax_genus
        if tax_species is not None and tax_species != &#39;&#39; and plutil.isstr(tax_species):
            self.taxonomy[&#39;species&#39;] = tax_species
        return self

    def get_lineage(self, level: str=None) -&gt; Iterator[str]:
        &#39;&#39;&#39;Returns a tuple of the lineage in order from Kingdom to the level
        indicated. Default value for level is `asv`.
        Parameters
        ----------
        level : str, Optional
            The taxonomic level you want the lineage until
            If nothing is provided, it returns the entire taxonomic lineage
            Example:
                level = &#39;class&#39;
                returns a tuple of (kingdom, phylum, class)
        Returns
        -------
        str
        &#39;&#39;&#39;
        a =  (self.taxonomy[&#39;kingdom&#39;], self.taxonomy[&#39;phylum&#39;], self.taxonomy[&#39;class&#39;],
            self.taxonomy[&#39;order&#39;], self.taxonomy[&#39;family&#39;], self.taxonomy[&#39;genus&#39;],
            self.taxonomy[&#39;species&#39;], self.taxonomy[&#39;asv&#39;])

        if level is None:
            a = a
        if level == &#39;asv&#39;:
            a = a
        elif level == &#39;species&#39;:
            a = a[:-1]
        elif level == &#39;genus&#39;:
            a = a[:-2]
        elif level == &#39;family&#39;:
            a = a[:-3]
        elif level == &#39;order&#39;:
            a = a[:-4]
        elif level == &#39;class&#39;:
            a = a[:-5]
        elif level == &#39;phylum&#39;:
            a = a[:-6]
        elif level == &#39;kingdom&#39;:
            a = a[:-7]
        else:
            raise ValueError(&#39;level `{}` was not recognized&#39;.format(level))

        return a
    
    def get_taxonomy(self, level: str) -&gt; str:
        &#39;&#39;&#39;Get the taxonomy at the level specified

        Parameters
        ----------
        level : str
            This is the level to get
            Valid responses: &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;

        Returns
        -------
        str
        &#39;&#39;&#39;
        return self.get_lineage(level=level)[-1]

    def tax_is_defined(self, level: str) -&gt; bool:
        &#39;&#39;&#39;Whether or not the taxon is defined at the specified taxonomic level

        Parameters
        ----------
        level : str
            This is the level to get
            Valid responses: &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;
        
        Returns
        -------
        bool
        &#39;&#39;&#39;
        try:
            tax = self.taxonomy[level]
        except:
            raise KeyError(&#39;`tax` ({}) not defined. Available taxs: {}&#39;.format(level, 
                list(self.taxonomy.keys())))
        return (type(tax) != float) and (tax != DEFAULT_TAXLEVEL_NAME) and (tax != &#39;&#39;)


class OTU(Taxon):
    &#39;&#39;&#39;Aggregates of Taxon objects

    NOTE: For self consistency, let the class TaxaSet initialize this object.

    Parameters
    ----------
    anchor, other : mdsine2.Taxon, mdsine2.OTU
        These are the taxa/Aggregates that you&#39;re joining together. The anchor is
        the one you are setting the sequeunce and taxonomy to
    &#39;&#39;&#39;
    def __init__(self, anchor: Union[Taxon, &#39;OTU&#39;], other: Union[Taxon, &#39;OTU&#39;]):
        name = anchor.name + &#39;_agg&#39;
        Taxon.__init__(self, name=name, idx=anchor.idx, sequence=anchor.sequence)

        _agg_taxa = {}

        if isotu(anchor):
            if other.name in anchor.aggregated_taxa:
                raise ValueError(&#39;`other` ({}) already aggregated with anchor &#39; \
                    &#39;({}) ({})&#39;.format(other.name, anchor.name, anchor.aggregated_taxa))
            agg1 = anchor.aggregated_taxa
            agg1_seq = anchor.aggregated_seqs
            for k,v in anchor.aggregated_taxonomies.items():
                _agg_taxa[k] = v
        else:
            agg1 = [anchor.name]
            agg1_seq = {anchor.name: anchor.sequence}
            _agg_taxa[anchor.name] = anchor.taxonomy

        if isotu(other):
            if anchor.name in other.aggregated_taxa:
                raise ValueError(&#39;`anchor` ({}) already aggregated with other &#39; \
                    &#39;({}) ({})&#39;.format(anchor.name, other.name, other.aggregated_taxa))
            agg2 = other.aggregated_taxa
            agg2_seq = other.aggregated_seqs
            for k,v in other.aggregated_taxonomies.items():
                _agg_taxa[k] = v
        else:
            agg2 = [other.name]
            agg2_seq = {other.name: other.sequence}
            _agg_taxa[other.name] = other.taxonomy

        self.aggregated_taxa = agg1 + agg2 # list
        self.aggregated_seqs = agg1_seq # dict: taxon.name (str) -&gt; sequence (str)
        self.aggregated_taxonomies = _agg_taxa # dict: taxon.name (str) -&gt; (dict: tax level (str) -&gt; taxonomy (str))
        for k,v in agg2_seq.items():
            self.aggregated_seqs[k] = v

        self.taxonomy = anchor.taxonomy

    def __str__(self) -&gt; str:
        return &#39;OTU\n\tid: {}\n\tidx: {}\n\tname: {}\n&#39; \
            &#39;\tAggregates: {}\n&#39; \
            &#39;\ttaxonomy:\n\t\tkingdom: {}\n\t\tphylum: {}\n&#39; \
            &#39;\t\tclass: {}\n\t\torder: {}\n\t\tfamily: {}\n&#39; \
            &#39;\t\tgenus: {}\n\t\tspecies: {}&#39;.format(
            self.id, self.idx, self.name, self.aggregated_taxa,
            self.taxonomy[&#39;kingdom&#39;], self.taxonomy[&#39;phylum&#39;],
            self.taxonomy[&#39;class&#39;], self.taxonomy[&#39;order&#39;],
            self.taxonomy[&#39;family&#39;], self.taxonomy[&#39;genus&#39;],
            self.taxonomy[&#39;species&#39;])

    def generate_consensus_seq(self, threshold: float=0.65, noconsensus_char: str=&#39;N&#39;):
        &#39;&#39;&#39;Generate the consensus sequence for the OTU given the sequences
        of all the contained ASVs

        Parameters
        ----------
        threshold : float
            This is the threshold for consensus (0 &lt; threshold &lt;= 1)
        noconsensus_char : str
            This is the character to set base if no consensus base is found
            at the respective position.

        NOTE
        ----
        Situation where all of the sequences are not the same length is not implemented
        &#39;&#39;&#39;
        if not plutil.isstr(noconsensus_char):
            raise TypeError(&#39;`noconsensus_char` ({}) must be a str&#39;.format(
                type(noconsensus_char)))
        if not plutil.isnumeric(threshold):
            raise TypeError(&#39;`threshold` ({}) must be a numeric&#39;.format(threshold))
        if threshold &lt; 0 or threshold &gt; 1:
            raise ValueError(&#39;`threshold` ({}) must be 0 &lt;= thresold &lt;= 1&#39;.format(threshold))

        # Check if all of the sequences are the same length
        agg_seqs = [seq for seq in self.aggregated_seqs.values()]
        l = None
        for seq in agg_seqs:
            if l is None:
                l = len(seq)
            if len(seq) != l:
                raise NotImplementedError(&#39;Unaligned sequences not implemented yet&#39;)

        # Generate the consensus base for each base position
        consensus_seq = &#39;&#39;
        for i in range(l):

            # Count the number of times each base occurs at position `i`
            found = {}
            for seq in agg_seqs:
                base = seq[i]
                if base not in found:
                    found[base] = 1
                else:
                    found[base] += 1

            # Set the base
            if len(found) == 1:
                # Every sequence agrees on this base. Set
                consensus_seq += list(found.keys())[0]
            else:
                # Get the maximum consensus
                consensus_percent = -1
                consensus_base = None
                for base in found:
                    consensus = 1 - (found[base]/len(agg_seqs))
                    if consensus &gt; consensus_percent:
                        consensus_percent = consensus
                        consensus_base = base

                # Set the consensus base if it passes the threshold
                if consensus_percent &gt;= threshold:
                    logging.debug(&#39;Consensus found for taxon {} in position {} as {}, found &#39; \
                        &#39;{}&#39;.format(self.name, i, consensus_base, found))
                    consensus_seq += consensus_base
                else:
                    logging.debug(&#39;No consensus for taxon {} in position {}. Consensus: {}&#39; \
                        &#39;, found {}&#39;.format(self.name, i, consensus, found))
                    consensus_seq += noconsensus_char

        # Check for errors with consensus sequence
        for seq in agg_seqs:
            perc_dist = diversity.beta.hamming(seq, consensus_seq, 
                ignore_char=noconsensus_char)/l
            if perc_dist &gt; 0.03:
                logging.warning(&#39;Taxon {} has a hamming distance &gt; 3% ({}) to the generated &#39; \
                    &#39;consensus sequence {} from individual sequence {}. Check that sequences &#39; \
                    &#39;make sense&#39;.format(self.name, perc_dist, consensus_seq, seq))

        # Set the consensus sequence as the OTU&#39;s sequence
        self.sequence = consensus_seq

    def generate_consensus_taxonomy(self, consensus_table: pd.DataFrame=None):
        &#39;&#39;&#39;Set the taxonomy of the OTU to the consensus taxonomy of the.

        If one of the ASVs is defined at a lower level than another ASV, use
        that taxonomy. If ASVs&#39; taxonomies disagree at the species level, use the 
        union of all the species. 

        Disagreeing taxonomy
        --------------------
        If the taxonomy of the ASVs differ on a taxonomic level other than species, we use an alternate 
        way of naming the OTU. The input `consensus_table` is a `pandas.DataFrame` object showing the
        taxonomic classification of an OTU. You would get this table by running RDP on the consensus
        sequence.
        
        If the consensus table is not given, then we specify the lowest level that they agree. If the 
        consensus table is given, then we use the taxonomy specified in that table.

        Examples
        --------
        ```
        Input:
         kingdom          phylum                class        order             family  genus       species      asv
        Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis  ASV_722
        Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea            NA  ASV_991
        
        Output:
         kingdom          phylum                class        order             family  genus       species
        Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis
        ```

        ```
        Input:
         kingdom          phylum           class              order              family            genus                 species      asv
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_283
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_302
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium    adolescentis/faecale  ASV_340
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  choerinum/pseudolongum  ASV_668

        Ouput:
         kingdom          phylum           class              order              family            genus                                      species
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  adolescentis/faecale/choerinum/pseudolongum
        ```

        Parameters
        ----------
        consensus_table : pd.DataFrame
            Table for resolving conflicts
        &#39;&#39;&#39;
        # Check that all the taxonomies have the same lineage
        set_to_na = False
        set_from_table = False
        for tax in TAX_LEVELS:
            if set_to_na:
                self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
                continue
            if set_from_table:
                if tax not in consensus_table.columns:
                    self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
                else:
                    self.taxonomy[tax] = consensus_table[tax][self.name]
                continue
            if tax == &#39;asv&#39;:
                continue
            consensus = []
            for taxonname in self.aggregated_taxa:
                if tax == &#39;species&#39;:
                    aaa = self.aggregated_taxonomies[taxonname][tax].split(&#39;/&#39;)
                else:
                    aaa = [self.aggregated_taxonomies[taxonname][tax]]
                for bbb in aaa:
                    if bbb in consensus:
                        continue
                    else:
                        consensus.append(bbb)
            if DEFAULT_TAXLEVEL_NAME in consensus:
                consensus.remove(DEFAULT_TAXLEVEL_NAME)

            if len(consensus) == 0:
                # No taxonomy found at this level
                self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
            elif len(consensus) == 1:
                # All taxonomies agree
                self.taxonomy[tax] = consensus[0]
            else:
                # All taxonomies do not agree
                if tax == &#39;species&#39;:
                    # Take the union of the species
                    self.taxonomy[tax] = &#39;/&#39;.join(consensus)
                else:
                    # This means that the taxonomy is different on a level different than
                    logging.critical(&#39;{} taxonomy does not agree&#39;.format(self.name))
                    logging.critical(str(self))
                    for taxonname in self.aggregated_taxonomies:
                        logging.warning(&#39;{}&#39;.format(list(self.aggregated_taxonomies[taxonname].values())))

                    if consensus_table is not None:
                        # Set from the table
                        self.taxonomy[tax] = consensus_table[tax][self.name]
                        set_from_table = True

                    else:
                        # Set this taxonomic level and everything below it to NA
                        self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
                        set_to_na = True


class Clusterable(Saveable):
    &#39;&#39;&#39;This is the base class for something to be clusterable (be used to cluster in
    pylab.cluster.Clustering). These are the functions that need to be implemented
    for it to be able to be clustered.

    `stritem`: This is the function that we use to get the label of the item
    &#39;&#39;&#39;
    def __len__(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def __getitem__(self, key):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def __iter__(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def __contains__(self, key):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def stritem(self, key):
        raise NotImplementedError(&#39;You must implement this function&#39;)


class TaxaSet(Clusterable):
    &#39;&#39;&#39;Wraps a set of `` objects. You can get the  object via the
     id,  name.
    Provides functionality for aggregating sequeunces and getting subsets for lineages.

    Aggregating/Deaggregating
    -------------------------
    s that are aggregated together to become OTUs are used because sequences are 
    very close together. This class provides functionality for aggregating taxa together
    (`mdsine2.TaxaSet.aggregate_items`) and to deaggregate a specific name from an aggregation
    (`mdsine2.TaxaSet.deaggregate_item`). If this object is within a `mdsine2.Study` object,
    MAKE SURE TO CALL THE AGGREGATION FUNCTIONS FROM THE `mdsine2.Study` OBJECT 
    (`mdsine2.Study.aggregate_items`, `mdsine2.Study.deaggregate_item`) so that the reads
    for the agglomerates and individual taxa can be consistent with the TaxaSet.

    Parameters
    ----------
    taxonomy_table : pandas.DataFrame
        This is the table defining the set. If this is specified, then it is passed into
        TaxaSet.parse

    See also
    --------
    mdsine2.TaxaSet.parse
    &#39;&#39;&#39;

    def __init__(self, taxonomy_table: pd.DataFrame=None):
        self.taxonomy_table = taxonomy_table 
        self.ids = CustomOrderedDict() # Effectively a dictionary (id (int) -&gt; OTU or Taxon)
        self.names = CustomOrderedDict() # Effectively a dictionary (name (int) -&gt; OTU or Taxon)
        self.index = [] # List (index (int) -&gt; OTU or Taxon)
        self._len = 0

        # Add all of the taxa from the dataframe if necessary
        if taxonomy_table is not None:
            self.parse(taxonomy_table=taxonomy_table)

    def __contains__(self, key: Union[Taxon, OTU, str, int]) -&gt; bool:
        try:
            self[key]
            return True
        except:
            return False

    def __getitem__(self, key: Union[Taxon, OTU, str, int]):
        &#39;&#39;&#39;Get a Taxon/OTU by either its sequence, name, index, or id

        Parameters
        ----------
        key : str, int
            Key to reference the Taxon
        &#39;&#39;&#39;
        if istaxontype(key):
            return key
        if key in self.ids:
            return self.ids[key]
        elif plutil.isint(key):
            return self.index[key]
        elif key in self.names:
            return self.names[key]
        else:
            raise IndexError(&#39;`{}` ({}) was not found as a name, sequence, index, or id&#39;.format(
                key, type(key)))

    def __iter__(self) -&gt; Union[Taxon, OTU]:
        &#39;&#39;&#39;Returns each Taxa obejct in order
        &#39;&#39;&#39;
        for taxon in self.index:
            yield taxon

    def __len__(self) -&gt; int:
        &#39;&#39;&#39;Return the number of taxa in the TaxaSet
        &#39;&#39;&#39;
        return self._len

    @property
    def n_taxa(self) -&gt; int:
        &#39;&#39;&#39;Alias for __len__
        &#39;&#39;&#39;
        return self._len

    def parse(self, taxonomy_table: pd.DataFrame):
        &#39;&#39;&#39;Parse a taxonomy table

        `taxonomy_table`
        ----------------
        This is a dataframe that contains the taxonomic information for each Taxon.
        The columns that must be included are:
            &#39;name&#39; : name of the taxon
            &#39;sequence&#39; : sequence of the taxon
        All of the taxonomy specifications are optional:
            &#39;kingdom&#39; : kingdom taxonomy
            &#39;phylum&#39; : phylum taxonomy
            &#39;class&#39; : class taxonomy
            &#39;family&#39; : family taxonomy
            &#39;genus&#39; : genus taxonomy
            &#39;species&#39; : species taxonomy

        Note that if the `name` column is not in the columns, this assumes that the
        OTU names are the index already.

        Parameters
        ----------
        taxonomy_table : pandas.DataFrame, Optional
            DataFrame containing the required information (Taxonomy, sequence).
            If nothing is passed in, it will be an empty TaxaSet
        &#39;&#39;&#39;
        logging.info(&#39;TaxaSet parsng new taxonomy table. Resetting&#39;)
        self.taxonomy_table = taxonomy_table
        self.ids = CustomOrderedDict()
        self.names = CustomOrderedDict()
        self.index = []
        self._len = 0

        self.taxonomy_table = taxonomy_table
        taxonomy_table = taxonomy_table.rename(str.lower, axis=&#39;columns&#39;)
        if &#39;name&#39; not in taxonomy_table.columns:
            logging.info(&#39;No `name` found - assuming index is the name&#39;)
        else:
            taxonomy_table = taxonomy_table.set_index(&#39;name&#39;)
        if SEQUENCE_COLUMN_LABEL not in taxonomy_table.columns:
            raise ValueError(&#39;`&#34;{}&#34;` ({}) not found as a column in `taxonomy_table`&#39;.format(
                SEQUENCE_COLUMN_LABEL, taxonomy_table.columns))

        for tax in TAX_LEVELS[:-1]:
            if tax not in taxonomy_table.columns:
                logging.info(&#39;Adding in `{}` column&#39;.format(tax))
                taxonomy_table = taxonomy_table.insert(-1, tax, 
                    [DEFAULT_TAXLEVEL_NAME for _ in range(len(taxonomy_table.index))])

        for i, name in enumerate(taxonomy_table.index):
            seq = taxonomy_table[SEQUENCE_COLUMN_LABEL][name]
            taxon = Taxon(name=name, sequence=seq, idx=self._len)
            taxon.set_taxonomy(
                tax_kingdom=taxonomy_table.loc[name][&#39;kingdom&#39;],
                tax_phylum=taxonomy_table.loc[name][&#39;phylum&#39;],
                tax_class=taxonomy_table.loc[name][&#39;class&#39;],
                tax_order=taxonomy_table.loc[name][&#39;order&#39;],
                tax_family=taxonomy_table.loc[name][&#39;family&#39;],
                tax_genus=taxonomy_table.loc[name][&#39;genus&#39;],
                tax_species=taxonomy_table.loc[name][&#39;species&#39;])

            self.ids[taxon.id] = taxon
            self.names[taxon.name] = taxon
            self.index.append(taxon)  
            self._len += 1

        self.ids.update_order()
        self.names.update_order()

    def add_taxon(self, name: str, sequence: Iterator[str]=None):
        &#39;&#39;&#39;Adds a taxon to the set

        Parameters
        ----------
        name : str
            This is the name of the taxon
        sequence : str
            This is the sequence of the taxon
        &#39;&#39;&#39;
        taxon = Taxon(name=name, sequence=sequence, idx=self._len)
        self.ids[taxon.id] = taxon
        self.names[taxon.name] = taxon
        self.index.append(taxon)

        # update the order of the taxa
        self.ids.update_order()
        self.names.update_order()
        self._len += 1

        return self

    def del_taxon(self, taxon: Union[Taxon, OTU, str, int]):
        &#39;&#39;&#39;Deletes the taxon from the set.

        Parameters
        ----------
        taxon : str, int, Taxon
            Can either be the name, sequence, or the ID of the taxon
        &#39;&#39;&#39;
        # Get the ID
        taxon = self[taxon]
        oidx = self.ids.index[taxon.id]

        # Delete the taxon from everything
        # taxon = self[taxon]
        self.ids.pop(taxon.id, None)
        self.names.pop(taxon.name, None)
        self.index.pop(oidx)

        # update the order of the taxa
        self.ids.update_order()
        self.names.update_order()

        # Update the indices of the taxa
        # Since everything points to the same object we only need to do it once
        for aidx, taxon in enumerate(self.index):
            taxon.idx = aidx

        self._len -= 1
        return self

    def taxonomic_similarity(self, 
        oid1: Union[Taxon, OTU, str, int], 
        oid2: Union[Taxon, OTU, str, int]) -&gt; float:
        &#39;&#39;&#39;Calculate the taxonomic similarity between taxon1 and taxon2
        Iterates through most broad to least broad taxonomic level and
        returns the fraction that are the same.

        Example:
            taxon1.taxonomy = (A,B,C,D)
            taxon2.taxonomy = (A,B,E,F)
            similarity = 0.5

            taxon1.taxonomy = (A,B,C,D)
            taxon2.taxonomy = (A,B,C,F)
            similarity = 0.75

            taxon1.taxonomy = (A,B,C,D)
            taxon2.taxonomy = (A,B,C,D)
            similarity = 1.0

            taxon1.taxonomy = (X,Y,Z,M)
            taxon2.taxonomy = (A,B,E,F)
            similarity = 0.0

        Parameters
        ----------
        oid1, oid2 : str, int
            The name, id, or sequence for the taxon
        &#39;&#39;&#39;
        if oid1 == oid2:
            return 1
        taxon1 = self[oid1].get_lineage()
        taxon2 = self[oid2].get_lineage()
        i = 0
        for a in taxon1:
            if a == taxon2[i]:
                i += 1
            else:
                break
        return i/8 # including asv

    def aggregate_items(self, anchor: Union[Taxon, OTU, str, int], other: Union[Taxon, OTU, str, int]):
        &#39;&#39;&#39;Create an OTU with the anchor `anchor` and other taxon  `other`.
        The aggregate takes the sequence and the taxonomy from the anchor.

        Parameters
        ----------
        anchor, other : str, int, mdsine2.Taxon, mdsine2.OTU
            These are the Taxa/Aggregates that you&#39;re joining together. The anchor is
            the one you are setting the sequeunce and taxonomy to

        Returns
        -------
        mdsine2.OTU
            This is the new aggregated taxon containing anchor and other
        &#39;&#39;&#39;
        anchor = self[anchor]
        other = self[other]
        
        agg = OTU(anchor=anchor, other=other)

        self.index[agg.idx] = agg
        self.index.pop(other.idx)

        self.ids = CustomOrderedDict()
        self.names = CustomOrderedDict()

        for idx, taxon in enumerate(self.index):
            taxon.idx = idx
            self.ids[taxon.id] = taxon
            self.names[taxon.name] = taxon
        
        # update the order of the taxa
        self.ids.update_order()
        self.names.update_order()

        self._len = len(self.index)
        return agg

    def deaggregate_item(self, agg: Union[Taxon, OTU, str, int], other: str) -&gt; Taxon:
        &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
        `other` is then appended to the end 

        Parameters
        ----------
        agg : OTU, str
            This is an OTU with multiple sequences contained. Must 
            have the name `other` in there
        other : str
            This is the name of the taxon that should be taken out of `agg`

        Returns
        -------
        mdsine2.Taxon
            This is the deaggregated taxon
        &#39;&#39;&#39;
        agg = self[agg]
        if not isotu(agg):
            raise TypeError(&#39;`agg` ({}) must be an OTU&#39;.format(type(agg)))
        if not plutil.isstr(other):
            raise TypeError(&#39;`other` ({}) must be a str&#39;.format(type(other)))
        if other not in agg.aggregated_taxa:
            raise ValueError(&#39;`other` ({}) is not contained in `agg` ({}) ({})&#39;.format(
                other, agg.name, agg.aggregated_taxa))

        other = Taxon(name=other, sequence=agg.aggregated_seqs[other], idx=self._len)
        other.taxonomy = agg.aggregated_taxonomies[other.name]
        agg.aggregated_seqs.pop(other.name, None)
        agg.aggregated_taxa.remove(other.name)
        agg.aggregated_taxonomies.pop(other.name, None)

        self.index.append(other)
        self.ids[other.id] = other
        self.names[other.name] = other

        self.ids.update_order()
        self.names.update_order()
        self._len += 1
        return other

    def rename(self, prefix: str, zero_based_index: bool=False):
        &#39;&#39;&#39;Rename the contents based on their index:

        Example
        -------
        Names before in order:
        [Taxon_22, Taxon_9982, TUDD_8484]

        Calling taxa.rename(prefix=&#39;OTU&#39;)
        New names:
        [OTU_1, OTU_2, OTU_3]

        Calling taxa.rename(prefix=&#39;OTU&#39;, zero_based_index=True)
        New names:
        [OTU_0, OTU_1, OTU_2]

        Parameters
        ----------
        prefix : str
            This is the prefix of the new taxon. The name of the taxa will change
            to `&#39;{}_{}&#39;.format(prefix, index)`
        zero_based_index : bool
            If this is False, then we start the enumeration of the taxa from 1
            instead of 0. If True, then the enumeration starts at 0
        &#39;&#39;&#39;
        if not plutil.isstr(prefix):
            raise TypeError(&#39;`prefix` ({}) must be a str&#39;.format(type(prefix)))
        if not plutil.isbool(zero_based_index):
            raise TypeError(&#39;`zero_based_index` ({}) must be a bool&#39;.format(
                type(zero_based_index)))

        offset = 0
        if not zero_based_index:
            offset = 1

        self.names = CustomOrderedDict()
        for taxon in self.index:
            newname = prefix + &#39;_{}&#39;.format(int(taxon.idx + offset))
            taxon.name = newname
            self.names[taxon.name] = taxon

    def generate_consensus_seqs(self, threshold: float=0.65, noconsensus_char: str=&#39;N&#39;):
        &#39;&#39;&#39;Generate the consensus sequence for all of the taxa given the sequences
        of all the contained ASVs of the respective OTUs

        Parameters
        ----------
        threshold : float
            This is the threshold for consensus (0 &lt; threshold &lt;= 1)
        noconsensus_char : str
            This is the character to replace
        &#39;&#39;&#39;
        for taxon in self:
            if isotu(taxon):
                taxon.generate_consensus_seq(
                    threshold=threshold, 
                    noconsensus_char=noconsensus_char)

    def generate_consensus_taxonomies(self, consensus_table: pd.DataFrame=None):
        &#39;&#39;&#39;Generates the consensus taxonomies for all of the OTUs within the TaxaSet.
        For details on the algorithm - see `OTU.generate_consensus_taxonomy`

        See Also
        --------
        mdsine2.pylab.base.OTU.generate_consensus_taxonomy
        &#39;&#39;&#39;
        for taxon in self:
            if isotu(taxon):
                taxon.generate_consensus_taxonomy(consensus_table=consensus_table)

    def write_taxonomy_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the taxon names, sequences, and taxonomy to a table. If a path
        is passed in, then write to that table

        Parameters
        ----------
        path : str
            This is the location to save the metadata file
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        columns = [&#39;name&#39;, &#39;sequence&#39;, &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;, &#39;species&#39;]
        data = []

        for taxon in self:
            temp = [taxon.name, taxon.sequence]
            for taxlevel in TAX_LEVELS[:-1]:
                temp.append(taxon.taxonomy[taxlevel])
            data.append(temp)
        
        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df


class qPCRdata:
    &#39;&#39;&#39;Single entry of qpcr data at a timepoint with maybe multiple technical replicates.
    Assumes that the dilution factor is constant between the replicate runs

    The normalized data is assumed to be:
        (cfus * dilution_factor / mass) * scaling_factor

    scaling_factor is a scale that we impose on the data so that the numbers don&#39;t get
    super large in the numerical calculations and we get errors, it does nothing to affect
    the empirical variance of the data.

    Parameters
    ----------
    cfus : np.ndarray
        These are the raw CFUs - it can be a single CFU measurement or a list of all
        the measurements
    mass : float
        This is the mass of the sample in grams
    dilution_factor : float
        This is the dilution factor of the samples
        Example:
            If the sample was diluted to 1/100 of its original concentration,
            the dilution factor is 100, NOT 1/100.

    &#39;&#39;&#39;
    def __init__(self, cfus: np.ndarray, mass: float=1., dilution_factor: float=1.):
        self._raw_data = np.asarray(cfus) # array of raw CFU values
        self.mass = mass
        self.dilution_factor = dilution_factor
        self.scaling_factor = 1 # Initialize with no scaling factor
        self.recalculate_parameters()

    def recalculate_parameters(self):
        &#39;&#39;&#39;Generate the normalized abundances and recalculate the statistics
        &#39;&#39;&#39;
        if len(self._raw_data) == 0:
            return

        self.data = (self._raw_data*self.dilution_factor/self.mass)*self.scaling_factor # array of normalized values
        self.log_data = np.log(self.data) 
        
        self.loc = np.mean(self.log_data)
        self.scale = np.std(self.log_data - self.loc)
        self.scale2 = self.scale ** 2


        self._mean_dist = np.exp(self.loc + (self.scale2/2) )
        self._var_dist = (np.exp(self.scale2) - 1) * np.exp(2*self.loc + self.scale2)
        self._std_dist = np.sqrt(self._var_dist)
        self._gmean = (np.prod(self.data))**(1/len(self.data))

    def __str__(self) -&gt; str:
        s = &#39;cfus: {}\nmass: {}\ndilution_factor: {}\n scaling_factor: {}\n&#39; \
            &#39;data: {}\nlog_data: {}\nloc: {}\n scale: {}&#39;.format( 
                self._raw_data, self.mass, self.dilution_factor, self.scaling_factor, 
                self.data, self.log_data, self.loc, self.scale)
        return s

    def add(self, raw_data: Union[np.ndarray, float, int]):
        &#39;&#39;&#39;Add a single qPCR measurement to add to the set of observations

        Parameters
        ----------
        raw_data : float, array_like
            This is the measurement to add
        &#39;&#39;&#39;
        self._raw_data = np.append(self._raw_data,raw_data)
        self.recalculate_parameters()

    def set_to_nan(self):
        &#39;&#39;&#39;Set all attributes to `np.nan`
        &#39;&#39;&#39;
        self._raw_data *= np.nan
        self.data *= np.nan
        self.mass = np.nan
        self.dilution_factor = np.nan
        self._mean_dist = np.nan
        self._std_dist = np.nan
        self._var_dist = np.nan
        self._gmean = np.nan
        self.loc = np.nan
        self.scale = np.nan
        self.scale2 = np.nan
        self.scaling_factor = np.nan

    def set_scaling_factor(self, scaling_factor: float):
        &#39;&#39;&#39;Resets the scaling factor

        Parameters
        ----------
        scaling_factor : float, int
            This is the scaling factor to set everything to
        &#39;&#39;&#39;
        if scaling_factor &lt;= 0:
            raise ValueError(&#39;The scaling factor must strictly be positive&#39;)
        self.scaling_factor = scaling_factor
        self.recalculate_parameters()

    def mean(self) -&gt; float:
        &#39;&#39;&#39;Return the geometric mean
        &#39;&#39;&#39;
        return self.gmean()
    
    def var(self) -&gt; float:
        return self._var_dist

    def std(self) -&gt; float:
        return self._std_dist

    def gmean(self) -&gt; float:
        return self._gmean


class CustomOrderedDict(dict):
    &#39;&#39;&#39;Order is an initialized version of self.keys() -&gt; much more efficient
    index maps the key to the index in order:
    - order (list)
        - same as a numpy version of the keys in order
    - index (dict)
        - Maps the key to the index that it was inserted in
    &#39;&#39;&#39;

    def __init__(self, *args, **kwargs):
        &#39;&#39;&#39;Extension of the OrderedDict

        Paramters
        ---------
        args, kwargs : Arguments
            These are extra arguments to initialize the baseline OrderedDict
        &#39;&#39;&#39;
        dict.__init__(self, *args, **kwargs)
        self.order = None
        self.index = None

    def update_order(self):
        &#39;&#39;&#39;This will update the reverse dictionary based on the index. It will 
        also redo the indexes if a taxon was deleted
        &#39;&#39;&#39;
        self.order = np.array(list(self.keys()))
        self.index = {}
        for i, taxon in enumerate(self.order):
            self.index[taxon] = i


class Subject(Saveable):
    &#39;&#39;&#39;Data for a single subject
    The TaxaSet order is done with respect to the ordering in the `reads_table`

    Parameters
    ----------
    parent : Study
        This is the parent class (we have a reverse pointer)
    name : str
        This is the name of the subject
    &#39;&#39;&#39;
    def __init__(self, parent: &#39;Study&#39;, name: str):
        self.name = name # str
        self.id = id(self)
        self.parent = parent
        self.qpcr = {} # dict: time (float) -&gt; qpcr object (qPCRData)
        self.reads = {} # dict: time (float) -&gt; reads (np.ndarray)
        self.times = np.asarray([]) # times in order
        self._reads_individ = {} # for taking out aggregated taxa

    def add_time(self, timepoint: Union[float, int]):
        &#39;&#39;&#39;Add the timepoint `timepoint`. Set the reads and qpcr at that timepoint
        to None

        Parameters
        ----------
        timepoint : float, int
            Time point to add
        &#39;&#39;&#39;
        if timepoint in self.times:
            return
        self.times = np.sort(np.append(self.times, timepoint))
        self.reads[timepoint] = None
        self.qpcr[timepoint] = None

    def add_reads(self, timepoints: Union[np.ndarray, int, float], reads: np.ndarray):
        &#39;&#39;&#39;Add the reads for timepoint `timepoint`

        Parameters
        ----------
        timepoint : numeric, array
            This is the time that the measurement occurs. If it is an array, then
            we are adding for multiple timepoints
        reads : np.ndarray(N_TAXA, N_TIMEPOINTS)
            These are the reads for the taxa in order. Assumed to be in the 
            same order as the TaxaSet. If it is a dataframe then we use the rows
            to index the taxon names. If timepoints is an array, then we are adding 
            for multiple timepoints. In this case we assume that the rows index  the 
            taxon and the columns index the timepoint.
        &#39;&#39;&#39;
        if not plutil.isarray(timepoints):
            timepoints = [timepoints]
        for timepoint in timepoints:
            if not plutil.isnumeric(timepoint):
                raise TypeError(&#39;`timepoint` ({}) must be a numeric&#39;.format(type(timepoint)))
        if not plutil.isarray(reads):
            raise TypeError(&#39;`reads` ({}) must be an array&#39;.format(type(reads)))
        
        if reads.ndim == 1:
            reads = reads.reshape(-1,1)
        if reads.ndim != 2:
            raise ValueError(&#39;`reads` {} must be a matrix&#39;.format(reads.shape))
        if reads.shape[0] != len(self.taxa) or reads.shape[1] != len(timepoints):
            raise ValueError(&#39;`reads` shape {} does not align with the number of taxa ({}) &#39; \
                &#39;or timepoints ({})&#39;.format(reads.shape, len(self.taxa), len(timepoints)))

        for tidx, timepoint in enumerate(timepoints):
            if timepoint in self.reads:
                if self.reads[timepoint] is not None:
                    logging.debug(&#39;There are already reads specified at time `{}` for subject `{}`, overwriting&#39;.format(
                        timepoint, self.name))
                
            self.reads[timepoint] = reads[:,tidx]
            if timepoint not in self.times:
                self.times = np.sort(np.append(self.times, timepoint))
        return self

    def add_qpcr(self, timepoints: Union[np.ndarray, int, float], qpcr: np.ndarray, 
        masses: Union[np.ndarray, int, float]=None, dilution_factors: Union[np.ndarray, int, float]=None):
        &#39;&#39;&#39;Add qpcr measurements for timepoints `timepoints`

        Parameters
        ----------
        timepoint : numeric, array
            This is the time that the measurement occurs. If it is an array, then
            we are adding for multiple timepoints
        qpcr : np.ndarray(N_TIMEPOINTS, N_REPLICATES)
            These are the qPCR measurements in order of timepoints. Assumed to be in the 
            same order as timepoints.If timepoints is an array, then we are adding 
            for multiple timepoints. In this case we assume that the rows index the 
            timepoint and the columns index the replicates of the qpcr measurement.
        masses : numeric, np.ndarray
            These are the masses for each on of the qPCR measurements. If this is not 
            specified, then this assumes that the numbers in `qpcr` are already normalized
            by their sample weight.
        dilution_factors : numeric, np.ndarray
            These are the dilution factors for each of the qPCR measurements. If this is
            not specified, then this assumes that each one of the numbers in `qpcr` are
            already normalized by the dilution factor
        &#39;&#39;&#39;
        if not plutil.isarray(timepoints):
            timepoints = [timepoints]
        for timepoint in timepoints:
            if not plutil.isnumeric(timepoint):
                raise TypeError(&#39;`timepoint` ({}) must be a numeric&#39;.format(type(timepoint)))
        if masses is not None:
            if plutil.isnumeric(masses):
                masses = [masses]
            for mass in masses:
                if not plutil.isnumeric(mass):
                    raise TypeError(&#39;Each mass in `masses` ({}) must be a numeric&#39;.format(type(mass)))
                if mass &lt;= 0:
                    raise ValueError(&#39;Each mass in `masses` ({}) must be &gt; 0&#39;.format(mass))
            if len(masses) != len(timepoints):
                raise ValueError(&#39;Number of timepoints ({}) and number of masses ({}) &#39; \
                    &#39;must be equal&#39;.format(len(timepoints), len(masses)))
        if dilution_factors is not None:
            if plutil.isnumeric(dilution_factors):
                dilution_factors = [dilution_factors]
            for dilution_factor in dilution_factors:
                if not plutil.isnumeric(dilution_factor):
                    raise TypeError(&#39;Each dilution_factor in `dilution_factors` ({}) &#39; \
                        &#39;must be a numeric&#39;.format(type(dilution_factor)))
                if dilution_factor &lt;= 0:
                    raise ValueError(&#39;Each dilution_factor in `dilution_factors` ({}) &#39; \
                        &#39;must be &gt; 0&#39;.format(dilution_factor))
            if len(dilution_factors) != len(timepoints):
                raise ValueError(&#39;Number of timepoints ({}) and number of dilution_factors ({}) &#39; \
                    &#39;must be equal&#39;.format(len(timepoints), len(dilution_factors)))
            
        if not plutil.isarray(qpcr):
            raise TypeError(&#39;`qpcr` ({}) must be an array&#39;.format(type(qpcr)))
        if qpcr.ndim == 1:
            qpcr = qpcr.reshape(1,-1)
        if qpcr.ndim != 2:
            raise ValueError(&#39;`qpcr` {} must be a matrix&#39;.format(qpcr.shape))
        if qpcr.shape[0] != len(timepoints):
            raise ValueError(&#39;`qpcr` shape {} does not align with the number of timepoints ({}) &#39; \
                &#39;&#39;.format(qpcr.shape, len(timepoints)))

        for tidx, timepoint in enumerate(timepoints):
            if timepoint in self.qpcr:
                if self.qpcr[timepoint] is not None:
                    logging.debug(&#39;There are already qpcr measurements specified at time `{}` for subject `{}`, overwriting&#39;.format(
                        timepoint, self.name))
            if masses is not None:
                mass = masses[tidx]
            else:
                mass = 1
            if dilution_factors is not None:
                dil = dilution_factors[tidx]
            else:
                dil = 1

            self.qpcr[timepoint] = qPCRdata(cfus=qpcr[tidx,:], mass=mass, 
                dilution_factor=dil)
                
            if timepoint not in self.times:
                self.times = np.sort(np.append(self.times, timepoint))
        return self

    @property
    def perturbations(self) -&gt; Perturbations:
        return self.parent.perturbations

    @property
    def taxa(self) -&gt; TaxaSet:
        return self.parent.taxa

    @property
    def index(self) -&gt; int:
        &#39;&#39;&#39;Return the index of this subject in the Study file
        &#39;&#39;&#39;
        for iii, subj in enumerate(self.parent):
            if subj.name == self.name:
                return iii
        raise ValueError(&#39;Should not get here&#39;)

    def matrix(self) -&gt; Dict[str, np.ndarray]:
        &#39;&#39;&#39;Make a numpy matrix out of our data - returns the raw reads,
        the relative abundance, and the absolute abundance.

        If there is no qPCR data, then the absolute abundance is set to None.
        &#39;&#39;&#39;

        shape = (len(self.taxa), len(self.times))
        raw = np.zeros(shape=shape, dtype=int)
        rel = np.zeros(shape=shape, dtype=float)
        abs = np.zeros(shape=shape, dtype=float)

        for i,t in enumerate(self.times):
            raw[:,i] = self.reads[t]
            rel[:,i] = raw[:,i]/np.sum(raw[:,i])
        
        try:
            for i,t in enumerate(self.times):
                abs[:,i] = rel[:,i] * self.qpcr[t].mean()
        except AttributeError as e:
            logging.info(&#39;Attribute Error ({}) for absolute abundance. This is likely &#39; \
                &#39;because you did not set the qPCR abundances. Skipping `abs`&#39;.format(e))
            abs = None

        return {&#39;raw&#39;:raw, &#39;rel&#39;: rel, &#39;abs&#39;:abs}

    def df(self) -&gt; Dict[str, pd.DataFrame]:
        &#39;&#39;&#39;Returns a dataframe of the data - same as matrix
        &#39;&#39;&#39;
        d = self.matrix()
        index = self.taxa.names.order
        times = self.times
        for key in d:
            d[key] = pd.DataFrame(data=d[key], index=index, columns=times)
        return d

    def read_depth(self, t: Union[int, float]=None) -&gt; Union[np.ndarray, int]:
        &#39;&#39;&#39;Get the read depth at time `t`. If nothing is given then return all
        of them

        Parameters
        ----------
        t : int, float, Optional
            Get the read depth at this time. If nothing is provided, all of the read depths for this 
            subject are returned
        &#39;&#39;&#39;
        if t is None:
            return np.sum(self.matrix()[&#39;raw&#39;], axis=0)
        if t not in self.reads:
            raise ValueError(&#39;`t` ({}) not recognized. Valid times: {}&#39;.format(
                t, self.times))
        return np.sum(self.reads[t])

    def cluster_by_taxlevel(self, dtype: str, taxlevel: str, index_formatter: str=None, 
        smart_unspec: bool=True) -&gt; Tuple[pd.DataFrame, Dict[str,str]]:
        &#39;&#39;&#39;Clusters the taxa into the taxonomic level indicated in `taxlevel`.

        Smart Unspecified
        -----------------
        If True, returns the higher taxonomic classification while saying the desired taxonomic level
        is unspecified. Example: &#39;Order ABC, Family NA&#39;. Note that this overrides the `index_formatter`.

        Parameters
        ----------
        dtype : str
            This is the type of data to cluster. Options are:
                &#39;raw&#39;: These are the counts
                &#39;rel&#39;: This is the relative abundances
                &#39;abs&#39;: This is the absolute abundance (qPCR * rel)
        taxlevel : str, None
            This is the taxonomic level to aggregate the data at. If it is 
            None then we do not do any collapsing (this is the same as &#39;asv&#39;)
        index_formatter : str
            How to make the index using `taxaname_formatter`. Note that you cannot
            specify anything at a lower taxonomic level than what youre clustering at. For 
            example, you cannot cluster at the &#39;class&#39; level and then specify &#39;%(genus)s&#39; 
            in the index formatter.
            If nothing is specified then only return the specified taxonomic level
        smart_unspec : bool
            If True, if the taxonomic level is not not specified for that OTU/Taxon, then use the
            lowest taxonomic level instead.

        Returns
        -------
        pandas.DataFrame
            Dataframe of the data
        dict (str-&gt;str)
            Maps taxon name to the row it got allocated to
        &#39;&#39;&#39;
        # Type checking
        if not plutil.isstr(dtype):
            raise TypeError(&#39;`dtype` ({}) must be a str&#39;.format(type(dtype)))
        if dtype not in [&#39;raw&#39;, &#39;rel&#39;, &#39;abs&#39;]:
            raise ValueError(&#39;`dtype` ({}) not recognized&#39;.format(dtype))
        if not plutil.isstr(taxlevel):
            raise TypeError(&#39;`taxlevel` ({}) must be a str&#39;.format(type(taxlevel)))
        if taxlevel not in [&#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;,  &#39;order&#39;, &#39;family&#39;, 
            &#39;genus&#39;, &#39;species&#39;, &#39;asv&#39;]:
            raise ValueError(&#39;`taxlevel` ({}) not recognized&#39;.format(taxlevel))
        if index_formatter is None:
            index_formatter = taxlevel
        if index_formatter is not None:
            if not plutil.isstr(index_formatter):
                raise TypeError(&#39;`index_formatter` ({}) must be a str&#39;.format(type(index_formatter)))
            
            for tx in TAX_IDXS:
                if tx in index_formatter and TAX_IDXS[tx] &gt; TAX_IDXS[taxlevel]:
                    raise ValueError(&#39;You are clustering at the {} level but are specifying&#39; \
                        &#39; {} in the `index_formatter`. This does not make sense. Either cluster&#39; \
                        &#39;at a lower tax level or specify the `index_formatter` to a higher tax &#39; \
                        &#39;level&#39;.format(taxlevel, tx))

        index_formatter = index_formatter.replace(&#39;%(asv)s&#39;, &#39;%(name)s&#39;)

        # Everything is valid, get the data dataframe and the return dataframe
        taxaname_map = {}
        df = self.df()[dtype]
        cols = list(df.columns)
        cols.append(taxlevel)
        dfnew = pd.DataFrame(columns = cols).set_index(taxlevel)

        # Get the level in the taxonomy, create a new entry if it is not there already
        taxa = {} # lineage -&gt; label
        for i, taxon in enumerate(self.taxa):
            row = df.index[i]
            tax = taxon.get_lineage(level=taxlevel)
            tax = tuple(tax)
            tax = str(tax).replace(&#34;&#39;&#34;, &#39;&#39;)
            if tax in taxa:
                dfnew.loc[taxa[tax]] += df.loc[row]
            else:
                if not taxon.tax_is_defined(taxlevel) and smart_unspec:
                    # Get the least common ancestor above the taxlevel
                    taxlevelidx = TAX_IDXS[taxlevel]
                    ttt = None
                    while taxlevelidx &gt; -1:
                        if taxon.tax_is_defined(TAX_LEVELS[taxlevelidx]):
                            ttt = TAX_LEVELS[taxlevelidx]
                            break
                        taxlevelidx -= 1
                    if ttt is None:
                        raise ValueError(&#39;Could not find a single taxlevel: {}&#39;.format(str(taxon)))
                    taxa[tax] = &#39;{} {}, {} NA&#39;.format(ttt.capitalize(), 
                        taxon.taxonomy[ttt], taxlevel.capitalize())
                else:
                    taxa[tax] = taxaname_formatter(format=index_formatter, taxon=taxon, taxa=self.taxa)
                toadd = pd.DataFrame(np.array(list(df.loc[row])).reshape(1,-1),
                    index=[taxa[tax]], columns=dfnew.columns)
                dfnew = dfnew.append(toadd)
            
            if taxa[tax] not in taxaname_map:
                taxaname_map[taxa[tax]] = []
            taxaname_map[taxa[tax]].append(taxon.name)
        
        return dfnew, taxaname_map

    def _split_on_perturbations(self):
        &#39;&#39;&#39;If there are perturbations, then we take out the data on perturbations
        and we set the data in the different segments to different subjects

        Internal funciton, should not be used by the user
        &#39;&#39;&#39;
        if len(self.parent.perturbations) == 0:
            logging.info(&#39;No perturbations to split on, do nothing&#39;)
            return

        # Get the time intervals for each of the times that we are not on perturbations
        start_tidx = 0
        not_perts = []
        in_pert = False
        for i in range(len(self.times)):
            # check if the time is in a perturbation
            a = False
            for pert in self.parent.perturbations:
                if self.name not in pert:
                    continue
                start = pert.starts[self.name]
                end = pert.ends[self.name]
                # check if in the perturbation
                if self.times[i] &gt; start and self.times[i] &lt;= end:
                    a = True
                    break
            if a:
                # If the current time point is in a perturbation and we previously
                # have no been in a perturbation, this means we can add the previous
                # interval into the intervals that we want to keep
                if not in_pert:
                    not_perts.append((start_tidx, i))
                in_pert = True
            else:
                # If we are not currently in a perturbation but we previously were
                # then we restart to `start_tidx`
                if in_pert:
                    start_tidx = i
                    in_pert = False
        # If we have finished and we are out of a perturbation at the end, then
        # we can add the rest of the times at the end to a valid not in perturbation time
        if not in_pert:
            not_perts.append((start_tidx, len(self.times)))

        # For each of the time slices recorded, make a new subject
        if len(in_pert) == 0:
            raise ValueError(&#39;THere are perturbations ({}), this must not be zero.&#39; \
                &#39; Something went wrong&#39;.format(len(self.parent.perturbations)))
        ii = 0
        for start,end in not_perts:
            mid = self.name+&#39;_{}&#39;.format(ii)
            self.parent.add(name=mid)
            for i in range(start,end):
                t = self.times[i]
                self.parent[mid].qpcr[t] = self.qpcr[t]
                self.parent[mid].reads[t] = self.reads[t]
            self.parent[mid].times = self.times[start:end]

    def _deaggregate_item(self, agg: OTU, other: str):
        &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
        `other` is then appended to the end. This is called from 
        `mdsine2.Study.deaggregate_item`.

        Parameters
        ----------
        agg : OTU
            This is an OTU with multiple sequences contained. Must 
            have the name `other` in there
        other : str
            This is the name of the taxon that should be taken out of `agg`
        &#39;&#39;&#39;
        # Append the reads of the deaggregated at the bottom and subtract them
        # from the aggregated index
        if other not in self._reads_individ:
            raise ValueError(&#39;`other` ({}) reads not found in archive. This probably &#39; \
                &#39;happened because you called `aggregate_items` from the TaxaSet object&#39; \
                &#39; instead from this object. Study object not consistent. Failing.&#39;.format(other))
        
        aggidx = agg.idx
        for t in self.times:
            try:
                new_reads = self._reads_individ[other][t]
            except:
                raise ValueError(&#39;Timepoint `{}` added into subject `{}` after &#39; \
                    &#39;Taxon `{}` was removed. Study object is not consistent. You &#39; \
                    &#39;cannot add in other timepoints after you aggregate taxa. Failing.&#39;.format(
                        t, self.name, other))
            self.reads[t][aggidx] = self.reads[t][aggidx] - new_reads
            self.reads[t] = np.append(self.reads[t], new_reads)
        self._reads_individ.pop(other)
        return

    def _aggregate_items(self, anchor: Union[OTU, Taxon], other: Union[OTU, Taxon]):
        &#39;&#39;&#39;Aggregate the taxon `other` into `anchor`. This is called from 
        `mdsine2.Study.aggregate_items`.

        Parameters
        ----------
        anchor, other : OTU, Taxon
            These are the s to combine
        &#39;&#39;&#39;
        # If one of them are taxon, then record their individual reads
        # if we want to dissociate them later
        for taxon in [anchor, other]:
            if istaxontype(taxon):
                if taxon.name in self._reads_individ:
                    raise ValueError(&#39;Taxon is already in this dict. This should not happen.&#39;)
                aidx = taxon.idx
                self._reads_individ[taxon.name] = {}
                for t in self.times:
                    self._reads_individ[taxon.name][t] = self.reads[t][aidx]
        
        for t in self.times:
            self.reads[t][anchor.idx] += self.reads[t][other.idx]
            self.reads[t] = np.delete(self.reads[t], other.idx)
        return


class Study(Saveable):
    &#39;&#39;&#39;Holds data for all the subjects

    Paramters
    ---------
    taxa : TaxaSet, Optional
        Contains all of the s
    &#39;&#39;&#39;
    def __init__(self, taxa: TaxaSet, name: str=&#39;unnamed-study&#39;):
        self.name = name
        self.id = id(self)
        self._subjects = {}
        self.perturbations = None
        self.qpcr_normalization_factor = None
        if not istaxaset(taxa):
            raise ValueError(&#39;If `taxa` ({}) is specified, it must be an TaxaSet&#39; \
                &#39; type&#39;.format(type(taxa)))
        self.taxa = taxa

        self._samples = {}
        
    def __getitem__(self, key: Union[str, int, Subject]) -&gt; Subject:
        return self._subjects[key]

    def __len__(self) -&gt; int:
        return len(self._subjects)

    def __iter__(self) -&gt; Subject:
        for v in self._subjects.values():
            yield v

    def __contains__(self, key: Union[str, int, Subject]) -&gt; bool:
        return key in self._subjects

    def parse(self, metadata: pd.DataFrame, reads: pd.DataFrame=None, qpcr: pd.DataFrame=None, 
        perturbations: pd.DataFrame=None):
        &#39;&#39;&#39;Parse tables of samples and cast in Subject sets. Automatically creates
        the subject classes with the respective names.

        Parameters
        ----------
        metadata : pandas.DataFrame
            Contains the meta data for each one of the samples
            Columns:
                &#39;sampleID&#39; -&gt; str : This is the name of the sample
                &#39;subject&#39; -&gt; str : This is the name of the subject
                &#39;time&#39; -&gt; float : This is the time the sample takes place
                &#39;perturbation:`name`&#39; -&gt; int : This is a perturbation meta data where the
                    name of the perturbation is `name`
        reads : pandas.DataFrame, None
            Contains the reads for each one of the samples and taxa
                index (str) : indexes the taxon name
                columns (str) : indexes the sample ID
            If nothing is passed in, the reads are set to None
        qpcr : pandas.DataFrame, None
            Contains the qpcr measurements for each sample
                index (str) : indexes the sample ID
                columns (str) : Name is ignored. the values are set to the measurements
        perturbations : pandas.DataFrame, None
            Contains the times and subjects for each perturbation
            columns:
                &#39;name&#39; -&gt; str : Name of the perturbation
                &#39;start&#39; -&gt; float : This is the start time for the perturbation
                &#39;end&#39; -&gt; float : This is the end time for the perturbation
                &#39;subject&#39; -&gt; str : This is the subject name the perturbation is applied to
        &#39;&#39;&#39;
        if not plutil.isdataframe(metadata):
            raise TypeError(&#39;`metadata` ({}) must be a pandas.DataFrame&#39;.format(type(metadata)))
        
        # Add the samples
        # ---------------
        if &#39;sampleID&#39; in metadata.columns:
            metadata = metadata.set_index(&#39;sampleID&#39;)
        for sampleid in metadata.index:

            sid = str(metadata[&#39;subject&#39;][sampleid])
            t = float(metadata[&#39;time&#39;][sampleid])

            if sid not in self:
                self.add_subject(name=sid)
            if t not in self[sid].times:
                self[sid].add_time(timepoint=t)

            self._samples[str(sampleid)] = (sid,t)

        # Add the perturbations if there are any
        # --------------------------------------
        if perturbations is not None:
            logging.warning(&#39;Reseting perturbations&#39;)
            self.perturbations = Perturbations()
            if not plutil.isdataframe(perturbations):
                raise TypeError(&#39;`metadata` ({}) must be a pandas.DataFrame&#39;.format(type(metadata)))
            try:
                for pidx in perturbations.index:
                    pname = perturbations[&#39;name&#39;][pidx]
                    subj = str(perturbations[&#39;subject&#39;][pidx])

                    if pname not in self.perturbations:
                        # Create a new one
                        pert = BasePerturbation(
                            name=pname, 
                            starts={subj: perturbations[&#39;start&#39;][pidx]},
                            ends={subj: perturbations[&#39;end&#39;][pidx]})
                        self.perturbations.append(pert)
                    else:
                        # Add this subject name to the pertubration
                        self.perturbations[pname].starts[subj] = perturbations[&#39;start&#39;][pidx]
                        self.perturbations[pname].ends[subj] = perturbations[&#39;end&#39;][pidx]
            except KeyError as e:
                logging.critical(e)
                raise KeyError(&#39;Make sure that `subject`, `start`, and `end` are columns&#39;)

        # Add the reads if necessary
        # --------------------------
        if reads is not None:
            if not plutil.isdataframe(reads):
                raise TypeError(&#39;`reads` ({}) must be a pandas.DataFrame&#39;.format(type(reads)))
            
            if &#39;name&#39; in reads.columns:
                reads = reads.set_index(&#39;name&#39;)

            for sampleid in reads.columns:
                if sampleid not in self._samples:
                    raise ValueError(&#39;sample {} not contained in metadata. abort&#39;.format(sampleid))
                sid, t = self._samples[sampleid]
                self[sid].add_reads(timepoints=t, reads=reads[sampleid].to_numpy())

        # Add the qPCR measurements if necessary
        # --------------------------------------
        if qpcr is not None:
            if not plutil.isdataframe(qpcr):
                raise TypeError(&#39;`qpcr` ({}) must be a pandas.DataFrame&#39;.format(type(qpcr)))
            if &#39;sampleID&#39; in qpcr.columns:
                qpcr = qpcr.set_index(&#39;sampleID&#39;)

            for sampleid in qpcr.index:
                try:
                    sid, t = self._samples[sampleid]
                except:
                    raise ValueError(&#39;Sample ID `{}` not found in metadata ({}). Make sure &#39; \
                        &#39;you set the sample ID as the index in the `qpcr` dataframe&#39;.format(
                            sampleid, list(self._samples.keys())))
                cfuspergram = qpcr.loc[sampleid].to_numpy()
                self[sid].add_qpcr(timepoints=t, qpcr=cfuspergram)
        return self
            
    def write_metadata_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the internal metadata to a table. If a path is provided
        then write it to that path.

        Parameters
        ----------
        path : str, None
            This is the location to save the metadata file
            If this is not provided then just return the dataframe
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        columns = [&#39;sampleID&#39;, &#39;subject&#39;, &#39;time&#39;]
        data = []
        for sampleid in self._samples:
            sid, t = self._samples[sampleid]
            if t not in self[sid].times:
                continue
            data.append([sampleid, sid, t])
        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def write_reads_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the reads to a table. If a path is provided then
        we write to that path

        Parameters
        ----------
        path : str
            This is the location to save the reads file
            If this is not provided then just return the dataframe
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        data = [[taxon.name for taxon in self.taxa]]
        index = [&#39;name&#39;]
        for sampleid in self._samples:
            sid, t = self._samples[sampleid]
            if t not in self[sid].times:
                continue

            index.append(sampleid)
            reads = self[sid].reads[t]
            data.append(reads)

        df = pd.DataFrame(data, index=index).T
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def write_qpcr_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the qPCR measurements to a table. If a path is provided then
        we write to that path

        Parameters
        ----------
        path : str
            This is the location to save the qPCR file
            If this is not provided then we do not save
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        max_n_measurements = -1
        data = []
        for sampleid in self._samples:
            sid, t = self._samples[sampleid]
            if t not in self[sid].times:
                continue
            subj = self[sid]
            ms = subj.qpcr[t].data
            if len(ms) &gt; max_n_measurements:
                max_n_measurements = len(ms)
            ms = [sampleid] + ms.tolist()
            data.append(ms)
        
        for i, ms in enumerate(data):
            if len(ms)-1 &lt; max_n_measurements:
                data[i] = np.append(
                    ms, 
                    np.nan * np.ones(max_n_measurements - len(ms)))
        
        columns = [&#39;sampleID&#39;] + [&#39;measurement{}&#39;.format(i+1) for i in range(max_n_measurements)]

        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def write_perturbations_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the perturbations to a table. If a path is provided then
        we write to that path

        Parameters
        ----------
        path : str
            This is the location to save the perturbations file
            If this is not provided then we do not save
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        columns = [&#39;name&#39;, &#39;start&#39;, &#39;end&#39;, &#39;subject&#39;]
        data = []
        for perturbation in self.perturbations:
            for subjname in perturbation.starts:
                data.append([
                    perturbation.name, 
                    perturbation.starts[subjname],
                    perturbation.ends[subjname],
                    subjname])

        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def names(self) -&gt; Iterator[str]:
        &#39;&#39;&#39;List the names of the contained subjects

        Returns
        -------
        list(str)
            List of names of the subjects in order
        &#39;&#39;&#39;
        return [subj.name for subj in self]

    def iloc(self, idx: int) -&gt; Subject:
        &#39;&#39;&#39;Get the subject as an index

        Parameters
        ----------
        idx : int
            Index of the subject

        Returns
        -------
        pl.base.Subject
        &#39;&#39;&#39;
        for i,sid in enumerate(self._subjects):
            if i == idx:
                return self._subjects[sid]
        raise IndexError(&#39;Index ({}) not found&#39;.format(idx))

    def add_subject(self, name: str):
        &#39;&#39;&#39;Create a subject with the name `name`

        Parameters
        ----------
        name : str
            This is the name of the new subject
        &#39;&#39;&#39;
        if name not in self._subjects:
            self._subjects[name] = Subject(name=name, parent=self)
        return self

    def pop_subject(self, sid: Union[int, str, Iterator[str]], 
        name: str=&#39;unnamed-study&#39;) -&gt; &#39;Study&#39;:
        &#39;&#39;&#39;Remove the indicated subject id

        Parameters
        ----------
        sid : list(str), str, int
            This is the subject name/s or the index/es to pop out.
            Return a new Study with the specified subjects removed.
        name : str
            Name of the new study to return
        &#39;&#39;&#39;
        if not plutil.isarray(sid):
            sids = [sid]
        else:
            sids = sid

        for i in range(len(sids)):
            if plutil.isint(sids[i]):
                sids[i] = list(self._subjects.keys())[sids[i]]
            elif not plutil.isstr(sids[i]):
                raise ValueError(&#39;`sid` ({}) must be a str&#39;.format(type(sids[i])))
        ret = Study(taxa=self.taxa, name=name)
        ret.qpcr_normalization_factor = self.qpcr_normalization_factor

        for s in sids:
            if s in self._subjects:
                ret._subjects[s] =  self._subjects.pop(s, None)
                ret._subjects[s].parent = ret
            else:
                raise ValueError(&#39;`sid` ({}) not found&#39;.format(sid))

        ret.perturbations = copy.deepcopy(self.perturbations)

        # Remove the names of the subjects in the perturbations
        for study in [ret, self]:
            for perturbation in study.perturbations:
                names = list(perturbation.starts.keys())
                for subjname in names:
                    if subjname not in study:
                        perturbation.starts.pop(subjname, None)
                names = list(perturbation.ends.keys())
                for subjname in names:
                    if subjname not in study:
                        perturbation.ends.pop(subjname, None)

        return ret

    def pop_taxa_like(self, study: &#39;Study&#39;):
        &#39;&#39;&#39;Remove s in the TaxaSet so that it matches the TaxaSet in `study`

        Parameters
        ----------
        study : mdsine2.study
            This is the study object we are mirroring in terms of taxa
        &#39;&#39;&#39;
        to_delete = []
        for taxon in self.taxa:
            if taxon.name not in study.taxa:
                to_delete.append(taxon.name)
        self.pop_taxa(to_delete)

    def pop_taxa(self, oids: Union[str, int, Iterator[str], Iterator[int]]):
        &#39;&#39;&#39;Delete the taxa indicated in oidxs. Updates the reads table and
        the internal TaxaSet

        Parameters
        ----------
        oids : str, int, list(str/int)
            These are the identifiers for each of the taxon/taxa to delete
        &#39;&#39;&#39;
        # get indices
        oidxs = []
        for oid in oids:
            oidxs.append(self.taxa[oid].idx)
        
        # Delete the s from taxaset
        for oid in oids:
            self.taxa.del_taxon(oid)

        # Delete the reads
        for subj in self:
            for t in subj.reads:
                subj.reads[t] = np.delete(subj.reads[t], oidxs)
        return self

    def deaggregate_item(self, agg: OTU, other: str) -&gt; Taxon:
        &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
        `other` is then appended to the end 

        Parameters
        ----------
        agg : OTU, str
            This is an OTU with multiple sequences contained. Must 
            have the name `other` in there
        other : str
            This is the name of the taxon that should be taken out of `agg`

        Returns
        -------
        mdsine2.Taxon
            This is the deaggregated taxon
        &#39;&#39;&#39;
        agg = self.taxa[agg]
        if not isotu(agg):
            raise TypeError(&#39;`agg` ({}) must be an OTU&#39;.format(type(agg)))
        if not plutil.isstr(other):
            raise TypeError(&#39;`other` ({}) must be a str&#39;.format(type(other)))
        if other not in agg.aggregated_taxa:
            raise ValueError(&#39;`other` ({}) is not contained in `agg` ({}) ({})&#39;.format(
                other, agg.name, agg.aggregated_taxa))

        for subj in self:
            subj._deaggregate_item(agg=agg, other=other)
        return self.taxa.deaggregate_item(agg, other)

    def aggregate_items_like(self, study: &#39;Study&#39;, prefix: str=None):
        &#39;&#39;&#39;Aggregate s like they are in study `study`

        Parameters
        ----------
        study : mdsine2.Study
            Data object we are mirroring
        prefix : str
            If provided, this is how you rename the Taxas after aggregation
        &#39;&#39;&#39;
        for taxon in study.taxa:
            if isotu(taxon):
                aname = taxon.aggregated_taxa[0]
                for bname in taxon.aggregated_taxa[1:]:
                    self.aggregate_items(aname, bname)
        if prefix is not None:
            self.taxa.rename(prefix=prefix)

    def aggregate_items(self, taxon1: Union[str, int, Taxon, OTU], 
        taxon2: Union[str, int, Taxon, OTU]) -&gt; OTU:
        &#39;&#39;&#39;Aggregates the abundances of `taxon1` and `taxon2`. Updates the reads table and
        internal TaxaSet

        Parameters
        ----------
        taxon1, taxon2 : str, int, mdsine2.Taxon, mdsine2.OTU
            These are the taxa you are agglomerating together

        Returns
        -------
        mdsine2.OTU
            This is the new aggregated taxon containing anchor and other
        &#39;&#39;&#39;
        # Find the anchor - use the highest index
        aidx1 = self.taxa[taxon1].idx
        aidx2 = self.taxa[taxon2].idx

        if aidx1 == aidx2:
            raise ValueError(&#39;Cannot aggregate the same taxa: {}&#39;.format(self.taxa[taxon1]))
        elif aidx1 &lt; aidx2:
            anchor = self.taxa[taxon1]
            other = self.taxa[taxon2]
        else:
            anchor = self.taxa[taxon2]
            other = self.taxa[taxon1]

        for subj in self:
            subj._aggregate_items(anchor=anchor, other=other)
        return self.taxa.aggregate_items(anchor=anchor, other=other)

    def pop_times(self, times: Union[int, float, np.ndarray], sids: Union[str, int, Iterator[int]]=&#39;all&#39;):
        &#39;&#39;&#39;Discard the times in `times` for the subjects listed in `sids`.
        If a timepoint is not found in a subject, no error is thrown.

        Parameters
        ----------
        times : numeric, list(numeric)
            Time/s to delete
        sids : str, int, list(int)
            The Subject ID or a list of subject IDs that you want to delete the timepoints
            from. If it is a str:
                &#39;all&#39; - delete from all subjects
        &#39;&#39;&#39;
        if plutil.isstr(sids):
            if sids == &#39;all&#39;:
                sids = list(self._subjects.keys())
            else:
                raise ValueError(&#39;`sids` ({}) not recognized&#39;.format(sids))
        elif plutil.isint(sids):
            if sids not in self._subjects:
                raise IndexError(&#39;`sid` ({}) not found in subjects&#39;.format(
                    list(self._subjects.keys())))
            sids = [sids]
        elif plutil.isarray(sids):
            for sid in sids:
                if not plutil.isint(sid):
                    raise TypeError(&#39;Each sid ({}) must be an int&#39;.format(type(sid)))
                if sid not in self._subjects:
                    raise IndexError(&#39;Subject {} not found in subjects ({})&#39;.format(
                        sid, list(self._subjects.keys())))
        else:
            raise TypeError(&#39;`sids` ({}) type not recognized&#39;.format(type(sids)))
        if plutil.isnumeric(times):
            times = [times]
        elif plutil.isarray(times):
            for t in times:
                if not plutil.isnumeric(t):
                    raise TypeError(&#39;Each time ({}) must be a numeric&#39;.format(type(t)))
        else:
            raise TypeError(&#39;`times` ({}) type not recognized&#39;.format(type(times)))

        for t in times:
            for sid in sids:
                subj = self._subjects[sid]
                if t in subj.times:
                    subj.qpcr.pop(t, None)
                    subj.reads.pop(t,None)
                    subj.times = np.sort(list(subj.reads.keys()))

    def normalize_qpcr(self, max_value: float):
        &#39;&#39;&#39;Normalize the qPCR values such that the largest value is the max value
        over all the subjects

        Parameters
        ----------
        max_value : float, int
            This is the maximum qPCR value to

        Returns
        -------
        self
        &#39;&#39;&#39;
        if type(max_value) not in [int, float]:
            raise ValueError(&#39;max_value ({}) must either be an int or a float&#39;.format(
                type(max_value)))

        if self.qpcr_normalization_factor is not None:
            logging.warning(&#39;qPCR is already rescaled. unscaling and rescaling&#39;)
            self.denormalize_qpcr()

        temp_max = -1
        for subj in self:
            for key in subj.qpcr:
                temp_max = np.max([temp_max, subj.qpcr[key].mean()])

        self.qpcr_normalization_factor = max_value/temp_max
        logging.info(&#39;max_value found: {}, scaling_factor: {}&#39;.format(
            temp_max, self.qpcr_normalization_factor))

        for subj in self:
            for key in subj.qpcr:
                subj.qpcr[key].set_scaling_factor(scaling_factor=
                    self.qpcr_normalization_factor)
        return self

    def denormalize_qpcr(self):
        &#39;&#39;&#39;Denormalizes the qpcr values if necessary

        Returns
        -------
        self
        &#39;&#39;&#39;
        if self.qpcr_normalization_factor is None:
            logging.warning(&#39;qPCR is not normalized. Doing nothing&#39;)
            return
        for subj in self:
            for key in subj.qpcr:
                subj.qpcr[key].set_scaling_factor(scaling_factor=1)
        self.qpcr_normalization_factor = None
        return self

    def add_perturbation(self, a: Union[Dict[str, float], BasePerturbation], ends: Dict[str, float]=None, 
        name: str=None):
        &#39;&#39;&#39;Add a perturbation. 
        
        We can either do this by passing a perturbation object 
        (if we do this then we do not need to specify `ends`) or we can 
        specify the start and stop times (if we do this them we need to
        specify `ends`).

        `starts` and `ends`
        -------------------
        If `a` is a dict, this corresponds to the start times for each subject in the
        perturbation. Each dict maps the name of the subject to the timepoint that it
        either starts or ends, respectively.

        Parameters
        ----------
        a : dict, BasePerturbation
            If this is a dict, then this corresponds to the starts
            times of the perturbation for each subject. If this is a Pertubration object
            then we just add this.
        ends : dict
            Only necessary if `a` is a dict
        name : str, None
            Only necessary if `a` is a dict. Name of the perturbation
        
        Returns
        -------
        self
        &#39;&#39;&#39;
        if self.perturbations is None:
            self.perturbations = Perturbations()
        if plutil.isdict(a):
            if not plutil.isdict(ends):
                raise ValueError(&#39;If `a` is a dict, then `ends` ({}) &#39; \
                    &#39;needs to be a dict&#39;.format(type(ends)))
            if not plutil.isstr(name):
                raise ValueError(&#39;`name` ({}) must be defined as a str&#39;.format(type(name)))
            self.perturbations.append(BasePerturbation(starts=a, ends=ends, name=name))
        elif isperturbation(a):
            self.perturbations.append(a)
        else:
            raise ValueError(&#39;`a` ({}) must be a subclass of &#39; \
                &#39;pl.base.BasePerturbation or a dict&#39;.format(type(a)))
        return self
        
    def split_on_perturbations(self):
        &#39;&#39;&#39;Make new subjects for the time points that are divided by perturbations. 
        Throw out all of the data  where the perturbations are active.

        Returns
        -------
        self
        &#39;&#39;&#39;
        for subj in self:
            subj._split_on_perturbations()
        return self

    def times(self, agg: str) -&gt; np.ndarray:
        &#39;&#39;&#39;Aggregate the times of all the contained subjects

        These are the types of time aggregations:
            &#39;union&#39;: Take  theunion of the times of the subjects
            &#39;intersection&#39;: Take the intersection of the times of the subjects
        You can manually specify the times to include with a list of times. If times are not
        included in any of the subjects then we set them to NAN.

        Parameters
        ----------
        agg : str
            Type of aggregation to do of the times. Options: &#39;union&#39;, &#39;intersection&#39;
        &#39;&#39;&#39;
        if agg not in [&#39;union&#39;, &#39;intersection&#39;]:
            raise ValueError(&#39;`agg` ({}) not recognized&#39;.format(agg))

        all_times = []
        for subj in self:
            all_times = np.append(all_times, subj.times)
        all_times = np.sort(np.unique(all_times))
        if agg == &#39;union&#39;:
            times = all_times

        elif agg == &#39;intersection&#39;:
            times = []
            for t in all_times:
                addin = True
                for subj in self:
                    if t not in subj.times:
                        addin = False
                        break
                if addin:
                    times = np.append(times, t)
        else:
            raise ValueError(&#39;`times` ({}) not recognized&#39;.format(times))
        return times

    def _matrix(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; Tuple[np.ndarray, np.ndarray]:
        if dtype not in [&#39;raw&#39;, &#39;rel&#39;, &#39;abs&#39;]:
            raise ValueError(&#39;`dtype` ({}) not recognized&#39;.format(dtype))
        
        if agg == &#39;mean&#39;:
            aggfunc = np.nanmean
        elif agg == &#39;median&#39;:
            aggfunc = np.nanmedian
        elif agg == &#39;sum&#39;:
            aggfunc = np.nansum
        elif agg == &#39;max&#39;:
            aggfunc = np.nanmax
        elif agg == &#39;min&#39;:
            aggfunc = np.nanmin
        else:
            raise ValueError(&#39;`agg` ({}) not recognized&#39;.format(agg))

        if plutil.isstr(times):
            times = self.times(agg=times)
        elif plutil.isarray(times):
            times = np.array(times)
        else:
            raise TypeError(&#39;`times` type ({}) not recognized&#39;.format(type(times)))

        shape = (len(self.taxa), len(times))
        M = np.zeros(shape, dtype=float)
        for tidx, t in enumerate(times):
            temp = None
            for subj in self:
                if t not in subj.times:
                    continue
                if dtype == &#39;raw&#39;:
                    a = subj.reads[t]
                elif dtype == &#39;rel&#39;:
                    a = subj.reads[t]/np.sum(subj.reads[t])
                else:
                    rel = subj.reads[t]/np.sum(subj.reads[t])
                    a = rel * subj.qpcr[t].mean()
                if temp is None:
                    temp = (a.reshape(-1,1), )
                else:
                    temp = temp + (a.reshape(-1,1), )
            if temp is None:
                temp = np.zeros(len(self.taxa)) * np.nan
            else:
                temp = np.hstack(temp)
                temp = aggfunc(temp, axis=1)
            M[:, tidx] = temp

        return M, times

    def matrix(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; np.ndarray:
        &#39;&#39;&#39;Make a matrix of the aggregation of all the subjects in the subjectset

        Aggregation of subjects
        -----------------------
        What are the values for the taxa? Set the aggregation type using the parameter `agg`. 
        These are the types of aggregations:
            &#39;mean&#39;: Mean abundance of the taxon at a timepoint over all the subjects
            &#39;median&#39;: Median abundance of the taxon at a timepoint over all the subjects
            &#39;sum&#39;: Sum of all the abundances of the taxon at a timepoint over all the subjects
            &#39;max&#39;: Maximum abundance of the taxon at a timepoint over all the subjects
            &#39;min&#39;: Minimum abundance of the taxon at a timepoint over all the subjects

        Aggregation of times
        --------------------
        Which times to include? Set the times to include with the parameter `times`.
        These are the types of time aggregations:
            &#39;union&#39;: Take  theunion of the times of the subjects
            &#39;intersection&#39;: Take the intersection of the times of the subjects
        You can manually specify the times to include with a list of times. If times are not
        included in any of the subjects then we set them to NAN.

        Parameters
        ----------
        dtype : str
            What kind of data to return. Options:
                &#39;raw&#39;: Count data
                &#39;rel&#39;: Relative abundance
                &#39;abs&#39;: Abundance data
        agg : str
            Type of aggregation of the values. Options specified above.
        times : str, array
            The times to include
        
        Returns
        -------
        np.ndarray(n_taxa, n_times)
        &#39;&#39;&#39;
        M, _ =  self._matrix(dtype=dtype, agg=agg, times=times)
        return M

    def df(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Returns a dataframe of the data in matrix. Rows are taxa, columns are times.

        Parameters
        ----------
        dtype : str
            What kind of data to return. Options:
                &#39;raw&#39;: Count data
                &#39;rel&#39;: Relative abundance
                &#39;abs&#39;: Abundance data
        agg : str
            Type of aggregation of the values. Options specified above.
        times : str, array
            The times to include

        Returns
        -------
        pandas.DataFrame

        See Also
        --------
        mdsine2.Study.matrix
        &#39;&#39;&#39;
        M, times = self._matrix(dtype=dtype, agg=agg, times=times)
        index = [taxon.name for taxon in self.taxa]
        return pd.DataFrame(data=M, index=index, columns=times)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="mdsine2.pylab.base.condense_matrix_with_taxonomy"><code class="name flex">
<span>def <span class="ident">condense_matrix_with_taxonomy</span></span>(<span>M: Union[pandas.core.frame.DataFrame, numpy.ndarray], taxa: <a title="mdsine2.pylab.base.TaxaSet" href="#mdsine2.pylab.base.TaxaSet">TaxaSet</a>, fmt: str) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Condense the specified matrix M thats on the asv level
to a taxonomic label specified with <code>fmt</code>. If <code>M</code>
is a pandas.DataFrame then we assume the index are the Taxon
names. If <code>M</code> is a numpy.ndarray, then we assume that the
order of the matrix mirrors the order of the taxa. <code>fmt</code> is
passed through <code>pylab.base.taxaname_formatter</code> to get the label.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>M</code></strong> :&ensp;<code>numpy.ndarray, pandas.DataFrame</code></dt>
<dd>Matrix to condense</dd>
<dt><strong><code>taxa</code></strong> :&ensp;<code>pylab.base.TaxaSet</code></dt>
<dd>Set of Taxa with the relevant taxonomic information</dd>
<dt><strong><code>taxlevel</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the taxonomic level to condense to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>The index are the taxonomic classes. If M was a pandas.DataFrame, then
the columns in M correspond to these columns. If <code>M</code> was a
numpy.ndarray, then the order of the columsn correspond and no names
are sent.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def condense_matrix_with_taxonomy(M: Union[pd.DataFrame, np.ndarray], taxa: &#39;TaxaSet&#39;, fmt: str) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Condense the specified matrix M thats on the asv level
    to a taxonomic label specified with `fmt`. If `M` 
    is a pandas.DataFrame then we assume the index are the Taxon
    names. If `M` is a numpy.ndarray, then we assume that the 
    order of the matrix mirrors the order of the taxa. `fmt` is
    passed through `pylab.base.taxaname_formatter` to get the label.

    Parameters
    ----------
    M : numpy.ndarray, pandas.DataFrame
        Matrix to condense
    taxa : pylab.base.TaxaSet
        Set of Taxa with the relevant taxonomic information
    taxlevel : str
        This is the taxonomic level to condense to

    Returns
    -------
    pandas.DataFrame
        The index are the taxonomic classes. If M was a pandas.DataFrame, then
        the columns in M correspond to these columns. If `M` was a 
        numpy.ndarray, then the order of the columsn correspond and no names
        are sent.
    &#39;&#39;&#39;
    if not istaxaset(taxa):
        raise TypeError(&#39;`taxa` ({}) must be a pylab.base.TaxaSet&#39;.format(type(taxa)))
    if not plutil.isstr(fmt):
        raise TypeError(&#39;`fmt` ({}) must be a str&#39;.format(type(fmt)))

    if type(M) == pd.DataFrame:
        for idx in M.index:
            if idx not in taxa:
                raise ValueError(&#39;row `{}` not found in taxa&#39;.format(idx))
        names = M.index
    elif plutil.isarray(M):
        if M.shape[0] != len(taxa):
            raise ValueError(&#39;Number of rows in M ({}) not equal to number of taxa ({})&#39;.format(
                M.shape[0], len(taxa)))
        names = taxa.names.order
    else:
        raise TypeError(&#39;`M` ({}) type not recognized&#39;.format(type(M)))

    # Get the rows that correspond to each row
    d = {}
    for row, name in enumerate(names):
        taxon = taxa[name]
        tax = taxaname_formatter(format=fmt, taxon=taxon, taxa=taxa)
        if tax not in d:
            d[tax] = []
        d[tax].append(row)

    # Add all of the rows for each taxon
    Ms = ()
    index = []
    columns = None
    if not plutil.isarray(M):
        columns = M.columns
    for taxname, rows, in d.items():
        index.append(taxname)
        if plutil.isarray(M):
            temp = np.sum(M[rows, ...], axis=0).reshape(1,-1)
        else:
            temp = np.sum(M.iloc[rows], axis=0).reshape(1,-1)
        Ms = Ms + (temp, )
    matrix = np.vstack(Ms)
    df = pd.DataFrame(matrix, index=index, columns=columns)
    df = df.sort_index(axis=&#39;index&#39;)
    return df</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.isclusterable"><code class="name flex">
<span>def <span class="ident">isclusterable</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Determines whether the input is a subclass of Clusterable</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of Clusterable</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type Clusterable, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isclusterable(x: Any) -&gt; bool:
    &#39;&#39;&#39;Determines whether the input is a subclass of Clusterable

    Parameters
    ----------
    x : any
        Input instance to check the type of Clusterable
    
    Returns
    -------
    bool
        True if `x` is of type Clusterable, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Clusterable)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.isotu"><code class="name flex">
<span>def <span class="ident">isotu</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of OTU</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of OTU</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type OTU, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isotu(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of OTU

    Parameters
    ----------
    x : any
        Input instance to check the type of OTU
    
    Returns
    -------
    bool
        True if `x` is of type OTU, else False
    &#39;&#39;&#39;
    return issubclass(x.__class__, OTU)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.isperturbation"><code class="name flex">
<span>def <span class="ident">isperturbation</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of BasePerturbation</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of BasePerturbation</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type BasePerturbation, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isperturbation(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of BasePerturbation

    Parameters
    ----------
    x : any
        Input instance to check the type of BasePerturbation
    
    Returns
    -------
    bool
        True if `x` is of type BasePerturbation, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, BasePerturbation)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.isqpcrdata"><code class="name flex">
<span>def <span class="ident">isqpcrdata</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of qPCRData</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of qPCRData</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type qPCRData, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isqpcrdata(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of qPCRData

    Parameters
    ----------
    x : any
        Input instance to check the type of qPCRData
    
    Returns
    -------
    bool
        True if `x` is of type qPCRData, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, qPCRdata)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.issavable"><code class="name flex">
<span>def <span class="ident">issavable</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of Savable</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of Savable</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type Savable, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def issavable(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Savable

    Parameters
    ----------
    x : any
        Input instance to check the type of Savable
    
    Returns
    -------
    bool
        True if `x` is of type Savable, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Saveable)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.isstudy"><code class="name flex">
<span>def <span class="ident">isstudy</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of Study</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of Study</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type Study, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isstudy(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Study

    Parameters
    ----------
    x : any
        Input instance to check the type of Study
    
    Returns
    -------
    bool
        True if `x` is of type Study, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Study)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.issubject"><code class="name flex">
<span>def <span class="ident">issubject</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of Subject</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of Subject</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type Subject, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def issubject(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Subject

    Parameters
    ----------
    x : any
        Input instance to check the type of Subject
    
    Returns
    -------
    bool
        True if `x` is of type Subject, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Subject)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.istaxaset"><code class="name flex">
<span>def <span class="ident">istaxaset</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of TaxaSet</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of TaxaSet</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type TaxaSet, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def istaxaset(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of TaxaSet

    Parameters
    ----------
    x : any
        Input instance to check the type of TaxaSet
    
    Returns
    -------
    bool
        True if `x` is of type TaxaSet, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, TaxaSet)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.istaxon"><code class="name flex">
<span>def <span class="ident">istaxon</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of Taxon</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of Taxon</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type Taxon, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def istaxon(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Taxon

    Parameters
    ----------
    x : any
        Input instance to check the type of Taxon
    
    Returns
    -------
    bool
        True if `x` is of type Taxon, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Taxon)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.istaxontype"><code class="name flex">
<span>def <span class="ident">istaxontype</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of OTU or Taxon</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of OTU or Taxon</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type OTU or Taxon, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def istaxontype(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of OTU or Taxon

    Parameters
    ----------
    x : any
        Input instance to check the type of OTU or Taxon
    
    Returns
    -------
    bool
        True if `x` is of type OTU or Taxon, else False
    &#39;&#39;&#39;
    return istaxon(x) or isotu(x)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.istraceable"><code class="name flex">
<span>def <span class="ident">istraceable</span></span>(<span>x: Any) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Checks whether the input is a subclass of Traceable</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>any</code></dt>
<dd>Input instance to check the type of Traceable</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if <code>x</code> is of type Traceable, else False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def istraceable(x: Any) -&gt; bool:
    &#39;&#39;&#39;Checks whether the input is a subclass of Traceable

    Parameters
    ----------
    x : any
        Input instance to check the type of Traceable
    
    Returns
    -------
    bool
        True if `x` is of type Traceable, else False
    &#39;&#39;&#39;
    return x is not None and issubclass(x.__class__, Traceable)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.taxaname_for_paper"><code class="name flex">
<span>def <span class="ident">taxaname_for_paper</span></span>(<span>taxon: Union[ForwardRef('<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>'), ForwardRef('<a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>')], taxa: <a title="mdsine2.pylab.base.TaxaSet" href="#mdsine2.pylab.base.TaxaSet">TaxaSet</a>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Makes the name in the format needed for the paper</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>taxon</code></strong> :&ensp;<code>pylab.base.Taxon/pylab.base.OTU</code></dt>
<dd>This is the taxon we are making the name for</dd>
<dt><strong><code>taxa</code></strong> :&ensp;<code>pylab.base.TaxaSet</code></dt>
<dd>This is the TaxaSet object that contains the taxon objects</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def taxaname_for_paper(taxon: Union[&#34;Taxon&#34;, &#34;OTU&#34;], taxa: &#34;TaxaSet&#34;) -&gt; str:
    &#39;&#39;&#39;Makes the name in the format needed for the paper

    Parameters
    ----------
    taxon : pylab.base.Taxon/pylab.base.OTU
        This is the taxon we are making the name for
    taxa : pylab.base.TaxaSet
        This is the TaxaSet object that contains the taxon objects

    Returns
    -------
    str
    &#39;&#39;&#39;
    taxon = taxa[taxon]
    if taxon.tax_is_defined(&#39;species&#39;):
        species = taxon.taxonomy[&#39;species&#39;]
        species = species.split(&#39;/&#39;)
        if len(species) &gt;= 3:
            species = species[:2]
        species = &#39;/&#39;.join(species)
        label = taxaname_formatter(
            format=&#39;%(genus)s {spec} %(name)s&#39;.format(
                spec=species), 
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;genus&#39;):
        label = taxaname_formatter(
            format=&#39;* %(genus)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;family&#39;):
        label = taxaname_formatter(
            format=&#39;** %(family)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;order&#39;):
        label = taxaname_formatter(
            format=&#39;*** %(order)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;class&#39;):
        label = taxaname_formatter(
            format=&#39;**** %(class)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;phylum&#39;):
        label = taxaname_formatter(
            format=&#39;***** %(phylum)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    elif taxon.tax_is_defined(&#39;kingdom&#39;):
        label = taxaname_formatter(
            format=&#39;****** %(kingdom)s %(name)s&#39;,
            taxon=taxon, taxa=taxa)
    else:
        logging.debug(&#39;Something went wrong - no taxnonomy: {}&#39;.format(str(taxon)))
        label = &#39;NA {}&#39;.format(taxa[taxon].name)

    return label</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.taxaname_formatter"><code class="name flex">
<span>def <span class="ident">taxaname_formatter</span></span>(<span>format: str, taxon: Union[ForwardRef('<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>'), ForwardRef('<a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>')], taxa: <a title="mdsine2.pylab.base.TaxaSet" href="#mdsine2.pylab.base.TaxaSet">TaxaSet</a>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Format the label of a taxon. Specify the taxon by its index in the TaxaSet <code>taxa</code>.</p>
<p>If <code>format == mdsine.TAXANAME_PAPER_FORMAT</code>, then we call the function
<code><a title="mdsine2.pylab.base.taxaname_for_paper" href="#mdsine2.pylab.base.taxaname_for_paper">taxaname_for_paper()</a></code>.</p>
<h2 id="example">Example</h2>
<p>taxon is an Taxon object at index 0 where:</p>
<pre><code>taxon.genus = 'A'
taxon.id = 1234532
</code></pre>
<p>In[1]</p>
<pre><code>```python-repl
&gt;&gt;&gt; taxaname_formatter(
    format='%(genus)s: %(index)s',
    taxon=1234532,
    taxa=taxa)
'A: 0'
</code></pre>
<p>In[2]</p>
<pre><code>&gt;&gt;&gt; taxaname_formatter(
    format='%(genus)s: %(genus)s',
    taxon=1234532,
    taxa=taxa)
'A: A'
</code></pre>
<p>In[3]</p>
<pre><code>&gt;&gt;&gt; taxaname_formatter(
    format='%(index)s',
    taxon=1234532,
    taxa=taxa)
'0'
</code></pre>
<p>In[4]</p>
<pre><code>&gt;&gt;&gt; taxaname_formatter(
    format='%(geNus)s: %(genus)s',
    taxon=1234532,
    taxa=taxa)
'%(geNus)s: A'
</code></pre>
<p>```</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>format</code></strong> :&ensp;<code>str</code></dt>
<dd>
<ul>
<li>This is the format for us to do the labels. Options:<ul>
<li>'%(paperformat)s'<ul>
<li>Return the <code><a title="mdsine2.pylab.base.taxaname_for_paper" href="#mdsine2.pylab.base.taxaname_for_paper">taxaname_for_paper()</a></code></li>
</ul>
</li>
<li>'%(name)s'<ul>
<li>Name of the taxon (pylab.base..name)</li>
</ul>
</li>
<li>'%(id)s'<ul>
<li>ID of the taxon (pylab.base..id)</li>
</ul>
</li>
<li>'%(index)s'<ul>
<li>The order that this appears in the TaxaSet</li>
</ul>
</li>
<li>'%(species)s'<ul>
<li><code>'species'</code> taxonomic classification of the taxon</li>
</ul>
</li>
<li>'%(genus)s'<ul>
<li><code>'genus'</code> taxonomic classification of the taxon</li>
</ul>
</li>
<li>'%(family)s'<ul>
<li><code>'family'</code> taxonomic classification of the taxon</li>
</ul>
</li>
<li>'%(class)s'<ul>
<li><code>'class'</code> taxonomic classification of the taxon</li>
</ul>
</li>
<li>'%(order)s'<ul>
<li><code>'order'</code> taxonomic classification of the taxon</li>
</ul>
</li>
<li>'%(phylum)s'<ul>
<li><code>'phylum'</code> taxonomic classification of the taxon</li>
</ul>
</li>
<li>'%(kingdom)s'<ul>
<li><code>'kingdom'</code> taxonomic classification of the taxon</li>
</ul>
</li>
</ul>
</li>
</ul>
</dd>
<dt><strong><code>taxon</code></strong> :&ensp;<code>str, int, <a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a></code></dt>
<dd>Taxon/OTU object or identifier (name, ID, index)</dd>
<dt><strong><code>taxa</code></strong> :&ensp;<code>pylab.base.TaxaSet</code></dt>
<dd>Dataset containing all of the information for the taxa</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def taxaname_formatter(format: str, taxon: Union[&#34;Taxon&#34;, &#34;OTU&#34;], taxa: &#34;TaxaSet&#34;) -&gt; str:
    &#39;&#39;&#39;Format the label of a taxon. Specify the taxon by its index in the TaxaSet `taxa`.

    If `format == mdsine.TAXANAME_PAPER_FORMAT`, then we call the function
    `taxaname_for_paper`.

    Example:
        taxon is an Taxon object at index 0 where:
        ```
        taxon.genus = &#39;A&#39;
        taxon.id = 1234532
        ```
        In[1]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(genus)s: %(index)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;A: 0&#39;
        ```
        In[2]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(genus)s: %(genus)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;A: A&#39;
        ```
        In[3]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(index)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;0&#39;
        ```
        In[4]
        ```
        &gt;&gt;&gt; taxaname_formatter(
            format=&#39;%(geNus)s: %(genus)s&#39;,
            taxon=1234532,
            taxa=taxa)
        &#39;%(geNus)s: A&#39;
        ```

    Parameters
    ----------
    format : str
        - This is the format for us to do the labels. Options:
            - &#39;%(paperformat)s&#39;
                * Return the `taxaname_for_paper`
            - &#39;%(name)s&#39;
                * Name of the taxon (pylab.base..name)
            - &#39;%(id)s&#39;
                * ID of the taxon (pylab.base..id)
            - &#39;%(index)s&#39;
                * The order that this appears in the TaxaSet
            - &#39;%(species)s&#39;
                * `&#39;species&#39;` taxonomic classification of the taxon
            - &#39;%(genus)s&#39;
                * `&#39;genus&#39;` taxonomic classification of the taxon
            - &#39;%(family)s&#39;
                * `&#39;family&#39;` taxonomic classification of the taxon
            - &#39;%(class)s&#39;
                * `&#39;class&#39;` taxonomic classification of the taxon
            - &#39;%(order)s&#39;
                * `&#39;order&#39;` taxonomic classification of the taxon
            - &#39;%(phylum)s&#39;
                * `&#39;phylum&#39;` taxonomic classification of the taxon
            - &#39;%(kingdom)s&#39;
                * `&#39;kingdom&#39;` taxonomic classification of the taxon
    taxon : str, int, Taxon, OTU
        Taxon/OTU object or identifier (name, ID, index)
    taxa : pylab.base.TaxaSet
        Dataset containing all of the information for the taxa

    Returns
    -------
    str
    &#39;&#39;&#39;
    if format == TAXANAME_PAPER_FORMAT:
        return taxaname_for_paper(taxon=taxon, taxa=taxa)
    taxon = taxa[taxon]
    index = taxon.idx
    label = format.replace(NAME_FORMATTER, str(taxon.name))
    label = label.replace(ID_FORMATTER, str(taxon.id))
    label = label.replace(INDEX_FORMATTER,  str(index))

    if PAPER_FORMATTER in label:
        label = label.replace(PAPER_FORMATTER, &#39;%(temp)s&#39;)
        label = label.replace(&#39;%(temp)s&#39;, taxaname_for_paper(taxon=taxon, taxa=taxa))
    
    for i in range(len(TAX_LEVELS)-1):
        taxlevel = TAX_LEVELS[i]
        fmt = _TAXFORMATTERS[i]
        try:
            label = label.replace(fmt, str(taxon.get_taxonomy(taxlevel)))
        except:
            logging.critical(&#39;taxon: {}&#39;.format(taxon))
            logging.critical(&#39;fmt: {}&#39;.format(fmt))
            logging.critical(&#39;label: {}&#39;.format(label))
            raise

    return label</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mdsine2.pylab.base.BasePerturbation"><code class="flex name class">
<span>class <span class="ident">BasePerturbation</span></span>
<span>(</span><span>name: str, starts: Dict[str, float] = None, ends: Dict[str, float] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Base perturbation class. </p>
<p>Does not have to be applied to all subjects, and each subject can have a different start and
end time to each other.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str, None</code></dt>
<dd>
<ul>
<li>This is the name of the perturabtion. If nothing is given then the name will be
set to the perturbation index</li>
</ul>
</dd>
<dt><strong><code>starts</code></strong>, <strong><code>ends</code></strong> :&ensp;<code>dict, None</code></dt>
<dd>
<ul>
<li>This is a map to the start and end times for the subject that have this perturbation</li>
</ul>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BasePerturbation:
    &#39;&#39;&#39;Base perturbation class. 

    Does not have to be applied to all subjects, and each subject can have a different start and
    end time to each other.

    Parameters
    ----------
    name : str, None
        - This is the name of the perturabtion. If nothing is given then the name will be
          set to the perturbation index
    starts, ends : dict, None
        - This is a map to the start and end times for the subject that have this perturbation
    &#39;&#39;&#39;
    def __init__(self, name: str, starts: Dict[str, float]=None, ends: Dict[str, float]=None):
        if not plutil.isstr(name):
            raise TypeError(&#39;`name` ({}) must be a str&#39;.format(type(name)))
        if (starts is not None and ends is None) or (starts is None and ends is not None):
            raise ValueError(&#39;If `starts` or `ends` is specified, the other must be specified.&#39;)
        if starts is not None:
            if not plutil.isdict(starts):
                raise TypeError(&#39;`starts` ({}) must be a dict&#39;.format(starts))
            if not plutil.isdict(ends):
                raise TypeError(&#39;`ends` ({}) must be a dict&#39;.format(ends))

        self.starts = starts
        self.ends = ends
        self.name = name

    def __str__(self) -&gt; str:
        s = &#39;Perturbation {}:\n&#39;.format(self.name)
        if self.starts is not None:
            for subj in self.starts:
                s += &#39;\tSubject {}: ({}, {})\n&#39;.format(subj, self.starts[subj], 
                    self.ends[subj])
        return s

    def __contains__(self, a: Union[str]) -&gt; bool:
        &#39;&#39;&#39;Checks if subject name `a` is in this perturbation
        &#39;&#39;&#39;
        if issubject(a):
            a = a.name
        return a in self.starts

    def isactive(self, time: Union[float, int], subj: str) -&gt; bool:
        &#39;&#39;&#39;Returns a `bool` if the perturbation is on at time `time`.

        Parameters
        ----------
        time : float, int
            Time to check
        subj : str
            Subject to check

        Returns
        -------
        bool

        Raises
        ------
        ValueError
            If there are no start and end times set
        &#39;&#39;&#39;
        if self.starts is None:
            raise ValueError(&#39;`start` is not set in {}&#39;.format(self.name))
        try:
            start = self.starts[subj]
            end = self.ends[subj]
        except:
            raise KeyError(&#39;`subj` {} not specified for {}&#39;.format(subj, self.name))

        return time &gt; start and time &lt;= end</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.contrib.ClusterPerturbationEffect" href="contrib.html#mdsine2.pylab.contrib.ClusterPerturbationEffect">ClusterPerturbationEffect</a></li>
<li><a title="mdsine2.pylab.contrib.Perturbation" href="contrib.html#mdsine2.pylab.contrib.Perturbation">Perturbation</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.BasePerturbation.isactive"><code class="name flex">
<span>def <span class="ident">isactive</span></span>(<span>self, time: Union[float, int], subj: str) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a <code>bool</code> if the perturbation is on at time <code>time</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>time</code></strong> :&ensp;<code>float, int</code></dt>
<dd>Time to check</dd>
<dt><strong><code>subj</code></strong> :&ensp;<code>str</code></dt>
<dd>Subject to check</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If there are no start and end times set</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isactive(self, time: Union[float, int], subj: str) -&gt; bool:
    &#39;&#39;&#39;Returns a `bool` if the perturbation is on at time `time`.

    Parameters
    ----------
    time : float, int
        Time to check
    subj : str
        Subject to check

    Returns
    -------
    bool

    Raises
    ------
    ValueError
        If there are no start and end times set
    &#39;&#39;&#39;
    if self.starts is None:
        raise ValueError(&#39;`start` is not set in {}&#39;.format(self.name))
    try:
        start = self.starts[subj]
        end = self.ends[subj]
    except:
        raise KeyError(&#39;`subj` {} not specified for {}&#39;.format(subj, self.name))

    return time &gt; start and time &lt;= end</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.pylab.base.ClusterItem"><code class="flex name class">
<span>class <span class="ident">ClusterItem</span></span>
<span>(</span><span>name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>These are single points that get clustered</p>
<p>It must have the parameter
'name'</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusterItem:
    &#39;&#39;&#39;These are single points that get clustered

    It must have the parameter
        &#39;name&#39;
    &#39;&#39;&#39;
    def __init__(self, name: str):
        self.name = name

    def cluster_str(self) -&gt; str:
        return self.name</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.ClusterItem.cluster_str"><code class="name flex">
<span>def <span class="ident">cluster_str</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cluster_str(self) -&gt; str:
    return self.name</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.pylab.base.Clusterable"><code class="flex name class">
<span>class <span class="ident">Clusterable</span></span>
</code></dt>
<dd>
<div class="desc"><p>This is the base class for something to be clusterable (be used to cluster in
pylab.cluster.Clustering). These are the functions that need to be implemented
for it to be able to be clustered.</p>
<p><code>stritem</code>: This is the function that we use to get the label of the item</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Clusterable(Saveable):
    &#39;&#39;&#39;This is the base class for something to be clusterable (be used to cluster in
    pylab.cluster.Clustering). These are the functions that need to be implemented
    for it to be able to be clustered.

    `stritem`: This is the function that we use to get the label of the item
    &#39;&#39;&#39;
    def __len__(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def __getitem__(self, key):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def __iter__(self):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def __contains__(self, key):
        raise NotImplementedError(&#39;You must implement this function&#39;)

    def stritem(self, key):
        raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.TaxaSet" href="#mdsine2.pylab.base.TaxaSet">TaxaSet</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Clusterable.stritem"><code class="name flex">
<span>def <span class="ident">stritem</span></span>(<span>self, key)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stritem(self, key):
    raise NotImplementedError(&#39;You must implement this function&#39;)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.base.Saveable.load" href="#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.save" href="#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.set_save_location" href="#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.pylab.base.CustomOrderedDict"><code class="flex name class">
<span>class <span class="ident">CustomOrderedDict</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Order is an initialized version of self.keys() -&gt; much more efficient
index maps the key to the index in order:
- order (list)
- same as a numpy version of the keys in order
- index (dict)
- Maps the key to the index that it was inserted in</p>
<p>Extension of the OrderedDict</p>
<h2 id="paramters">Paramters</h2>
<p>args, kwargs : Arguments
These are extra arguments to initialize the baseline OrderedDict</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CustomOrderedDict(dict):
    &#39;&#39;&#39;Order is an initialized version of self.keys() -&gt; much more efficient
    index maps the key to the index in order:
    - order (list)
        - same as a numpy version of the keys in order
    - index (dict)
        - Maps the key to the index that it was inserted in
    &#39;&#39;&#39;

    def __init__(self, *args, **kwargs):
        &#39;&#39;&#39;Extension of the OrderedDict

        Paramters
        ---------
        args, kwargs : Arguments
            These are extra arguments to initialize the baseline OrderedDict
        &#39;&#39;&#39;
        dict.__init__(self, *args, **kwargs)
        self.order = None
        self.index = None

    def update_order(self):
        &#39;&#39;&#39;This will update the reverse dictionary based on the index. It will 
        also redo the indexes if a taxon was deleted
        &#39;&#39;&#39;
        self.order = np.array(list(self.keys()))
        self.index = {}
        for i, taxon in enumerate(self.order):
            self.index[taxon] = i</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.CustomOrderedDict.update_order"><code class="name flex">
<span>def <span class="ident">update_order</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This will update the reverse dictionary based on the index. It will
also redo the indexes if a taxon was deleted</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_order(self):
    &#39;&#39;&#39;This will update the reverse dictionary based on the index. It will 
    also redo the indexes if a taxon was deleted
    &#39;&#39;&#39;
    self.order = np.array(list(self.keys()))
    self.index = {}
    for i, taxon in enumerate(self.order):
        self.index[taxon] = i</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.pylab.base.OTU"><code class="flex name class">
<span>class <span class="ident">OTU</span></span>
<span>(</span><span>anchor: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, ForwardRef('<a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>')], other: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, ForwardRef('<a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>')])</span>
</code></dt>
<dd>
<div class="desc"><p>Aggregates of Taxon objects</p>
<p>NOTE: For self consistency, let the class TaxaSet initialize this object.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>anchor</code></strong>, <strong><code>other</code></strong> :&ensp;<code>mdsine2.Taxon, mdsine2.OTU</code></dt>
<dd>These are the taxa/Aggregates that you're joining together. The anchor is
the one you are setting the sequeunce and taxonomy to</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OTU(Taxon):
    &#39;&#39;&#39;Aggregates of Taxon objects

    NOTE: For self consistency, let the class TaxaSet initialize this object.

    Parameters
    ----------
    anchor, other : mdsine2.Taxon, mdsine2.OTU
        These are the taxa/Aggregates that you&#39;re joining together. The anchor is
        the one you are setting the sequeunce and taxonomy to
    &#39;&#39;&#39;
    def __init__(self, anchor: Union[Taxon, &#39;OTU&#39;], other: Union[Taxon, &#39;OTU&#39;]):
        name = anchor.name + &#39;_agg&#39;
        Taxon.__init__(self, name=name, idx=anchor.idx, sequence=anchor.sequence)

        _agg_taxa = {}

        if isotu(anchor):
            if other.name in anchor.aggregated_taxa:
                raise ValueError(&#39;`other` ({}) already aggregated with anchor &#39; \
                    &#39;({}) ({})&#39;.format(other.name, anchor.name, anchor.aggregated_taxa))
            agg1 = anchor.aggregated_taxa
            agg1_seq = anchor.aggregated_seqs
            for k,v in anchor.aggregated_taxonomies.items():
                _agg_taxa[k] = v
        else:
            agg1 = [anchor.name]
            agg1_seq = {anchor.name: anchor.sequence}
            _agg_taxa[anchor.name] = anchor.taxonomy

        if isotu(other):
            if anchor.name in other.aggregated_taxa:
                raise ValueError(&#39;`anchor` ({}) already aggregated with other &#39; \
                    &#39;({}) ({})&#39;.format(anchor.name, other.name, other.aggregated_taxa))
            agg2 = other.aggregated_taxa
            agg2_seq = other.aggregated_seqs
            for k,v in other.aggregated_taxonomies.items():
                _agg_taxa[k] = v
        else:
            agg2 = [other.name]
            agg2_seq = {other.name: other.sequence}
            _agg_taxa[other.name] = other.taxonomy

        self.aggregated_taxa = agg1 + agg2 # list
        self.aggregated_seqs = agg1_seq # dict: taxon.name (str) -&gt; sequence (str)
        self.aggregated_taxonomies = _agg_taxa # dict: taxon.name (str) -&gt; (dict: tax level (str) -&gt; taxonomy (str))
        for k,v in agg2_seq.items():
            self.aggregated_seqs[k] = v

        self.taxonomy = anchor.taxonomy

    def __str__(self) -&gt; str:
        return &#39;OTU\n\tid: {}\n\tidx: {}\n\tname: {}\n&#39; \
            &#39;\tAggregates: {}\n&#39; \
            &#39;\ttaxonomy:\n\t\tkingdom: {}\n\t\tphylum: {}\n&#39; \
            &#39;\t\tclass: {}\n\t\torder: {}\n\t\tfamily: {}\n&#39; \
            &#39;\t\tgenus: {}\n\t\tspecies: {}&#39;.format(
            self.id, self.idx, self.name, self.aggregated_taxa,
            self.taxonomy[&#39;kingdom&#39;], self.taxonomy[&#39;phylum&#39;],
            self.taxonomy[&#39;class&#39;], self.taxonomy[&#39;order&#39;],
            self.taxonomy[&#39;family&#39;], self.taxonomy[&#39;genus&#39;],
            self.taxonomy[&#39;species&#39;])

    def generate_consensus_seq(self, threshold: float=0.65, noconsensus_char: str=&#39;N&#39;):
        &#39;&#39;&#39;Generate the consensus sequence for the OTU given the sequences
        of all the contained ASVs

        Parameters
        ----------
        threshold : float
            This is the threshold for consensus (0 &lt; threshold &lt;= 1)
        noconsensus_char : str
            This is the character to set base if no consensus base is found
            at the respective position.

        NOTE
        ----
        Situation where all of the sequences are not the same length is not implemented
        &#39;&#39;&#39;
        if not plutil.isstr(noconsensus_char):
            raise TypeError(&#39;`noconsensus_char` ({}) must be a str&#39;.format(
                type(noconsensus_char)))
        if not plutil.isnumeric(threshold):
            raise TypeError(&#39;`threshold` ({}) must be a numeric&#39;.format(threshold))
        if threshold &lt; 0 or threshold &gt; 1:
            raise ValueError(&#39;`threshold` ({}) must be 0 &lt;= thresold &lt;= 1&#39;.format(threshold))

        # Check if all of the sequences are the same length
        agg_seqs = [seq for seq in self.aggregated_seqs.values()]
        l = None
        for seq in agg_seqs:
            if l is None:
                l = len(seq)
            if len(seq) != l:
                raise NotImplementedError(&#39;Unaligned sequences not implemented yet&#39;)

        # Generate the consensus base for each base position
        consensus_seq = &#39;&#39;
        for i in range(l):

            # Count the number of times each base occurs at position `i`
            found = {}
            for seq in agg_seqs:
                base = seq[i]
                if base not in found:
                    found[base] = 1
                else:
                    found[base] += 1

            # Set the base
            if len(found) == 1:
                # Every sequence agrees on this base. Set
                consensus_seq += list(found.keys())[0]
            else:
                # Get the maximum consensus
                consensus_percent = -1
                consensus_base = None
                for base in found:
                    consensus = 1 - (found[base]/len(agg_seqs))
                    if consensus &gt; consensus_percent:
                        consensus_percent = consensus
                        consensus_base = base

                # Set the consensus base if it passes the threshold
                if consensus_percent &gt;= threshold:
                    logging.debug(&#39;Consensus found for taxon {} in position {} as {}, found &#39; \
                        &#39;{}&#39;.format(self.name, i, consensus_base, found))
                    consensus_seq += consensus_base
                else:
                    logging.debug(&#39;No consensus for taxon {} in position {}. Consensus: {}&#39; \
                        &#39;, found {}&#39;.format(self.name, i, consensus, found))
                    consensus_seq += noconsensus_char

        # Check for errors with consensus sequence
        for seq in agg_seqs:
            perc_dist = diversity.beta.hamming(seq, consensus_seq, 
                ignore_char=noconsensus_char)/l
            if perc_dist &gt; 0.03:
                logging.warning(&#39;Taxon {} has a hamming distance &gt; 3% ({}) to the generated &#39; \
                    &#39;consensus sequence {} from individual sequence {}. Check that sequences &#39; \
                    &#39;make sense&#39;.format(self.name, perc_dist, consensus_seq, seq))

        # Set the consensus sequence as the OTU&#39;s sequence
        self.sequence = consensus_seq

    def generate_consensus_taxonomy(self, consensus_table: pd.DataFrame=None):
        &#39;&#39;&#39;Set the taxonomy of the OTU to the consensus taxonomy of the.

        If one of the ASVs is defined at a lower level than another ASV, use
        that taxonomy. If ASVs&#39; taxonomies disagree at the species level, use the 
        union of all the species. 

        Disagreeing taxonomy
        --------------------
        If the taxonomy of the ASVs differ on a taxonomic level other than species, we use an alternate 
        way of naming the OTU. The input `consensus_table` is a `pandas.DataFrame` object showing the
        taxonomic classification of an OTU. You would get this table by running RDP on the consensus
        sequence.
        
        If the consensus table is not given, then we specify the lowest level that they agree. If the 
        consensus table is given, then we use the taxonomy specified in that table.

        Examples
        --------
        ```
        Input:
         kingdom          phylum                class        order             family  genus       species      asv
        Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis  ASV_722
        Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea            NA  ASV_991
        
        Output:
         kingdom          phylum                class        order             family  genus       species
        Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis
        ```

        ```
        Input:
         kingdom          phylum           class              order              family            genus                 species      asv
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_283
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_302
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium    adolescentis/faecale  ASV_340
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  choerinum/pseudolongum  ASV_668

        Ouput:
         kingdom          phylum           class              order              family            genus                                      species
        Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  adolescentis/faecale/choerinum/pseudolongum
        ```

        Parameters
        ----------
        consensus_table : pd.DataFrame
            Table for resolving conflicts
        &#39;&#39;&#39;
        # Check that all the taxonomies have the same lineage
        set_to_na = False
        set_from_table = False
        for tax in TAX_LEVELS:
            if set_to_na:
                self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
                continue
            if set_from_table:
                if tax not in consensus_table.columns:
                    self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
                else:
                    self.taxonomy[tax] = consensus_table[tax][self.name]
                continue
            if tax == &#39;asv&#39;:
                continue
            consensus = []
            for taxonname in self.aggregated_taxa:
                if tax == &#39;species&#39;:
                    aaa = self.aggregated_taxonomies[taxonname][tax].split(&#39;/&#39;)
                else:
                    aaa = [self.aggregated_taxonomies[taxonname][tax]]
                for bbb in aaa:
                    if bbb in consensus:
                        continue
                    else:
                        consensus.append(bbb)
            if DEFAULT_TAXLEVEL_NAME in consensus:
                consensus.remove(DEFAULT_TAXLEVEL_NAME)

            if len(consensus) == 0:
                # No taxonomy found at this level
                self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
            elif len(consensus) == 1:
                # All taxonomies agree
                self.taxonomy[tax] = consensus[0]
            else:
                # All taxonomies do not agree
                if tax == &#39;species&#39;:
                    # Take the union of the species
                    self.taxonomy[tax] = &#39;/&#39;.join(consensus)
                else:
                    # This means that the taxonomy is different on a level different than
                    logging.critical(&#39;{} taxonomy does not agree&#39;.format(self.name))
                    logging.critical(str(self))
                    for taxonname in self.aggregated_taxonomies:
                        logging.warning(&#39;{}&#39;.format(list(self.aggregated_taxonomies[taxonname].values())))

                    if consensus_table is not None:
                        # Set from the table
                        self.taxonomy[tax] = consensus_table[tax][self.name]
                        set_from_table = True

                    else:
                        # Set this taxonomic level and everything below it to NA
                        self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
                        set_to_na = True</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a></li>
<li><a title="mdsine2.pylab.base.ClusterItem" href="#mdsine2.pylab.base.ClusterItem">ClusterItem</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.OTU.generate_consensus_seq"><code class="name flex">
<span>def <span class="ident">generate_consensus_seq</span></span>(<span>self, threshold: float = 0.65, noconsensus_char: str = 'N')</span>
</code></dt>
<dd>
<div class="desc"><p>Generate the consensus sequence for the OTU given the sequences
of all the contained ASVs</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>This is the threshold for consensus (0 &lt; threshold &lt;= 1)</dd>
<dt><strong><code>noconsensus_char</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the character to set base if no consensus base is found
at the respective position.</dd>
</dl>
<h2 id="note">Note</h2>
<p>Situation where all of the sequences are not the same length is not implemented</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_consensus_seq(self, threshold: float=0.65, noconsensus_char: str=&#39;N&#39;):
    &#39;&#39;&#39;Generate the consensus sequence for the OTU given the sequences
    of all the contained ASVs

    Parameters
    ----------
    threshold : float
        This is the threshold for consensus (0 &lt; threshold &lt;= 1)
    noconsensus_char : str
        This is the character to set base if no consensus base is found
        at the respective position.

    NOTE
    ----
    Situation where all of the sequences are not the same length is not implemented
    &#39;&#39;&#39;
    if not plutil.isstr(noconsensus_char):
        raise TypeError(&#39;`noconsensus_char` ({}) must be a str&#39;.format(
            type(noconsensus_char)))
    if not plutil.isnumeric(threshold):
        raise TypeError(&#39;`threshold` ({}) must be a numeric&#39;.format(threshold))
    if threshold &lt; 0 or threshold &gt; 1:
        raise ValueError(&#39;`threshold` ({}) must be 0 &lt;= thresold &lt;= 1&#39;.format(threshold))

    # Check if all of the sequences are the same length
    agg_seqs = [seq for seq in self.aggregated_seqs.values()]
    l = None
    for seq in agg_seqs:
        if l is None:
            l = len(seq)
        if len(seq) != l:
            raise NotImplementedError(&#39;Unaligned sequences not implemented yet&#39;)

    # Generate the consensus base for each base position
    consensus_seq = &#39;&#39;
    for i in range(l):

        # Count the number of times each base occurs at position `i`
        found = {}
        for seq in agg_seqs:
            base = seq[i]
            if base not in found:
                found[base] = 1
            else:
                found[base] += 1

        # Set the base
        if len(found) == 1:
            # Every sequence agrees on this base. Set
            consensus_seq += list(found.keys())[0]
        else:
            # Get the maximum consensus
            consensus_percent = -1
            consensus_base = None
            for base in found:
                consensus = 1 - (found[base]/len(agg_seqs))
                if consensus &gt; consensus_percent:
                    consensus_percent = consensus
                    consensus_base = base

            # Set the consensus base if it passes the threshold
            if consensus_percent &gt;= threshold:
                logging.debug(&#39;Consensus found for taxon {} in position {} as {}, found &#39; \
                    &#39;{}&#39;.format(self.name, i, consensus_base, found))
                consensus_seq += consensus_base
            else:
                logging.debug(&#39;No consensus for taxon {} in position {}. Consensus: {}&#39; \
                    &#39;, found {}&#39;.format(self.name, i, consensus, found))
                consensus_seq += noconsensus_char

    # Check for errors with consensus sequence
    for seq in agg_seqs:
        perc_dist = diversity.beta.hamming(seq, consensus_seq, 
            ignore_char=noconsensus_char)/l
        if perc_dist &gt; 0.03:
            logging.warning(&#39;Taxon {} has a hamming distance &gt; 3% ({}) to the generated &#39; \
                &#39;consensus sequence {} from individual sequence {}. Check that sequences &#39; \
                &#39;make sense&#39;.format(self.name, perc_dist, consensus_seq, seq))

    # Set the consensus sequence as the OTU&#39;s sequence
    self.sequence = consensus_seq</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.OTU.generate_consensus_taxonomy"><code class="name flex">
<span>def <span class="ident">generate_consensus_taxonomy</span></span>(<span>self, consensus_table: pandas.core.frame.DataFrame = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the taxonomy of the OTU to the consensus taxonomy of the.</p>
<p>If one of the ASVs is defined at a lower level than another ASV, use
that taxonomy. If ASVs' taxonomies disagree at the species level, use the
union of all the species. </p>
<h2 id="disagreeing-taxonomy">Disagreeing Taxonomy</h2>
<p>If the taxonomy of the ASVs differ on a taxonomic level other than species, we use an alternate
way of naming the OTU. The input <code>consensus_table</code> is a <code>pandas.DataFrame</code> object showing the
taxonomic classification of an OTU. You would get this table by running RDP on the consensus
sequence.</p>
<p>If the consensus table is not given, then we specify the lowest level that they agree. If the
consensus table is given, then we use the taxonomy specified in that table.</p>
<h2 id="examples">Examples</h2>
<pre><code>Input:
 kingdom          phylum                class        order             family  genus       species      asv
Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis  ASV_722
Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea            NA  ASV_991

Output:
 kingdom          phylum                class        order             family  genus       species
Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis
</code></pre>
<pre><code>Input:
 kingdom          phylum           class              order              family            genus                 species      asv
Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_283
Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_302
Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium    adolescentis/faecale  ASV_340
Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  choerinum/pseudolongum  ASV_668

Ouput:
 kingdom          phylum           class              order              family            genus                                      species
Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  adolescentis/faecale/choerinum/pseudolongum
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>consensus_table</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Table for resolving conflicts</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_consensus_taxonomy(self, consensus_table: pd.DataFrame=None):
    &#39;&#39;&#39;Set the taxonomy of the OTU to the consensus taxonomy of the.

    If one of the ASVs is defined at a lower level than another ASV, use
    that taxonomy. If ASVs&#39; taxonomies disagree at the species level, use the 
    union of all the species. 

    Disagreeing taxonomy
    --------------------
    If the taxonomy of the ASVs differ on a taxonomic level other than species, we use an alternate 
    way of naming the OTU. The input `consensus_table` is a `pandas.DataFrame` object showing the
    taxonomic classification of an OTU. You would get this table by running RDP on the consensus
    sequence.
    
    If the consensus table is not given, then we specify the lowest level that they agree. If the 
    consensus table is given, then we use the taxonomy specified in that table.

    Examples
    --------
    ```
    Input:
     kingdom          phylum                class        order             family  genus       species      asv
    Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis  ASV_722
    Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea            NA  ASV_991
    
    Output:
     kingdom          phylum                class        order             family  genus       species
    Bacteria  Proteobacteria  Alphaproteobacteria  Rhizobiales  Bradyrhizobiaceae  Bosea  massiliensis
    ```

    ```
    Input:
     kingdom          phylum           class              order              family            genus                 species      asv
    Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_283
    Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium                      NA  ASV_302
    Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium    adolescentis/faecale  ASV_340
    Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  choerinum/pseudolongum  ASV_668

    Ouput:
     kingdom          phylum           class              order              family            genus                                      species
    Bacteria  Actinobacteria  Actinobacteria  Bifidobacteriales  Bifidobacteriaceae  Bifidobacterium  adolescentis/faecale/choerinum/pseudolongum
    ```

    Parameters
    ----------
    consensus_table : pd.DataFrame
        Table for resolving conflicts
    &#39;&#39;&#39;
    # Check that all the taxonomies have the same lineage
    set_to_na = False
    set_from_table = False
    for tax in TAX_LEVELS:
        if set_to_na:
            self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
            continue
        if set_from_table:
            if tax not in consensus_table.columns:
                self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
            else:
                self.taxonomy[tax] = consensus_table[tax][self.name]
            continue
        if tax == &#39;asv&#39;:
            continue
        consensus = []
        for taxonname in self.aggregated_taxa:
            if tax == &#39;species&#39;:
                aaa = self.aggregated_taxonomies[taxonname][tax].split(&#39;/&#39;)
            else:
                aaa = [self.aggregated_taxonomies[taxonname][tax]]
            for bbb in aaa:
                if bbb in consensus:
                    continue
                else:
                    consensus.append(bbb)
        if DEFAULT_TAXLEVEL_NAME in consensus:
            consensus.remove(DEFAULT_TAXLEVEL_NAME)

        if len(consensus) == 0:
            # No taxonomy found at this level
            self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
        elif len(consensus) == 1:
            # All taxonomies agree
            self.taxonomy[tax] = consensus[0]
        else:
            # All taxonomies do not agree
            if tax == &#39;species&#39;:
                # Take the union of the species
                self.taxonomy[tax] = &#39;/&#39;.join(consensus)
            else:
                # This means that the taxonomy is different on a level different than
                logging.critical(&#39;{} taxonomy does not agree&#39;.format(self.name))
                logging.critical(str(self))
                for taxonname in self.aggregated_taxonomies:
                    logging.warning(&#39;{}&#39;.format(list(self.aggregated_taxonomies[taxonname].values())))

                if consensus_table is not None:
                    # Set from the table
                    self.taxonomy[tax] = consensus_table[tax][self.name]
                    set_from_table = True

                else:
                    # Set this taxonomic level and everything below it to NA
                    self.taxonomy[tax] = DEFAULT_TAXLEVEL_NAME
                    set_to_na = True</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.base.Taxon.get_lineage" href="#mdsine2.pylab.base.Taxon.get_lineage">get_lineage</a></code></li>
<li><code><a title="mdsine2.pylab.base.Taxon.get_taxonomy" href="#mdsine2.pylab.base.Taxon.get_taxonomy">get_taxonomy</a></code></li>
<li><code><a title="mdsine2.pylab.base.Taxon.set_taxonomy" href="#mdsine2.pylab.base.Taxon.set_taxonomy">set_taxonomy</a></code></li>
<li><code><a title="mdsine2.pylab.base.Taxon.tax_is_defined" href="#mdsine2.pylab.base.Taxon.tax_is_defined">tax_is_defined</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.pylab.base.Perturbations"><code class="flex name class">
<span>class <span class="ident">Perturbations</span></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregator for individual perturbation obejcts</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Perturbations:
    &#39;&#39;&#39;Aggregator for individual perturbation obejcts
    &#39;&#39;&#39;
    def __init__(self):
        self._d = {}
        self._rev_idx = []

    def __len__(self) -&gt; int:
        return len(self._d)

    def __getitem__(self, a: Union[BasePerturbation, int, str]) -&gt; BasePerturbation:
        &#39;&#39;&#39;Get the perturbation either by index, name, or object
        &#39;&#39;&#39;
        if isperturbation(a):
            if a.name in self:
                return a
            else:
                raise KeyError(&#39;`a` ({}) not contained in this Set&#39;.format(a))
        if plutil.isstr(a):
            return self._d[a]
        elif plutil.isint(a):
            return self._d[self._rev_idx[a]]
        else:
            raise KeyError(&#39;`a` {} ({}) not recognized&#39;.format(a, type(a)))

    def __contains__(self, a: Union[BasePerturbation, str, int]) -&gt; bool:
        try:
            _ = self[a]
            return True
        except:
            False

    def __iter__(self):
        for a in self._d:
            yield self._d[a]

    def append(self, a: BasePerturbation):
        &#39;&#39;&#39;Add a perturbation

        a : mdsine2.BasePertubration
            Perturbation to add
        &#39;&#39;&#39;
        if not isperturbation(a):
            raise TypeError(&#39;`a` ({}) must be a perturbation&#39;.format(type(a)))
        self._d[a.name] = a
        self._rev_idx.append(a.name)

    def remove(self, a: Union[BasePerturbation, str, int]):
        &#39;&#39;&#39;Remove the perturbation `a`. Can be either the name, index, or 
        the object itself.

        Parameters
        ----------
        a : str, int, mdsine2.BasePerturbation
            Perturbation to remove
        
        Returns
        -------
        mdsine2.BasePerturbation
        &#39;&#39;&#39;
        a = self[a]
        self._d.pop(a.name, None)
        self._rev_idx = []
        for mer in self._d:
            self._rev_idx.append(mer.name)
        return a</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Perturbations.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, a: <a title="mdsine2.pylab.base.BasePerturbation" href="#mdsine2.pylab.base.BasePerturbation">BasePerturbation</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a perturbation</p>
<p>a : mdsine2.BasePertubration
Perturbation to add</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append(self, a: BasePerturbation):
    &#39;&#39;&#39;Add a perturbation

    a : mdsine2.BasePertubration
        Perturbation to add
    &#39;&#39;&#39;
    if not isperturbation(a):
        raise TypeError(&#39;`a` ({}) must be a perturbation&#39;.format(type(a)))
    self._d[a.name] = a
    self._rev_idx.append(a.name)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Perturbations.remove"><code class="name flex">
<span>def <span class="ident">remove</span></span>(<span>self, a: Union[<a title="mdsine2.pylab.base.BasePerturbation" href="#mdsine2.pylab.base.BasePerturbation">BasePerturbation</a>, str, int])</span>
</code></dt>
<dd>
<div class="desc"><p>Remove the perturbation <code>a</code>. Can be either the name, index, or
the object itself.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>a</code></strong> :&ensp;<code>str, int, mdsine2.BasePerturbation</code></dt>
<dd>Perturbation to remove</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.BasePerturbation</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove(self, a: Union[BasePerturbation, str, int]):
    &#39;&#39;&#39;Remove the perturbation `a`. Can be either the name, index, or 
    the object itself.

    Parameters
    ----------
    a : str, int, mdsine2.BasePerturbation
        Perturbation to remove
    
    Returns
    -------
    mdsine2.BasePerturbation
    &#39;&#39;&#39;
    a = self[a]
    self._d.pop(a.name, None)
    self._rev_idx = []
    for mer in self._d:
        self._rev_idx.append(mer.name)
    return a</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.pylab.base.Saveable"><code class="flex name class">
<span>class <span class="ident">Saveable</span></span>
</code></dt>
<dd>
<div class="desc"><p>Implements baseline saving classes with pickle for classes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Saveable:
    &#39;&#39;&#39;Implements baseline saving classes with pickle for classes
    &#39;&#39;&#39;
    def save(self, filename: str=None):
        &#39;&#39;&#39;Pickle the object

        Paramters
        ---------
        filename : str
            This is the location to store the file. Overrides the location if
            it is set using `pylab.base.Saveable.set_save_location`. If None
            it means that we are using the file location set in 
            set_location. 
        &#39;&#39;&#39;
        if filename is None:
            if not hasattr(self, &#39;_save_loc&#39;):
                raise TypeError(&#39;`filename` must be specified if you have not &#39; \
                    &#39;set the save location&#39;)
            filename = self._save_loc
        
        try:
            with open(str(filename), &#39;wb&#39;) as output:  # Overwrites any existing file.
                pickle.dump(self, output, protocol=pickle.HIGHEST_PROTOCOL)
        except:
            os.system(&#39;rm {}&#39;.format(filename))
            with open(str(filename), &#39;wb&#39;) as output:  # Overwrites any existing file.
                pickle.dump(self, output, protocol=pickle.HIGHEST_PROTOCOL)

    @classmethod
    def load(cls, filename: str):
        &#39;&#39;&#39;Unpickle the object

        Paramters
        ---------
        cls : type
            Type
        filename : str
            This is the location of the file to unpickle
        &#39;&#39;&#39;
        with open(str(filename), &#39;rb&#39;) as handle:
            b = pickle.load(handle)
        
        # redo the filename to the new path if it has a save location
        if not hasattr(b, &#39;_save_loc&#39;):
            filename = os.path.abspath(filename)
            b._save_loc = filename

        return b

    def set_save_location(self, filename: str):
        &#39;&#39;&#39;Set the save location for the object.

        Internally converts this to the absolute path

        Parameters
        ----------
        filename : str
            This is the path to set it to
        &#39;&#39;&#39;
        if not plutil.isstr(filename):
            raise TypeError(&#39;`filename` ({}) must be a str&#39;.format(type(filename)))
        filename = os.path.abspath(filename)
        self._save_loc = filename

    def get_save_location(self) -&gt; str:
        try:
            return self._save_loc
        except:
            raise AttributeError(&#39;Save location is not set.&#39;)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.config.FilteringConfig" href="../config.html#mdsine2.config.FilteringConfig">FilteringConfig</a></li>
<li><a title="mdsine2.config.LoggingConfig" href="../config.html#mdsine2.config.LoggingConfig">LoggingConfig</a></li>
<li>mdsine2.config._BaseModelConfig</li>
<li><a title="mdsine2.pylab.base.Clusterable" href="#mdsine2.pylab.base.Clusterable">Clusterable</a></li>
<li><a title="mdsine2.pylab.base.Study" href="#mdsine2.pylab.base.Study">Study</a></li>
<li><a title="mdsine2.pylab.base.Subject" href="#mdsine2.pylab.base.Subject">Subject</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.graph.Graph" href="graph.html#mdsine2.pylab.graph.Graph">Graph</a></li>
<li><a title="mdsine2.pylab.inference.BaseModel" href="inference.html#mdsine2.pylab.inference.BaseModel">BaseModel</a></li>
<li><a title="mdsine2.pylab.inference.Tracer" href="inference.html#mdsine2.pylab.inference.Tracer">Tracer</a></li>
<li><a title="mdsine2.synthetic.Synthetic" href="../synthetic.html#mdsine2.synthetic.Synthetic">Synthetic</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Saveable.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>filename: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Unpickle the object</p>
<h2 id="paramters">Paramters</h2>
<p>cls : type
Type
filename : str
This is the location of the file to unpickle</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def load(cls, filename: str):
    &#39;&#39;&#39;Unpickle the object

    Paramters
    ---------
    cls : type
        Type
    filename : str
        This is the location of the file to unpickle
    &#39;&#39;&#39;
    with open(str(filename), &#39;rb&#39;) as handle:
        b = pickle.load(handle)
    
    # redo the filename to the new path if it has a save location
    if not hasattr(b, &#39;_save_loc&#39;):
        filename = os.path.abspath(filename)
        b._save_loc = filename

    return b</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Saveable.get_save_location"><code class="name flex">
<span>def <span class="ident">get_save_location</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_save_location(self) -&gt; str:
    try:
        return self._save_loc
    except:
        raise AttributeError(&#39;Save location is not set.&#39;)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Saveable.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Pickle the object</p>
<h2 id="paramters">Paramters</h2>
<p>filename : str
This is the location to store the file. Overrides the location if
it is set using <code>pylab.base.Saveable.set_save_location</code>. If None
it means that we are using the file location set in
set_location.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filename: str=None):
    &#39;&#39;&#39;Pickle the object

    Paramters
    ---------
    filename : str
        This is the location to store the file. Overrides the location if
        it is set using `pylab.base.Saveable.set_save_location`. If None
        it means that we are using the file location set in 
        set_location. 
    &#39;&#39;&#39;
    if filename is None:
        if not hasattr(self, &#39;_save_loc&#39;):
            raise TypeError(&#39;`filename` must be specified if you have not &#39; \
                &#39;set the save location&#39;)
        filename = self._save_loc
    
    try:
        with open(str(filename), &#39;wb&#39;) as output:  # Overwrites any existing file.
            pickle.dump(self, output, protocol=pickle.HIGHEST_PROTOCOL)
    except:
        os.system(&#39;rm {}&#39;.format(filename))
        with open(str(filename), &#39;wb&#39;) as output:  # Overwrites any existing file.
            pickle.dump(self, output, protocol=pickle.HIGHEST_PROTOCOL)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Saveable.set_save_location"><code class="name flex">
<span>def <span class="ident">set_save_location</span></span>(<span>self, filename: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the save location for the object.</p>
<p>Internally converts this to the absolute path</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the path to set it to</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_save_location(self, filename: str):
    &#39;&#39;&#39;Set the save location for the object.

    Internally converts this to the absolute path

    Parameters
    ----------
    filename : str
        This is the path to set it to
    &#39;&#39;&#39;
    if not plutil.isstr(filename):
        raise TypeError(&#39;`filename` ({}) must be a str&#39;.format(type(filename)))
    filename = os.path.abspath(filename)
    self._save_loc = filename</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.pylab.base.Study"><code class="flex name class">
<span>class <span class="ident">Study</span></span>
<span>(</span><span>taxa: <a title="mdsine2.pylab.base.TaxaSet" href="#mdsine2.pylab.base.TaxaSet">TaxaSet</a>, name: str = 'unnamed-study')</span>
</code></dt>
<dd>
<div class="desc"><p>Holds data for all the subjects</p>
<h2 id="paramters">Paramters</h2>
<p>taxa : TaxaSet, Optional
Contains all of the s</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Study(Saveable):
    &#39;&#39;&#39;Holds data for all the subjects

    Paramters
    ---------
    taxa : TaxaSet, Optional
        Contains all of the s
    &#39;&#39;&#39;
    def __init__(self, taxa: TaxaSet, name: str=&#39;unnamed-study&#39;):
        self.name = name
        self.id = id(self)
        self._subjects = {}
        self.perturbations = None
        self.qpcr_normalization_factor = None
        if not istaxaset(taxa):
            raise ValueError(&#39;If `taxa` ({}) is specified, it must be an TaxaSet&#39; \
                &#39; type&#39;.format(type(taxa)))
        self.taxa = taxa

        self._samples = {}
        
    def __getitem__(self, key: Union[str, int, Subject]) -&gt; Subject:
        return self._subjects[key]

    def __len__(self) -&gt; int:
        return len(self._subjects)

    def __iter__(self) -&gt; Subject:
        for v in self._subjects.values():
            yield v

    def __contains__(self, key: Union[str, int, Subject]) -&gt; bool:
        return key in self._subjects

    def parse(self, metadata: pd.DataFrame, reads: pd.DataFrame=None, qpcr: pd.DataFrame=None, 
        perturbations: pd.DataFrame=None):
        &#39;&#39;&#39;Parse tables of samples and cast in Subject sets. Automatically creates
        the subject classes with the respective names.

        Parameters
        ----------
        metadata : pandas.DataFrame
            Contains the meta data for each one of the samples
            Columns:
                &#39;sampleID&#39; -&gt; str : This is the name of the sample
                &#39;subject&#39; -&gt; str : This is the name of the subject
                &#39;time&#39; -&gt; float : This is the time the sample takes place
                &#39;perturbation:`name`&#39; -&gt; int : This is a perturbation meta data where the
                    name of the perturbation is `name`
        reads : pandas.DataFrame, None
            Contains the reads for each one of the samples and taxa
                index (str) : indexes the taxon name
                columns (str) : indexes the sample ID
            If nothing is passed in, the reads are set to None
        qpcr : pandas.DataFrame, None
            Contains the qpcr measurements for each sample
                index (str) : indexes the sample ID
                columns (str) : Name is ignored. the values are set to the measurements
        perturbations : pandas.DataFrame, None
            Contains the times and subjects for each perturbation
            columns:
                &#39;name&#39; -&gt; str : Name of the perturbation
                &#39;start&#39; -&gt; float : This is the start time for the perturbation
                &#39;end&#39; -&gt; float : This is the end time for the perturbation
                &#39;subject&#39; -&gt; str : This is the subject name the perturbation is applied to
        &#39;&#39;&#39;
        if not plutil.isdataframe(metadata):
            raise TypeError(&#39;`metadata` ({}) must be a pandas.DataFrame&#39;.format(type(metadata)))
        
        # Add the samples
        # ---------------
        if &#39;sampleID&#39; in metadata.columns:
            metadata = metadata.set_index(&#39;sampleID&#39;)
        for sampleid in metadata.index:

            sid = str(metadata[&#39;subject&#39;][sampleid])
            t = float(metadata[&#39;time&#39;][sampleid])

            if sid not in self:
                self.add_subject(name=sid)
            if t not in self[sid].times:
                self[sid].add_time(timepoint=t)

            self._samples[str(sampleid)] = (sid,t)

        # Add the perturbations if there are any
        # --------------------------------------
        if perturbations is not None:
            logging.warning(&#39;Reseting perturbations&#39;)
            self.perturbations = Perturbations()
            if not plutil.isdataframe(perturbations):
                raise TypeError(&#39;`metadata` ({}) must be a pandas.DataFrame&#39;.format(type(metadata)))
            try:
                for pidx in perturbations.index:
                    pname = perturbations[&#39;name&#39;][pidx]
                    subj = str(perturbations[&#39;subject&#39;][pidx])

                    if pname not in self.perturbations:
                        # Create a new one
                        pert = BasePerturbation(
                            name=pname, 
                            starts={subj: perturbations[&#39;start&#39;][pidx]},
                            ends={subj: perturbations[&#39;end&#39;][pidx]})
                        self.perturbations.append(pert)
                    else:
                        # Add this subject name to the pertubration
                        self.perturbations[pname].starts[subj] = perturbations[&#39;start&#39;][pidx]
                        self.perturbations[pname].ends[subj] = perturbations[&#39;end&#39;][pidx]
            except KeyError as e:
                logging.critical(e)
                raise KeyError(&#39;Make sure that `subject`, `start`, and `end` are columns&#39;)

        # Add the reads if necessary
        # --------------------------
        if reads is not None:
            if not plutil.isdataframe(reads):
                raise TypeError(&#39;`reads` ({}) must be a pandas.DataFrame&#39;.format(type(reads)))
            
            if &#39;name&#39; in reads.columns:
                reads = reads.set_index(&#39;name&#39;)

            for sampleid in reads.columns:
                if sampleid not in self._samples:
                    raise ValueError(&#39;sample {} not contained in metadata. abort&#39;.format(sampleid))
                sid, t = self._samples[sampleid]
                self[sid].add_reads(timepoints=t, reads=reads[sampleid].to_numpy())

        # Add the qPCR measurements if necessary
        # --------------------------------------
        if qpcr is not None:
            if not plutil.isdataframe(qpcr):
                raise TypeError(&#39;`qpcr` ({}) must be a pandas.DataFrame&#39;.format(type(qpcr)))
            if &#39;sampleID&#39; in qpcr.columns:
                qpcr = qpcr.set_index(&#39;sampleID&#39;)

            for sampleid in qpcr.index:
                try:
                    sid, t = self._samples[sampleid]
                except:
                    raise ValueError(&#39;Sample ID `{}` not found in metadata ({}). Make sure &#39; \
                        &#39;you set the sample ID as the index in the `qpcr` dataframe&#39;.format(
                            sampleid, list(self._samples.keys())))
                cfuspergram = qpcr.loc[sampleid].to_numpy()
                self[sid].add_qpcr(timepoints=t, qpcr=cfuspergram)
        return self
            
    def write_metadata_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the internal metadata to a table. If a path is provided
        then write it to that path.

        Parameters
        ----------
        path : str, None
            This is the location to save the metadata file
            If this is not provided then just return the dataframe
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        columns = [&#39;sampleID&#39;, &#39;subject&#39;, &#39;time&#39;]
        data = []
        for sampleid in self._samples:
            sid, t = self._samples[sampleid]
            if t not in self[sid].times:
                continue
            data.append([sampleid, sid, t])
        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def write_reads_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the reads to a table. If a path is provided then
        we write to that path

        Parameters
        ----------
        path : str
            This is the location to save the reads file
            If this is not provided then just return the dataframe
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        data = [[taxon.name for taxon in self.taxa]]
        index = [&#39;name&#39;]
        for sampleid in self._samples:
            sid, t = self._samples[sampleid]
            if t not in self[sid].times:
                continue

            index.append(sampleid)
            reads = self[sid].reads[t]
            data.append(reads)

        df = pd.DataFrame(data, index=index).T
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def write_qpcr_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the qPCR measurements to a table. If a path is provided then
        we write to that path

        Parameters
        ----------
        path : str
            This is the location to save the qPCR file
            If this is not provided then we do not save
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        max_n_measurements = -1
        data = []
        for sampleid in self._samples:
            sid, t = self._samples[sampleid]
            if t not in self[sid].times:
                continue
            subj = self[sid]
            ms = subj.qpcr[t].data
            if len(ms) &gt; max_n_measurements:
                max_n_measurements = len(ms)
            ms = [sampleid] + ms.tolist()
            data.append(ms)
        
        for i, ms in enumerate(data):
            if len(ms)-1 &lt; max_n_measurements:
                data[i] = np.append(
                    ms, 
                    np.nan * np.ones(max_n_measurements - len(ms)))
        
        columns = [&#39;sampleID&#39;] + [&#39;measurement{}&#39;.format(i+1) for i in range(max_n_measurements)]

        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def write_perturbations_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the perturbations to a table. If a path is provided then
        we write to that path

        Parameters
        ----------
        path : str
            This is the location to save the perturbations file
            If this is not provided then we do not save
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        columns = [&#39;name&#39;, &#39;start&#39;, &#39;end&#39;, &#39;subject&#39;]
        data = []
        for perturbation in self.perturbations:
            for subjname in perturbation.starts:
                data.append([
                    perturbation.name, 
                    perturbation.starts[subjname],
                    perturbation.ends[subjname],
                    subjname])

        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df

    def names(self) -&gt; Iterator[str]:
        &#39;&#39;&#39;List the names of the contained subjects

        Returns
        -------
        list(str)
            List of names of the subjects in order
        &#39;&#39;&#39;
        return [subj.name for subj in self]

    def iloc(self, idx: int) -&gt; Subject:
        &#39;&#39;&#39;Get the subject as an index

        Parameters
        ----------
        idx : int
            Index of the subject

        Returns
        -------
        pl.base.Subject
        &#39;&#39;&#39;
        for i,sid in enumerate(self._subjects):
            if i == idx:
                return self._subjects[sid]
        raise IndexError(&#39;Index ({}) not found&#39;.format(idx))

    def add_subject(self, name: str):
        &#39;&#39;&#39;Create a subject with the name `name`

        Parameters
        ----------
        name : str
            This is the name of the new subject
        &#39;&#39;&#39;
        if name not in self._subjects:
            self._subjects[name] = Subject(name=name, parent=self)
        return self

    def pop_subject(self, sid: Union[int, str, Iterator[str]], 
        name: str=&#39;unnamed-study&#39;) -&gt; &#39;Study&#39;:
        &#39;&#39;&#39;Remove the indicated subject id

        Parameters
        ----------
        sid : list(str), str, int
            This is the subject name/s or the index/es to pop out.
            Return a new Study with the specified subjects removed.
        name : str
            Name of the new study to return
        &#39;&#39;&#39;
        if not plutil.isarray(sid):
            sids = [sid]
        else:
            sids = sid

        for i in range(len(sids)):
            if plutil.isint(sids[i]):
                sids[i] = list(self._subjects.keys())[sids[i]]
            elif not plutil.isstr(sids[i]):
                raise ValueError(&#39;`sid` ({}) must be a str&#39;.format(type(sids[i])))
        ret = Study(taxa=self.taxa, name=name)
        ret.qpcr_normalization_factor = self.qpcr_normalization_factor

        for s in sids:
            if s in self._subjects:
                ret._subjects[s] =  self._subjects.pop(s, None)
                ret._subjects[s].parent = ret
            else:
                raise ValueError(&#39;`sid` ({}) not found&#39;.format(sid))

        ret.perturbations = copy.deepcopy(self.perturbations)

        # Remove the names of the subjects in the perturbations
        for study in [ret, self]:
            for perturbation in study.perturbations:
                names = list(perturbation.starts.keys())
                for subjname in names:
                    if subjname not in study:
                        perturbation.starts.pop(subjname, None)
                names = list(perturbation.ends.keys())
                for subjname in names:
                    if subjname not in study:
                        perturbation.ends.pop(subjname, None)

        return ret

    def pop_taxa_like(self, study: &#39;Study&#39;):
        &#39;&#39;&#39;Remove s in the TaxaSet so that it matches the TaxaSet in `study`

        Parameters
        ----------
        study : mdsine2.study
            This is the study object we are mirroring in terms of taxa
        &#39;&#39;&#39;
        to_delete = []
        for taxon in self.taxa:
            if taxon.name not in study.taxa:
                to_delete.append(taxon.name)
        self.pop_taxa(to_delete)

    def pop_taxa(self, oids: Union[str, int, Iterator[str], Iterator[int]]):
        &#39;&#39;&#39;Delete the taxa indicated in oidxs. Updates the reads table and
        the internal TaxaSet

        Parameters
        ----------
        oids : str, int, list(str/int)
            These are the identifiers for each of the taxon/taxa to delete
        &#39;&#39;&#39;
        # get indices
        oidxs = []
        for oid in oids:
            oidxs.append(self.taxa[oid].idx)
        
        # Delete the s from taxaset
        for oid in oids:
            self.taxa.del_taxon(oid)

        # Delete the reads
        for subj in self:
            for t in subj.reads:
                subj.reads[t] = np.delete(subj.reads[t], oidxs)
        return self

    def deaggregate_item(self, agg: OTU, other: str) -&gt; Taxon:
        &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
        `other` is then appended to the end 

        Parameters
        ----------
        agg : OTU, str
            This is an OTU with multiple sequences contained. Must 
            have the name `other` in there
        other : str
            This is the name of the taxon that should be taken out of `agg`

        Returns
        -------
        mdsine2.Taxon
            This is the deaggregated taxon
        &#39;&#39;&#39;
        agg = self.taxa[agg]
        if not isotu(agg):
            raise TypeError(&#39;`agg` ({}) must be an OTU&#39;.format(type(agg)))
        if not plutil.isstr(other):
            raise TypeError(&#39;`other` ({}) must be a str&#39;.format(type(other)))
        if other not in agg.aggregated_taxa:
            raise ValueError(&#39;`other` ({}) is not contained in `agg` ({}) ({})&#39;.format(
                other, agg.name, agg.aggregated_taxa))

        for subj in self:
            subj._deaggregate_item(agg=agg, other=other)
        return self.taxa.deaggregate_item(agg, other)

    def aggregate_items_like(self, study: &#39;Study&#39;, prefix: str=None):
        &#39;&#39;&#39;Aggregate s like they are in study `study`

        Parameters
        ----------
        study : mdsine2.Study
            Data object we are mirroring
        prefix : str
            If provided, this is how you rename the Taxas after aggregation
        &#39;&#39;&#39;
        for taxon in study.taxa:
            if isotu(taxon):
                aname = taxon.aggregated_taxa[0]
                for bname in taxon.aggregated_taxa[1:]:
                    self.aggregate_items(aname, bname)
        if prefix is not None:
            self.taxa.rename(prefix=prefix)

    def aggregate_items(self, taxon1: Union[str, int, Taxon, OTU], 
        taxon2: Union[str, int, Taxon, OTU]) -&gt; OTU:
        &#39;&#39;&#39;Aggregates the abundances of `taxon1` and `taxon2`. Updates the reads table and
        internal TaxaSet

        Parameters
        ----------
        taxon1, taxon2 : str, int, mdsine2.Taxon, mdsine2.OTU
            These are the taxa you are agglomerating together

        Returns
        -------
        mdsine2.OTU
            This is the new aggregated taxon containing anchor and other
        &#39;&#39;&#39;
        # Find the anchor - use the highest index
        aidx1 = self.taxa[taxon1].idx
        aidx2 = self.taxa[taxon2].idx

        if aidx1 == aidx2:
            raise ValueError(&#39;Cannot aggregate the same taxa: {}&#39;.format(self.taxa[taxon1]))
        elif aidx1 &lt; aidx2:
            anchor = self.taxa[taxon1]
            other = self.taxa[taxon2]
        else:
            anchor = self.taxa[taxon2]
            other = self.taxa[taxon1]

        for subj in self:
            subj._aggregate_items(anchor=anchor, other=other)
        return self.taxa.aggregate_items(anchor=anchor, other=other)

    def pop_times(self, times: Union[int, float, np.ndarray], sids: Union[str, int, Iterator[int]]=&#39;all&#39;):
        &#39;&#39;&#39;Discard the times in `times` for the subjects listed in `sids`.
        If a timepoint is not found in a subject, no error is thrown.

        Parameters
        ----------
        times : numeric, list(numeric)
            Time/s to delete
        sids : str, int, list(int)
            The Subject ID or a list of subject IDs that you want to delete the timepoints
            from. If it is a str:
                &#39;all&#39; - delete from all subjects
        &#39;&#39;&#39;
        if plutil.isstr(sids):
            if sids == &#39;all&#39;:
                sids = list(self._subjects.keys())
            else:
                raise ValueError(&#39;`sids` ({}) not recognized&#39;.format(sids))
        elif plutil.isint(sids):
            if sids not in self._subjects:
                raise IndexError(&#39;`sid` ({}) not found in subjects&#39;.format(
                    list(self._subjects.keys())))
            sids = [sids]
        elif plutil.isarray(sids):
            for sid in sids:
                if not plutil.isint(sid):
                    raise TypeError(&#39;Each sid ({}) must be an int&#39;.format(type(sid)))
                if sid not in self._subjects:
                    raise IndexError(&#39;Subject {} not found in subjects ({})&#39;.format(
                        sid, list(self._subjects.keys())))
        else:
            raise TypeError(&#39;`sids` ({}) type not recognized&#39;.format(type(sids)))
        if plutil.isnumeric(times):
            times = [times]
        elif plutil.isarray(times):
            for t in times:
                if not plutil.isnumeric(t):
                    raise TypeError(&#39;Each time ({}) must be a numeric&#39;.format(type(t)))
        else:
            raise TypeError(&#39;`times` ({}) type not recognized&#39;.format(type(times)))

        for t in times:
            for sid in sids:
                subj = self._subjects[sid]
                if t in subj.times:
                    subj.qpcr.pop(t, None)
                    subj.reads.pop(t,None)
                    subj.times = np.sort(list(subj.reads.keys()))

    def normalize_qpcr(self, max_value: float):
        &#39;&#39;&#39;Normalize the qPCR values such that the largest value is the max value
        over all the subjects

        Parameters
        ----------
        max_value : float, int
            This is the maximum qPCR value to

        Returns
        -------
        self
        &#39;&#39;&#39;
        if type(max_value) not in [int, float]:
            raise ValueError(&#39;max_value ({}) must either be an int or a float&#39;.format(
                type(max_value)))

        if self.qpcr_normalization_factor is not None:
            logging.warning(&#39;qPCR is already rescaled. unscaling and rescaling&#39;)
            self.denormalize_qpcr()

        temp_max = -1
        for subj in self:
            for key in subj.qpcr:
                temp_max = np.max([temp_max, subj.qpcr[key].mean()])

        self.qpcr_normalization_factor = max_value/temp_max
        logging.info(&#39;max_value found: {}, scaling_factor: {}&#39;.format(
            temp_max, self.qpcr_normalization_factor))

        for subj in self:
            for key in subj.qpcr:
                subj.qpcr[key].set_scaling_factor(scaling_factor=
                    self.qpcr_normalization_factor)
        return self

    def denormalize_qpcr(self):
        &#39;&#39;&#39;Denormalizes the qpcr values if necessary

        Returns
        -------
        self
        &#39;&#39;&#39;
        if self.qpcr_normalization_factor is None:
            logging.warning(&#39;qPCR is not normalized. Doing nothing&#39;)
            return
        for subj in self:
            for key in subj.qpcr:
                subj.qpcr[key].set_scaling_factor(scaling_factor=1)
        self.qpcr_normalization_factor = None
        return self

    def add_perturbation(self, a: Union[Dict[str, float], BasePerturbation], ends: Dict[str, float]=None, 
        name: str=None):
        &#39;&#39;&#39;Add a perturbation. 
        
        We can either do this by passing a perturbation object 
        (if we do this then we do not need to specify `ends`) or we can 
        specify the start and stop times (if we do this them we need to
        specify `ends`).

        `starts` and `ends`
        -------------------
        If `a` is a dict, this corresponds to the start times for each subject in the
        perturbation. Each dict maps the name of the subject to the timepoint that it
        either starts or ends, respectively.

        Parameters
        ----------
        a : dict, BasePerturbation
            If this is a dict, then this corresponds to the starts
            times of the perturbation for each subject. If this is a Pertubration object
            then we just add this.
        ends : dict
            Only necessary if `a` is a dict
        name : str, None
            Only necessary if `a` is a dict. Name of the perturbation
        
        Returns
        -------
        self
        &#39;&#39;&#39;
        if self.perturbations is None:
            self.perturbations = Perturbations()
        if plutil.isdict(a):
            if not plutil.isdict(ends):
                raise ValueError(&#39;If `a` is a dict, then `ends` ({}) &#39; \
                    &#39;needs to be a dict&#39;.format(type(ends)))
            if not plutil.isstr(name):
                raise ValueError(&#39;`name` ({}) must be defined as a str&#39;.format(type(name)))
            self.perturbations.append(BasePerturbation(starts=a, ends=ends, name=name))
        elif isperturbation(a):
            self.perturbations.append(a)
        else:
            raise ValueError(&#39;`a` ({}) must be a subclass of &#39; \
                &#39;pl.base.BasePerturbation or a dict&#39;.format(type(a)))
        return self
        
    def split_on_perturbations(self):
        &#39;&#39;&#39;Make new subjects for the time points that are divided by perturbations. 
        Throw out all of the data  where the perturbations are active.

        Returns
        -------
        self
        &#39;&#39;&#39;
        for subj in self:
            subj._split_on_perturbations()
        return self

    def times(self, agg: str) -&gt; np.ndarray:
        &#39;&#39;&#39;Aggregate the times of all the contained subjects

        These are the types of time aggregations:
            &#39;union&#39;: Take  theunion of the times of the subjects
            &#39;intersection&#39;: Take the intersection of the times of the subjects
        You can manually specify the times to include with a list of times. If times are not
        included in any of the subjects then we set them to NAN.

        Parameters
        ----------
        agg : str
            Type of aggregation to do of the times. Options: &#39;union&#39;, &#39;intersection&#39;
        &#39;&#39;&#39;
        if agg not in [&#39;union&#39;, &#39;intersection&#39;]:
            raise ValueError(&#39;`agg` ({}) not recognized&#39;.format(agg))

        all_times = []
        for subj in self:
            all_times = np.append(all_times, subj.times)
        all_times = np.sort(np.unique(all_times))
        if agg == &#39;union&#39;:
            times = all_times

        elif agg == &#39;intersection&#39;:
            times = []
            for t in all_times:
                addin = True
                for subj in self:
                    if t not in subj.times:
                        addin = False
                        break
                if addin:
                    times = np.append(times, t)
        else:
            raise ValueError(&#39;`times` ({}) not recognized&#39;.format(times))
        return times

    def _matrix(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; Tuple[np.ndarray, np.ndarray]:
        if dtype not in [&#39;raw&#39;, &#39;rel&#39;, &#39;abs&#39;]:
            raise ValueError(&#39;`dtype` ({}) not recognized&#39;.format(dtype))
        
        if agg == &#39;mean&#39;:
            aggfunc = np.nanmean
        elif agg == &#39;median&#39;:
            aggfunc = np.nanmedian
        elif agg == &#39;sum&#39;:
            aggfunc = np.nansum
        elif agg == &#39;max&#39;:
            aggfunc = np.nanmax
        elif agg == &#39;min&#39;:
            aggfunc = np.nanmin
        else:
            raise ValueError(&#39;`agg` ({}) not recognized&#39;.format(agg))

        if plutil.isstr(times):
            times = self.times(agg=times)
        elif plutil.isarray(times):
            times = np.array(times)
        else:
            raise TypeError(&#39;`times` type ({}) not recognized&#39;.format(type(times)))

        shape = (len(self.taxa), len(times))
        M = np.zeros(shape, dtype=float)
        for tidx, t in enumerate(times):
            temp = None
            for subj in self:
                if t not in subj.times:
                    continue
                if dtype == &#39;raw&#39;:
                    a = subj.reads[t]
                elif dtype == &#39;rel&#39;:
                    a = subj.reads[t]/np.sum(subj.reads[t])
                else:
                    rel = subj.reads[t]/np.sum(subj.reads[t])
                    a = rel * subj.qpcr[t].mean()
                if temp is None:
                    temp = (a.reshape(-1,1), )
                else:
                    temp = temp + (a.reshape(-1,1), )
            if temp is None:
                temp = np.zeros(len(self.taxa)) * np.nan
            else:
                temp = np.hstack(temp)
                temp = aggfunc(temp, axis=1)
            M[:, tidx] = temp

        return M, times

    def matrix(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; np.ndarray:
        &#39;&#39;&#39;Make a matrix of the aggregation of all the subjects in the subjectset

        Aggregation of subjects
        -----------------------
        What are the values for the taxa? Set the aggregation type using the parameter `agg`. 
        These are the types of aggregations:
            &#39;mean&#39;: Mean abundance of the taxon at a timepoint over all the subjects
            &#39;median&#39;: Median abundance of the taxon at a timepoint over all the subjects
            &#39;sum&#39;: Sum of all the abundances of the taxon at a timepoint over all the subjects
            &#39;max&#39;: Maximum abundance of the taxon at a timepoint over all the subjects
            &#39;min&#39;: Minimum abundance of the taxon at a timepoint over all the subjects

        Aggregation of times
        --------------------
        Which times to include? Set the times to include with the parameter `times`.
        These are the types of time aggregations:
            &#39;union&#39;: Take  theunion of the times of the subjects
            &#39;intersection&#39;: Take the intersection of the times of the subjects
        You can manually specify the times to include with a list of times. If times are not
        included in any of the subjects then we set them to NAN.

        Parameters
        ----------
        dtype : str
            What kind of data to return. Options:
                &#39;raw&#39;: Count data
                &#39;rel&#39;: Relative abundance
                &#39;abs&#39;: Abundance data
        agg : str
            Type of aggregation of the values. Options specified above.
        times : str, array
            The times to include
        
        Returns
        -------
        np.ndarray(n_taxa, n_times)
        &#39;&#39;&#39;
        M, _ =  self._matrix(dtype=dtype, agg=agg, times=times)
        return M

    def df(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Returns a dataframe of the data in matrix. Rows are taxa, columns are times.

        Parameters
        ----------
        dtype : str
            What kind of data to return. Options:
                &#39;raw&#39;: Count data
                &#39;rel&#39;: Relative abundance
                &#39;abs&#39;: Abundance data
        agg : str
            Type of aggregation of the values. Options specified above.
        times : str, array
            The times to include

        Returns
        -------
        pandas.DataFrame

        See Also
        --------
        mdsine2.Study.matrix
        &#39;&#39;&#39;
        M, times = self._matrix(dtype=dtype, agg=agg, times=times)
        index = [taxon.name for taxon in self.taxa]
        return pd.DataFrame(data=M, index=index, columns=times)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Study.add_perturbation"><code class="name flex">
<span>def <span class="ident">add_perturbation</span></span>(<span>self, a: Union[Dict[str, float], <a title="mdsine2.pylab.base.BasePerturbation" href="#mdsine2.pylab.base.BasePerturbation">BasePerturbation</a>], ends: Dict[str, float] = None, name: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a perturbation. </p>
<p>We can either do this by passing a perturbation object
(if we do this then we do not need to specify <code>ends</code>) or we can
specify the start and stop times (if we do this them we need to
specify <code>ends</code>).</p>
<h2 id="starts-and-ends"><code>starts</code> and <code>ends</code></h2>
<p>If <code>a</code> is a dict, this corresponds to the start times for each subject in the
perturbation. Each dict maps the name of the subject to the timepoint that it
either starts or ends, respectively.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>a</code></strong> :&ensp;<code>dict, <a title="mdsine2.pylab.base.BasePerturbation" href="#mdsine2.pylab.base.BasePerturbation">BasePerturbation</a></code></dt>
<dd>If this is a dict, then this corresponds to the starts
times of the perturbation for each subject. If this is a Pertubration object
then we just add this.</dd>
<dt><strong><code>ends</code></strong> :&ensp;<code>dict</code></dt>
<dd>Only necessary if <code>a</code> is a dict</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str, None</code></dt>
<dd>Only necessary if <code>a</code> is a dict. Name of the perturbation</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_perturbation(self, a: Union[Dict[str, float], BasePerturbation], ends: Dict[str, float]=None, 
    name: str=None):
    &#39;&#39;&#39;Add a perturbation. 
    
    We can either do this by passing a perturbation object 
    (if we do this then we do not need to specify `ends`) or we can 
    specify the start and stop times (if we do this them we need to
    specify `ends`).

    `starts` and `ends`
    -------------------
    If `a` is a dict, this corresponds to the start times for each subject in the
    perturbation. Each dict maps the name of the subject to the timepoint that it
    either starts or ends, respectively.

    Parameters
    ----------
    a : dict, BasePerturbation
        If this is a dict, then this corresponds to the starts
        times of the perturbation for each subject. If this is a Pertubration object
        then we just add this.
    ends : dict
        Only necessary if `a` is a dict
    name : str, None
        Only necessary if `a` is a dict. Name of the perturbation
    
    Returns
    -------
    self
    &#39;&#39;&#39;
    if self.perturbations is None:
        self.perturbations = Perturbations()
    if plutil.isdict(a):
        if not plutil.isdict(ends):
            raise ValueError(&#39;If `a` is a dict, then `ends` ({}) &#39; \
                &#39;needs to be a dict&#39;.format(type(ends)))
        if not plutil.isstr(name):
            raise ValueError(&#39;`name` ({}) must be defined as a str&#39;.format(type(name)))
        self.perturbations.append(BasePerturbation(starts=a, ends=ends, name=name))
    elif isperturbation(a):
        self.perturbations.append(a)
    else:
        raise ValueError(&#39;`a` ({}) must be a subclass of &#39; \
            &#39;pl.base.BasePerturbation or a dict&#39;.format(type(a)))
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.add_subject"><code class="name flex">
<span>def <span class="ident">add_subject</span></span>(<span>self, name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a subject with the name <code>name</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the name of the new subject</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_subject(self, name: str):
    &#39;&#39;&#39;Create a subject with the name `name`

    Parameters
    ----------
    name : str
        This is the name of the new subject
    &#39;&#39;&#39;
    if name not in self._subjects:
        self._subjects[name] = Subject(name=name, parent=self)
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.aggregate_items"><code class="name flex">
<span>def <span class="ident">aggregate_items</span></span>(<span>self, taxon1: Union[str, int, <a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>], taxon2: Union[str, int, <a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>]) ‑> <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregates the abundances of <code>taxon1</code> and <code>taxon2</code>. Updates the reads table and
internal TaxaSet</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>taxon1</code></strong>, <strong><code>taxon2</code></strong> :&ensp;<code>str, int, mdsine2.Taxon, mdsine2.OTU</code></dt>
<dd>These are the taxa you are agglomerating together</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.OTU</code></dt>
<dd>This is the new aggregated taxon containing anchor and other</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_items(self, taxon1: Union[str, int, Taxon, OTU], 
    taxon2: Union[str, int, Taxon, OTU]) -&gt; OTU:
    &#39;&#39;&#39;Aggregates the abundances of `taxon1` and `taxon2`. Updates the reads table and
    internal TaxaSet

    Parameters
    ----------
    taxon1, taxon2 : str, int, mdsine2.Taxon, mdsine2.OTU
        These are the taxa you are agglomerating together

    Returns
    -------
    mdsine2.OTU
        This is the new aggregated taxon containing anchor and other
    &#39;&#39;&#39;
    # Find the anchor - use the highest index
    aidx1 = self.taxa[taxon1].idx
    aidx2 = self.taxa[taxon2].idx

    if aidx1 == aidx2:
        raise ValueError(&#39;Cannot aggregate the same taxa: {}&#39;.format(self.taxa[taxon1]))
    elif aidx1 &lt; aidx2:
        anchor = self.taxa[taxon1]
        other = self.taxa[taxon2]
    else:
        anchor = self.taxa[taxon2]
        other = self.taxa[taxon1]

    for subj in self:
        subj._aggregate_items(anchor=anchor, other=other)
    return self.taxa.aggregate_items(anchor=anchor, other=other)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.aggregate_items_like"><code class="name flex">
<span>def <span class="ident">aggregate_items_like</span></span>(<span>self, study: <a title="mdsine2.pylab.base.Study" href="#mdsine2.pylab.base.Study">Study</a>, prefix: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate s like they are in study <code>study</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>study</code></strong> :&ensp;<code>mdsine2.Study</code></dt>
<dd>Data object we are mirroring</dd>
<dt><strong><code>prefix</code></strong> :&ensp;<code>str</code></dt>
<dd>If provided, this is how you rename the Taxas after aggregation</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_items_like(self, study: &#39;Study&#39;, prefix: str=None):
    &#39;&#39;&#39;Aggregate s like they are in study `study`

    Parameters
    ----------
    study : mdsine2.Study
        Data object we are mirroring
    prefix : str
        If provided, this is how you rename the Taxas after aggregation
    &#39;&#39;&#39;
    for taxon in study.taxa:
        if isotu(taxon):
            aname = taxon.aggregated_taxa[0]
            for bname in taxon.aggregated_taxa[1:]:
                self.aggregate_items(aname, bname)
    if prefix is not None:
        self.taxa.rename(prefix=prefix)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.deaggregate_item"><code class="name flex">
<span>def <span class="ident">deaggregate_item</span></span>(<span>self, agg: <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, other: str) ‑> <a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a></span>
</code></dt>
<dd>
<div class="desc"><p>Deaggregate the sequence <code>other</code> from OTU <code>agg</code>.
<code>other</code> is then appended to the end </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>agg</code></strong> :&ensp;<code><a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str</code></dt>
<dd>This is an OTU with multiple sequences contained. Must
have the name <code>other</code> in there</dd>
<dt><strong><code>other</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the name of the taxon that should be taken out of <code>agg</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.Taxon</code></dt>
<dd>This is the deaggregated taxon</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deaggregate_item(self, agg: OTU, other: str) -&gt; Taxon:
    &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
    `other` is then appended to the end 

    Parameters
    ----------
    agg : OTU, str
        This is an OTU with multiple sequences contained. Must 
        have the name `other` in there
    other : str
        This is the name of the taxon that should be taken out of `agg`

    Returns
    -------
    mdsine2.Taxon
        This is the deaggregated taxon
    &#39;&#39;&#39;
    agg = self.taxa[agg]
    if not isotu(agg):
        raise TypeError(&#39;`agg` ({}) must be an OTU&#39;.format(type(agg)))
    if not plutil.isstr(other):
        raise TypeError(&#39;`other` ({}) must be a str&#39;.format(type(other)))
    if other not in agg.aggregated_taxa:
        raise ValueError(&#39;`other` ({}) is not contained in `agg` ({}) ({})&#39;.format(
            other, agg.name, agg.aggregated_taxa))

    for subj in self:
        subj._deaggregate_item(agg=agg, other=other)
    return self.taxa.deaggregate_item(agg, other)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.denormalize_qpcr"><code class="name flex">
<span>def <span class="ident">denormalize_qpcr</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Denormalizes the qpcr values if necessary</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def denormalize_qpcr(self):
    &#39;&#39;&#39;Denormalizes the qpcr values if necessary

    Returns
    -------
    self
    &#39;&#39;&#39;
    if self.qpcr_normalization_factor is None:
        logging.warning(&#39;qPCR is not normalized. Doing nothing&#39;)
        return
    for subj in self:
        for key in subj.qpcr:
            subj.qpcr[key].set_scaling_factor(scaling_factor=1)
    self.qpcr_normalization_factor = None
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.df"><code class="name flex">
<span>def <span class="ident">df</span></span>(<span>self, dtype: str, agg: str, times: Union[str, numpy.ndarray]) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a dataframe of the data in matrix. Rows are taxa, columns are times.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>What kind of data to return. Options:
'raw': Count data
'rel': Relative abundance
'abs': Abundance data</dd>
<dt><strong><code>agg</code></strong> :&ensp;<code>str</code></dt>
<dd>Type of aggregation of the values. Options specified above.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>str, array</code></dt>
<dd>The times to include</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="see-also">See Also</h2>
<p><code>mdsine2.Study.matrix</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def df(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Returns a dataframe of the data in matrix. Rows are taxa, columns are times.

    Parameters
    ----------
    dtype : str
        What kind of data to return. Options:
            &#39;raw&#39;: Count data
            &#39;rel&#39;: Relative abundance
            &#39;abs&#39;: Abundance data
    agg : str
        Type of aggregation of the values. Options specified above.
    times : str, array
        The times to include

    Returns
    -------
    pandas.DataFrame

    See Also
    --------
    mdsine2.Study.matrix
    &#39;&#39;&#39;
    M, times = self._matrix(dtype=dtype, agg=agg, times=times)
    index = [taxon.name for taxon in self.taxa]
    return pd.DataFrame(data=M, index=index, columns=times)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.iloc"><code class="name flex">
<span>def <span class="ident">iloc</span></span>(<span>self, idx: int) ‑> <a title="mdsine2.pylab.base.Subject" href="#mdsine2.pylab.base.Subject">Subject</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get the subject as an index</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of the subject</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pl.base.Subject</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iloc(self, idx: int) -&gt; Subject:
    &#39;&#39;&#39;Get the subject as an index

    Parameters
    ----------
    idx : int
        Index of the subject

    Returns
    -------
    pl.base.Subject
    &#39;&#39;&#39;
    for i,sid in enumerate(self._subjects):
        if i == idx:
            return self._subjects[sid]
    raise IndexError(&#39;Index ({}) not found&#39;.format(idx))</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.matrix"><code class="name flex">
<span>def <span class="ident">matrix</span></span>(<span>self, dtype: str, agg: str, times: Union[str, numpy.ndarray]) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Make a matrix of the aggregation of all the subjects in the subjectset</p>
<h2 id="aggregation-of-subjects">Aggregation Of Subjects</h2>
<p>What are the values for the taxa? Set the aggregation type using the parameter <code>agg</code>.
These are the types of aggregations:
'mean': Mean abundance of the taxon at a timepoint over all the subjects
'median': Median abundance of the taxon at a timepoint over all the subjects
'sum': Sum of all the abundances of the taxon at a timepoint over all the subjects
'max': Maximum abundance of the taxon at a timepoint over all the subjects
'min': Minimum abundance of the taxon at a timepoint over all the subjects</p>
<h2 id="aggregation-of-times">Aggregation Of Times</h2>
<p>Which times to include? Set the times to include with the parameter <code>times</code>.
These are the types of time aggregations:
'union': Take
theunion of the times of the subjects
'intersection': Take the intersection of the times of the subjects
You can manually specify the times to include with a list of times. If times are not
included in any of the subjects then we set them to NAN.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>What kind of data to return. Options:
'raw': Count data
'rel': Relative abundance
'abs': Abundance data</dd>
<dt><strong><code>agg</code></strong> :&ensp;<code>str</code></dt>
<dd>Type of aggregation of the values. Options specified above.</dd>
<dt><strong><code>times</code></strong> :&ensp;<code>str, array</code></dt>
<dd>The times to include</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray(n_taxa, n_times)</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def matrix(self, dtype: str, agg: str, times: Union[str, np.ndarray]) -&gt; np.ndarray:
    &#39;&#39;&#39;Make a matrix of the aggregation of all the subjects in the subjectset

    Aggregation of subjects
    -----------------------
    What are the values for the taxa? Set the aggregation type using the parameter `agg`. 
    These are the types of aggregations:
        &#39;mean&#39;: Mean abundance of the taxon at a timepoint over all the subjects
        &#39;median&#39;: Median abundance of the taxon at a timepoint over all the subjects
        &#39;sum&#39;: Sum of all the abundances of the taxon at a timepoint over all the subjects
        &#39;max&#39;: Maximum abundance of the taxon at a timepoint over all the subjects
        &#39;min&#39;: Minimum abundance of the taxon at a timepoint over all the subjects

    Aggregation of times
    --------------------
    Which times to include? Set the times to include with the parameter `times`.
    These are the types of time aggregations:
        &#39;union&#39;: Take  theunion of the times of the subjects
        &#39;intersection&#39;: Take the intersection of the times of the subjects
    You can manually specify the times to include with a list of times. If times are not
    included in any of the subjects then we set them to NAN.

    Parameters
    ----------
    dtype : str
        What kind of data to return. Options:
            &#39;raw&#39;: Count data
            &#39;rel&#39;: Relative abundance
            &#39;abs&#39;: Abundance data
    agg : str
        Type of aggregation of the values. Options specified above.
    times : str, array
        The times to include
    
    Returns
    -------
    np.ndarray(n_taxa, n_times)
    &#39;&#39;&#39;
    M, _ =  self._matrix(dtype=dtype, agg=agg, times=times)
    return M</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.names"><code class="name flex">
<span>def <span class="ident">names</span></span>(<span>self) ‑> Iterator[str]</span>
</code></dt>
<dd>
<div class="desc"><p>List the names of the contained subjects</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list(str)</code></dt>
<dd>List of names of the subjects in order</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def names(self) -&gt; Iterator[str]:
    &#39;&#39;&#39;List the names of the contained subjects

    Returns
    -------
    list(str)
        List of names of the subjects in order
    &#39;&#39;&#39;
    return [subj.name for subj in self]</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.normalize_qpcr"><code class="name flex">
<span>def <span class="ident">normalize_qpcr</span></span>(<span>self, max_value: float)</span>
</code></dt>
<dd>
<div class="desc"><p>Normalize the qPCR values such that the largest value is the max value
over all the subjects</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>max_value</code></strong> :&ensp;<code>float, int</code></dt>
<dd>This is the maximum qPCR value to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize_qpcr(self, max_value: float):
    &#39;&#39;&#39;Normalize the qPCR values such that the largest value is the max value
    over all the subjects

    Parameters
    ----------
    max_value : float, int
        This is the maximum qPCR value to

    Returns
    -------
    self
    &#39;&#39;&#39;
    if type(max_value) not in [int, float]:
        raise ValueError(&#39;max_value ({}) must either be an int or a float&#39;.format(
            type(max_value)))

    if self.qpcr_normalization_factor is not None:
        logging.warning(&#39;qPCR is already rescaled. unscaling and rescaling&#39;)
        self.denormalize_qpcr()

    temp_max = -1
    for subj in self:
        for key in subj.qpcr:
            temp_max = np.max([temp_max, subj.qpcr[key].mean()])

    self.qpcr_normalization_factor = max_value/temp_max
    logging.info(&#39;max_value found: {}, scaling_factor: {}&#39;.format(
        temp_max, self.qpcr_normalization_factor))

    for subj in self:
        for key in subj.qpcr:
            subj.qpcr[key].set_scaling_factor(scaling_factor=
                self.qpcr_normalization_factor)
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.parse"><code class="name flex">
<span>def <span class="ident">parse</span></span>(<span>self, metadata: pandas.core.frame.DataFrame, reads: pandas.core.frame.DataFrame = None, qpcr: pandas.core.frame.DataFrame = None, perturbations: pandas.core.frame.DataFrame = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse tables of samples and cast in Subject sets. Automatically creates
the subject classes with the respective names.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>metadata</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>Contains the meta data for each one of the samples
Columns:
'sampleID' -&gt; str : This is the name of the sample
'subject' -&gt; str : This is the name of the subject
'time' -&gt; float : This is the time the sample takes place
'perturbation:<code>name</code>' -&gt; int : This is a perturbation meta data where the
name of the perturbation is <code>name</code></dd>
<dt><strong><code>reads</code></strong> :&ensp;<code>pandas.DataFrame, None</code></dt>
<dd>Contains the reads for each one of the samples and taxa
index (str) : indexes the taxon name
columns (str) : indexes the sample ID
If nothing is passed in, the reads are set to None</dd>
<dt><strong><code>qpcr</code></strong> :&ensp;<code>pandas.DataFrame, None</code></dt>
<dd>Contains the qpcr measurements for each sample
index (str) : indexes the sample ID
columns (str) : Name is ignored. the values are set to the measurements</dd>
<dt><strong><code>perturbations</code></strong> :&ensp;<code>pandas.DataFrame, None</code></dt>
<dd>Contains the times and subjects for each perturbation
columns:
'name' -&gt; str : Name of the perturbation
'start' -&gt; float : This is the start time for the perturbation
'end' -&gt; float : This is the end time for the perturbation
'subject' -&gt; str : This is the subject name the perturbation is applied to</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse(self, metadata: pd.DataFrame, reads: pd.DataFrame=None, qpcr: pd.DataFrame=None, 
    perturbations: pd.DataFrame=None):
    &#39;&#39;&#39;Parse tables of samples and cast in Subject sets. Automatically creates
    the subject classes with the respective names.

    Parameters
    ----------
    metadata : pandas.DataFrame
        Contains the meta data for each one of the samples
        Columns:
            &#39;sampleID&#39; -&gt; str : This is the name of the sample
            &#39;subject&#39; -&gt; str : This is the name of the subject
            &#39;time&#39; -&gt; float : This is the time the sample takes place
            &#39;perturbation:`name`&#39; -&gt; int : This is a perturbation meta data where the
                name of the perturbation is `name`
    reads : pandas.DataFrame, None
        Contains the reads for each one of the samples and taxa
            index (str) : indexes the taxon name
            columns (str) : indexes the sample ID
        If nothing is passed in, the reads are set to None
    qpcr : pandas.DataFrame, None
        Contains the qpcr measurements for each sample
            index (str) : indexes the sample ID
            columns (str) : Name is ignored. the values are set to the measurements
    perturbations : pandas.DataFrame, None
        Contains the times and subjects for each perturbation
        columns:
            &#39;name&#39; -&gt; str : Name of the perturbation
            &#39;start&#39; -&gt; float : This is the start time for the perturbation
            &#39;end&#39; -&gt; float : This is the end time for the perturbation
            &#39;subject&#39; -&gt; str : This is the subject name the perturbation is applied to
    &#39;&#39;&#39;
    if not plutil.isdataframe(metadata):
        raise TypeError(&#39;`metadata` ({}) must be a pandas.DataFrame&#39;.format(type(metadata)))
    
    # Add the samples
    # ---------------
    if &#39;sampleID&#39; in metadata.columns:
        metadata = metadata.set_index(&#39;sampleID&#39;)
    for sampleid in metadata.index:

        sid = str(metadata[&#39;subject&#39;][sampleid])
        t = float(metadata[&#39;time&#39;][sampleid])

        if sid not in self:
            self.add_subject(name=sid)
        if t not in self[sid].times:
            self[sid].add_time(timepoint=t)

        self._samples[str(sampleid)] = (sid,t)

    # Add the perturbations if there are any
    # --------------------------------------
    if perturbations is not None:
        logging.warning(&#39;Reseting perturbations&#39;)
        self.perturbations = Perturbations()
        if not plutil.isdataframe(perturbations):
            raise TypeError(&#39;`metadata` ({}) must be a pandas.DataFrame&#39;.format(type(metadata)))
        try:
            for pidx in perturbations.index:
                pname = perturbations[&#39;name&#39;][pidx]
                subj = str(perturbations[&#39;subject&#39;][pidx])

                if pname not in self.perturbations:
                    # Create a new one
                    pert = BasePerturbation(
                        name=pname, 
                        starts={subj: perturbations[&#39;start&#39;][pidx]},
                        ends={subj: perturbations[&#39;end&#39;][pidx]})
                    self.perturbations.append(pert)
                else:
                    # Add this subject name to the pertubration
                    self.perturbations[pname].starts[subj] = perturbations[&#39;start&#39;][pidx]
                    self.perturbations[pname].ends[subj] = perturbations[&#39;end&#39;][pidx]
        except KeyError as e:
            logging.critical(e)
            raise KeyError(&#39;Make sure that `subject`, `start`, and `end` are columns&#39;)

    # Add the reads if necessary
    # --------------------------
    if reads is not None:
        if not plutil.isdataframe(reads):
            raise TypeError(&#39;`reads` ({}) must be a pandas.DataFrame&#39;.format(type(reads)))
        
        if &#39;name&#39; in reads.columns:
            reads = reads.set_index(&#39;name&#39;)

        for sampleid in reads.columns:
            if sampleid not in self._samples:
                raise ValueError(&#39;sample {} not contained in metadata. abort&#39;.format(sampleid))
            sid, t = self._samples[sampleid]
            self[sid].add_reads(timepoints=t, reads=reads[sampleid].to_numpy())

    # Add the qPCR measurements if necessary
    # --------------------------------------
    if qpcr is not None:
        if not plutil.isdataframe(qpcr):
            raise TypeError(&#39;`qpcr` ({}) must be a pandas.DataFrame&#39;.format(type(qpcr)))
        if &#39;sampleID&#39; in qpcr.columns:
            qpcr = qpcr.set_index(&#39;sampleID&#39;)

        for sampleid in qpcr.index:
            try:
                sid, t = self._samples[sampleid]
            except:
                raise ValueError(&#39;Sample ID `{}` not found in metadata ({}). Make sure &#39; \
                    &#39;you set the sample ID as the index in the `qpcr` dataframe&#39;.format(
                        sampleid, list(self._samples.keys())))
            cfuspergram = qpcr.loc[sampleid].to_numpy()
            self[sid].add_qpcr(timepoints=t, qpcr=cfuspergram)
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.pop_subject"><code class="name flex">
<span>def <span class="ident">pop_subject</span></span>(<span>self, sid: Union[int, str, Iterator[str]], name: str = 'unnamed-study') ‑> <a title="mdsine2.pylab.base.Study" href="#mdsine2.pylab.base.Study">Study</a></span>
</code></dt>
<dd>
<div class="desc"><p>Remove the indicated subject id</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sid</code></strong> :&ensp;<code>list(str), str, int</code></dt>
<dd>This is the subject name/s or the index/es to pop out.
Return a new Study with the specified subjects removed.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the new study to return</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pop_subject(self, sid: Union[int, str, Iterator[str]], 
    name: str=&#39;unnamed-study&#39;) -&gt; &#39;Study&#39;:
    &#39;&#39;&#39;Remove the indicated subject id

    Parameters
    ----------
    sid : list(str), str, int
        This is the subject name/s or the index/es to pop out.
        Return a new Study with the specified subjects removed.
    name : str
        Name of the new study to return
    &#39;&#39;&#39;
    if not plutil.isarray(sid):
        sids = [sid]
    else:
        sids = sid

    for i in range(len(sids)):
        if plutil.isint(sids[i]):
            sids[i] = list(self._subjects.keys())[sids[i]]
        elif not plutil.isstr(sids[i]):
            raise ValueError(&#39;`sid` ({}) must be a str&#39;.format(type(sids[i])))
    ret = Study(taxa=self.taxa, name=name)
    ret.qpcr_normalization_factor = self.qpcr_normalization_factor

    for s in sids:
        if s in self._subjects:
            ret._subjects[s] =  self._subjects.pop(s, None)
            ret._subjects[s].parent = ret
        else:
            raise ValueError(&#39;`sid` ({}) not found&#39;.format(sid))

    ret.perturbations = copy.deepcopy(self.perturbations)

    # Remove the names of the subjects in the perturbations
    for study in [ret, self]:
        for perturbation in study.perturbations:
            names = list(perturbation.starts.keys())
            for subjname in names:
                if subjname not in study:
                    perturbation.starts.pop(subjname, None)
            names = list(perturbation.ends.keys())
            for subjname in names:
                if subjname not in study:
                    perturbation.ends.pop(subjname, None)

    return ret</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.pop_taxa"><code class="name flex">
<span>def <span class="ident">pop_taxa</span></span>(<span>self, oids: Union[str, int, Iterator[str], Iterator[int]])</span>
</code></dt>
<dd>
<div class="desc"><p>Delete the taxa indicated in oidxs. Updates the reads table and
the internal TaxaSet</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>oids</code></strong> :&ensp;<code>str, int, list(str/int)</code></dt>
<dd>These are the identifiers for each of the taxon/taxa to delete</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pop_taxa(self, oids: Union[str, int, Iterator[str], Iterator[int]]):
    &#39;&#39;&#39;Delete the taxa indicated in oidxs. Updates the reads table and
    the internal TaxaSet

    Parameters
    ----------
    oids : str, int, list(str/int)
        These are the identifiers for each of the taxon/taxa to delete
    &#39;&#39;&#39;
    # get indices
    oidxs = []
    for oid in oids:
        oidxs.append(self.taxa[oid].idx)
    
    # Delete the s from taxaset
    for oid in oids:
        self.taxa.del_taxon(oid)

    # Delete the reads
    for subj in self:
        for t in subj.reads:
            subj.reads[t] = np.delete(subj.reads[t], oidxs)
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.pop_taxa_like"><code class="name flex">
<span>def <span class="ident">pop_taxa_like</span></span>(<span>self, study: <a title="mdsine2.pylab.base.Study" href="#mdsine2.pylab.base.Study">Study</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove s in the TaxaSet so that it matches the TaxaSet in <code>study</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>study</code></strong> :&ensp;<code>mdsine2.study</code></dt>
<dd>This is the study object we are mirroring in terms of taxa</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pop_taxa_like(self, study: &#39;Study&#39;):
    &#39;&#39;&#39;Remove s in the TaxaSet so that it matches the TaxaSet in `study`

    Parameters
    ----------
    study : mdsine2.study
        This is the study object we are mirroring in terms of taxa
    &#39;&#39;&#39;
    to_delete = []
    for taxon in self.taxa:
        if taxon.name not in study.taxa:
            to_delete.append(taxon.name)
    self.pop_taxa(to_delete)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.pop_times"><code class="name flex">
<span>def <span class="ident">pop_times</span></span>(<span>self, times: Union[int, float, numpy.ndarray], sids: Union[str, int, Iterator[int]] = 'all')</span>
</code></dt>
<dd>
<div class="desc"><p>Discard the times in <code>times</code> for the subjects listed in <code>sids</code>.
If a timepoint is not found in a subject, no error is thrown.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>times</code></strong> :&ensp;<code>numeric, list(numeric)</code></dt>
<dd>Time/s to delete</dd>
<dt><strong><code>sids</code></strong> :&ensp;<code>str, int, list(int)</code></dt>
<dd>The Subject ID or a list of subject IDs that you want to delete the timepoints
from. If it is a str:
'all' - delete from all subjects</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pop_times(self, times: Union[int, float, np.ndarray], sids: Union[str, int, Iterator[int]]=&#39;all&#39;):
    &#39;&#39;&#39;Discard the times in `times` for the subjects listed in `sids`.
    If a timepoint is not found in a subject, no error is thrown.

    Parameters
    ----------
    times : numeric, list(numeric)
        Time/s to delete
    sids : str, int, list(int)
        The Subject ID or a list of subject IDs that you want to delete the timepoints
        from. If it is a str:
            &#39;all&#39; - delete from all subjects
    &#39;&#39;&#39;
    if plutil.isstr(sids):
        if sids == &#39;all&#39;:
            sids = list(self._subjects.keys())
        else:
            raise ValueError(&#39;`sids` ({}) not recognized&#39;.format(sids))
    elif plutil.isint(sids):
        if sids not in self._subjects:
            raise IndexError(&#39;`sid` ({}) not found in subjects&#39;.format(
                list(self._subjects.keys())))
        sids = [sids]
    elif plutil.isarray(sids):
        for sid in sids:
            if not plutil.isint(sid):
                raise TypeError(&#39;Each sid ({}) must be an int&#39;.format(type(sid)))
            if sid not in self._subjects:
                raise IndexError(&#39;Subject {} not found in subjects ({})&#39;.format(
                    sid, list(self._subjects.keys())))
    else:
        raise TypeError(&#39;`sids` ({}) type not recognized&#39;.format(type(sids)))
    if plutil.isnumeric(times):
        times = [times]
    elif plutil.isarray(times):
        for t in times:
            if not plutil.isnumeric(t):
                raise TypeError(&#39;Each time ({}) must be a numeric&#39;.format(type(t)))
    else:
        raise TypeError(&#39;`times` ({}) type not recognized&#39;.format(type(times)))

    for t in times:
        for sid in sids:
            subj = self._subjects[sid]
            if t in subj.times:
                subj.qpcr.pop(t, None)
                subj.reads.pop(t,None)
                subj.times = np.sort(list(subj.reads.keys()))</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.split_on_perturbations"><code class="name flex">
<span>def <span class="ident">split_on_perturbations</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Make new subjects for the time points that are divided by perturbations.
Throw out all of the data
where the perturbations are active.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_on_perturbations(self):
    &#39;&#39;&#39;Make new subjects for the time points that are divided by perturbations. 
    Throw out all of the data  where the perturbations are active.

    Returns
    -------
    self
    &#39;&#39;&#39;
    for subj in self:
        subj._split_on_perturbations()
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.times"><code class="name flex">
<span>def <span class="ident">times</span></span>(<span>self, agg: str) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the times of all the contained subjects</p>
<p>These are the types of time aggregations:
'union': Take
theunion of the times of the subjects
'intersection': Take the intersection of the times of the subjects
You can manually specify the times to include with a list of times. If times are not
included in any of the subjects then we set them to NAN.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>agg</code></strong> :&ensp;<code>str</code></dt>
<dd>Type of aggregation to do of the times. Options: 'union', 'intersection'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def times(self, agg: str) -&gt; np.ndarray:
    &#39;&#39;&#39;Aggregate the times of all the contained subjects

    These are the types of time aggregations:
        &#39;union&#39;: Take  theunion of the times of the subjects
        &#39;intersection&#39;: Take the intersection of the times of the subjects
    You can manually specify the times to include with a list of times. If times are not
    included in any of the subjects then we set them to NAN.

    Parameters
    ----------
    agg : str
        Type of aggregation to do of the times. Options: &#39;union&#39;, &#39;intersection&#39;
    &#39;&#39;&#39;
    if agg not in [&#39;union&#39;, &#39;intersection&#39;]:
        raise ValueError(&#39;`agg` ({}) not recognized&#39;.format(agg))

    all_times = []
    for subj in self:
        all_times = np.append(all_times, subj.times)
    all_times = np.sort(np.unique(all_times))
    if agg == &#39;union&#39;:
        times = all_times

    elif agg == &#39;intersection&#39;:
        times = []
        for t in all_times:
            addin = True
            for subj in self:
                if t not in subj.times:
                    addin = False
                    break
            if addin:
                times = np.append(times, t)
    else:
        raise ValueError(&#39;`times` ({}) not recognized&#39;.format(times))
    return times</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.write_metadata_to_csv"><code class="name flex">
<span>def <span class="ident">write_metadata_to_csv</span></span>(<span>self, path: str = None, sep: str = '\t') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Write the internal metadata to a table. If a path is provided
then write it to that path.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str, None</code></dt>
<dd>This is the location to save the metadata file
If this is not provided then just return the dataframe</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the separator of the table</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_metadata_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Write the internal metadata to a table. If a path is provided
    then write it to that path.

    Parameters
    ----------
    path : str, None
        This is the location to save the metadata file
        If this is not provided then just return the dataframe
    sep : str
        This is the separator of the table
    &#39;&#39;&#39;
    columns = [&#39;sampleID&#39;, &#39;subject&#39;, &#39;time&#39;]
    data = []
    for sampleid in self._samples:
        sid, t = self._samples[sampleid]
        if t not in self[sid].times:
            continue
        data.append([sampleid, sid, t])
    df = pd.DataFrame(data, columns=columns)
    if path is not None:
        df.to_csv(path, sep=sep, index=False, header=True)
    return df</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.write_perturbations_to_csv"><code class="name flex">
<span>def <span class="ident">write_perturbations_to_csv</span></span>(<span>self, path: str = None, sep: str = '\t') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Write the perturbations to a table. If a path is provided then
we write to that path</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location to save the perturbations file
If this is not provided then we do not save</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the separator of the table</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_perturbations_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Write the perturbations to a table. If a path is provided then
    we write to that path

    Parameters
    ----------
    path : str
        This is the location to save the perturbations file
        If this is not provided then we do not save
    sep : str
        This is the separator of the table
    &#39;&#39;&#39;
    columns = [&#39;name&#39;, &#39;start&#39;, &#39;end&#39;, &#39;subject&#39;]
    data = []
    for perturbation in self.perturbations:
        for subjname in perturbation.starts:
            data.append([
                perturbation.name, 
                perturbation.starts[subjname],
                perturbation.ends[subjname],
                subjname])

    df = pd.DataFrame(data, columns=columns)
    if path is not None:
        df.to_csv(path, sep=sep, index=False, header=True)
    return df</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.write_qpcr_to_csv"><code class="name flex">
<span>def <span class="ident">write_qpcr_to_csv</span></span>(<span>self, path: str = None, sep: str = '\t') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Write the qPCR measurements to a table. If a path is provided then
we write to that path</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location to save the qPCR file
If this is not provided then we do not save</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the separator of the table</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_qpcr_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Write the qPCR measurements to a table. If a path is provided then
    we write to that path

    Parameters
    ----------
    path : str
        This is the location to save the qPCR file
        If this is not provided then we do not save
    sep : str
        This is the separator of the table
    &#39;&#39;&#39;
    max_n_measurements = -1
    data = []
    for sampleid in self._samples:
        sid, t = self._samples[sampleid]
        if t not in self[sid].times:
            continue
        subj = self[sid]
        ms = subj.qpcr[t].data
        if len(ms) &gt; max_n_measurements:
            max_n_measurements = len(ms)
        ms = [sampleid] + ms.tolist()
        data.append(ms)
    
    for i, ms in enumerate(data):
        if len(ms)-1 &lt; max_n_measurements:
            data[i] = np.append(
                ms, 
                np.nan * np.ones(max_n_measurements - len(ms)))
    
    columns = [&#39;sampleID&#39;] + [&#39;measurement{}&#39;.format(i+1) for i in range(max_n_measurements)]

    df = pd.DataFrame(data, columns=columns)
    if path is not None:
        df.to_csv(path, sep=sep, index=False, header=True)
    return df</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Study.write_reads_to_csv"><code class="name flex">
<span>def <span class="ident">write_reads_to_csv</span></span>(<span>self, path: str = None, sep: str = '\t') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Write the reads to a table. If a path is provided then
we write to that path</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location to save the reads file
If this is not provided then just return the dataframe</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the separator of the table</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_reads_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Write the reads to a table. If a path is provided then
    we write to that path

    Parameters
    ----------
    path : str
        This is the location to save the reads file
        If this is not provided then just return the dataframe
    sep : str
        This is the separator of the table
    &#39;&#39;&#39;
    data = [[taxon.name for taxon in self.taxa]]
    index = [&#39;name&#39;]
    for sampleid in self._samples:
        sid, t = self._samples[sampleid]
        if t not in self[sid].times:
            continue

        index.append(sampleid)
        reads = self[sid].reads[t]
        data.append(reads)

    df = pd.DataFrame(data, index=index).T
    if path is not None:
        df.to_csv(path, sep=sep, index=False, header=True)
    return df</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.base.Saveable.load" href="#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.save" href="#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.set_save_location" href="#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.pylab.base.Subject"><code class="flex name class">
<span>class <span class="ident">Subject</span></span>
<span>(</span><span>parent: <a title="mdsine2.pylab.base.Study" href="#mdsine2.pylab.base.Study">Study</a>, name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Data for a single subject
The TaxaSet order is done with respect to the ordering in the <code>reads_table</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>parent</code></strong> :&ensp;<code><a title="mdsine2.pylab.base.Study" href="#mdsine2.pylab.base.Study">Study</a></code></dt>
<dd>This is the parent class (we have a reverse pointer)</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the name of the subject</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Subject(Saveable):
    &#39;&#39;&#39;Data for a single subject
    The TaxaSet order is done with respect to the ordering in the `reads_table`

    Parameters
    ----------
    parent : Study
        This is the parent class (we have a reverse pointer)
    name : str
        This is the name of the subject
    &#39;&#39;&#39;
    def __init__(self, parent: &#39;Study&#39;, name: str):
        self.name = name # str
        self.id = id(self)
        self.parent = parent
        self.qpcr = {} # dict: time (float) -&gt; qpcr object (qPCRData)
        self.reads = {} # dict: time (float) -&gt; reads (np.ndarray)
        self.times = np.asarray([]) # times in order
        self._reads_individ = {} # for taking out aggregated taxa

    def add_time(self, timepoint: Union[float, int]):
        &#39;&#39;&#39;Add the timepoint `timepoint`. Set the reads and qpcr at that timepoint
        to None

        Parameters
        ----------
        timepoint : float, int
            Time point to add
        &#39;&#39;&#39;
        if timepoint in self.times:
            return
        self.times = np.sort(np.append(self.times, timepoint))
        self.reads[timepoint] = None
        self.qpcr[timepoint] = None

    def add_reads(self, timepoints: Union[np.ndarray, int, float], reads: np.ndarray):
        &#39;&#39;&#39;Add the reads for timepoint `timepoint`

        Parameters
        ----------
        timepoint : numeric, array
            This is the time that the measurement occurs. If it is an array, then
            we are adding for multiple timepoints
        reads : np.ndarray(N_TAXA, N_TIMEPOINTS)
            These are the reads for the taxa in order. Assumed to be in the 
            same order as the TaxaSet. If it is a dataframe then we use the rows
            to index the taxon names. If timepoints is an array, then we are adding 
            for multiple timepoints. In this case we assume that the rows index  the 
            taxon and the columns index the timepoint.
        &#39;&#39;&#39;
        if not plutil.isarray(timepoints):
            timepoints = [timepoints]
        for timepoint in timepoints:
            if not plutil.isnumeric(timepoint):
                raise TypeError(&#39;`timepoint` ({}) must be a numeric&#39;.format(type(timepoint)))
        if not plutil.isarray(reads):
            raise TypeError(&#39;`reads` ({}) must be an array&#39;.format(type(reads)))
        
        if reads.ndim == 1:
            reads = reads.reshape(-1,1)
        if reads.ndim != 2:
            raise ValueError(&#39;`reads` {} must be a matrix&#39;.format(reads.shape))
        if reads.shape[0] != len(self.taxa) or reads.shape[1] != len(timepoints):
            raise ValueError(&#39;`reads` shape {} does not align with the number of taxa ({}) &#39; \
                &#39;or timepoints ({})&#39;.format(reads.shape, len(self.taxa), len(timepoints)))

        for tidx, timepoint in enumerate(timepoints):
            if timepoint in self.reads:
                if self.reads[timepoint] is not None:
                    logging.debug(&#39;There are already reads specified at time `{}` for subject `{}`, overwriting&#39;.format(
                        timepoint, self.name))
                
            self.reads[timepoint] = reads[:,tidx]
            if timepoint not in self.times:
                self.times = np.sort(np.append(self.times, timepoint))
        return self

    def add_qpcr(self, timepoints: Union[np.ndarray, int, float], qpcr: np.ndarray, 
        masses: Union[np.ndarray, int, float]=None, dilution_factors: Union[np.ndarray, int, float]=None):
        &#39;&#39;&#39;Add qpcr measurements for timepoints `timepoints`

        Parameters
        ----------
        timepoint : numeric, array
            This is the time that the measurement occurs. If it is an array, then
            we are adding for multiple timepoints
        qpcr : np.ndarray(N_TIMEPOINTS, N_REPLICATES)
            These are the qPCR measurements in order of timepoints. Assumed to be in the 
            same order as timepoints.If timepoints is an array, then we are adding 
            for multiple timepoints. In this case we assume that the rows index the 
            timepoint and the columns index the replicates of the qpcr measurement.
        masses : numeric, np.ndarray
            These are the masses for each on of the qPCR measurements. If this is not 
            specified, then this assumes that the numbers in `qpcr` are already normalized
            by their sample weight.
        dilution_factors : numeric, np.ndarray
            These are the dilution factors for each of the qPCR measurements. If this is
            not specified, then this assumes that each one of the numbers in `qpcr` are
            already normalized by the dilution factor
        &#39;&#39;&#39;
        if not plutil.isarray(timepoints):
            timepoints = [timepoints]
        for timepoint in timepoints:
            if not plutil.isnumeric(timepoint):
                raise TypeError(&#39;`timepoint` ({}) must be a numeric&#39;.format(type(timepoint)))
        if masses is not None:
            if plutil.isnumeric(masses):
                masses = [masses]
            for mass in masses:
                if not plutil.isnumeric(mass):
                    raise TypeError(&#39;Each mass in `masses` ({}) must be a numeric&#39;.format(type(mass)))
                if mass &lt;= 0:
                    raise ValueError(&#39;Each mass in `masses` ({}) must be &gt; 0&#39;.format(mass))
            if len(masses) != len(timepoints):
                raise ValueError(&#39;Number of timepoints ({}) and number of masses ({}) &#39; \
                    &#39;must be equal&#39;.format(len(timepoints), len(masses)))
        if dilution_factors is not None:
            if plutil.isnumeric(dilution_factors):
                dilution_factors = [dilution_factors]
            for dilution_factor in dilution_factors:
                if not plutil.isnumeric(dilution_factor):
                    raise TypeError(&#39;Each dilution_factor in `dilution_factors` ({}) &#39; \
                        &#39;must be a numeric&#39;.format(type(dilution_factor)))
                if dilution_factor &lt;= 0:
                    raise ValueError(&#39;Each dilution_factor in `dilution_factors` ({}) &#39; \
                        &#39;must be &gt; 0&#39;.format(dilution_factor))
            if len(dilution_factors) != len(timepoints):
                raise ValueError(&#39;Number of timepoints ({}) and number of dilution_factors ({}) &#39; \
                    &#39;must be equal&#39;.format(len(timepoints), len(dilution_factors)))
            
        if not plutil.isarray(qpcr):
            raise TypeError(&#39;`qpcr` ({}) must be an array&#39;.format(type(qpcr)))
        if qpcr.ndim == 1:
            qpcr = qpcr.reshape(1,-1)
        if qpcr.ndim != 2:
            raise ValueError(&#39;`qpcr` {} must be a matrix&#39;.format(qpcr.shape))
        if qpcr.shape[0] != len(timepoints):
            raise ValueError(&#39;`qpcr` shape {} does not align with the number of timepoints ({}) &#39; \
                &#39;&#39;.format(qpcr.shape, len(timepoints)))

        for tidx, timepoint in enumerate(timepoints):
            if timepoint in self.qpcr:
                if self.qpcr[timepoint] is not None:
                    logging.debug(&#39;There are already qpcr measurements specified at time `{}` for subject `{}`, overwriting&#39;.format(
                        timepoint, self.name))
            if masses is not None:
                mass = masses[tidx]
            else:
                mass = 1
            if dilution_factors is not None:
                dil = dilution_factors[tidx]
            else:
                dil = 1

            self.qpcr[timepoint] = qPCRdata(cfus=qpcr[tidx,:], mass=mass, 
                dilution_factor=dil)
                
            if timepoint not in self.times:
                self.times = np.sort(np.append(self.times, timepoint))
        return self

    @property
    def perturbations(self) -&gt; Perturbations:
        return self.parent.perturbations

    @property
    def taxa(self) -&gt; TaxaSet:
        return self.parent.taxa

    @property
    def index(self) -&gt; int:
        &#39;&#39;&#39;Return the index of this subject in the Study file
        &#39;&#39;&#39;
        for iii, subj in enumerate(self.parent):
            if subj.name == self.name:
                return iii
        raise ValueError(&#39;Should not get here&#39;)

    def matrix(self) -&gt; Dict[str, np.ndarray]:
        &#39;&#39;&#39;Make a numpy matrix out of our data - returns the raw reads,
        the relative abundance, and the absolute abundance.

        If there is no qPCR data, then the absolute abundance is set to None.
        &#39;&#39;&#39;

        shape = (len(self.taxa), len(self.times))
        raw = np.zeros(shape=shape, dtype=int)
        rel = np.zeros(shape=shape, dtype=float)
        abs = np.zeros(shape=shape, dtype=float)

        for i,t in enumerate(self.times):
            raw[:,i] = self.reads[t]
            rel[:,i] = raw[:,i]/np.sum(raw[:,i])
        
        try:
            for i,t in enumerate(self.times):
                abs[:,i] = rel[:,i] * self.qpcr[t].mean()
        except AttributeError as e:
            logging.info(&#39;Attribute Error ({}) for absolute abundance. This is likely &#39; \
                &#39;because you did not set the qPCR abundances. Skipping `abs`&#39;.format(e))
            abs = None

        return {&#39;raw&#39;:raw, &#39;rel&#39;: rel, &#39;abs&#39;:abs}

    def df(self) -&gt; Dict[str, pd.DataFrame]:
        &#39;&#39;&#39;Returns a dataframe of the data - same as matrix
        &#39;&#39;&#39;
        d = self.matrix()
        index = self.taxa.names.order
        times = self.times
        for key in d:
            d[key] = pd.DataFrame(data=d[key], index=index, columns=times)
        return d

    def read_depth(self, t: Union[int, float]=None) -&gt; Union[np.ndarray, int]:
        &#39;&#39;&#39;Get the read depth at time `t`. If nothing is given then return all
        of them

        Parameters
        ----------
        t : int, float, Optional
            Get the read depth at this time. If nothing is provided, all of the read depths for this 
            subject are returned
        &#39;&#39;&#39;
        if t is None:
            return np.sum(self.matrix()[&#39;raw&#39;], axis=0)
        if t not in self.reads:
            raise ValueError(&#39;`t` ({}) not recognized. Valid times: {}&#39;.format(
                t, self.times))
        return np.sum(self.reads[t])

    def cluster_by_taxlevel(self, dtype: str, taxlevel: str, index_formatter: str=None, 
        smart_unspec: bool=True) -&gt; Tuple[pd.DataFrame, Dict[str,str]]:
        &#39;&#39;&#39;Clusters the taxa into the taxonomic level indicated in `taxlevel`.

        Smart Unspecified
        -----------------
        If True, returns the higher taxonomic classification while saying the desired taxonomic level
        is unspecified. Example: &#39;Order ABC, Family NA&#39;. Note that this overrides the `index_formatter`.

        Parameters
        ----------
        dtype : str
            This is the type of data to cluster. Options are:
                &#39;raw&#39;: These are the counts
                &#39;rel&#39;: This is the relative abundances
                &#39;abs&#39;: This is the absolute abundance (qPCR * rel)
        taxlevel : str, None
            This is the taxonomic level to aggregate the data at. If it is 
            None then we do not do any collapsing (this is the same as &#39;asv&#39;)
        index_formatter : str
            How to make the index using `taxaname_formatter`. Note that you cannot
            specify anything at a lower taxonomic level than what youre clustering at. For 
            example, you cannot cluster at the &#39;class&#39; level and then specify &#39;%(genus)s&#39; 
            in the index formatter.
            If nothing is specified then only return the specified taxonomic level
        smart_unspec : bool
            If True, if the taxonomic level is not not specified for that OTU/Taxon, then use the
            lowest taxonomic level instead.

        Returns
        -------
        pandas.DataFrame
            Dataframe of the data
        dict (str-&gt;str)
            Maps taxon name to the row it got allocated to
        &#39;&#39;&#39;
        # Type checking
        if not plutil.isstr(dtype):
            raise TypeError(&#39;`dtype` ({}) must be a str&#39;.format(type(dtype)))
        if dtype not in [&#39;raw&#39;, &#39;rel&#39;, &#39;abs&#39;]:
            raise ValueError(&#39;`dtype` ({}) not recognized&#39;.format(dtype))
        if not plutil.isstr(taxlevel):
            raise TypeError(&#39;`taxlevel` ({}) must be a str&#39;.format(type(taxlevel)))
        if taxlevel not in [&#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;,  &#39;order&#39;, &#39;family&#39;, 
            &#39;genus&#39;, &#39;species&#39;, &#39;asv&#39;]:
            raise ValueError(&#39;`taxlevel` ({}) not recognized&#39;.format(taxlevel))
        if index_formatter is None:
            index_formatter = taxlevel
        if index_formatter is not None:
            if not plutil.isstr(index_formatter):
                raise TypeError(&#39;`index_formatter` ({}) must be a str&#39;.format(type(index_formatter)))
            
            for tx in TAX_IDXS:
                if tx in index_formatter and TAX_IDXS[tx] &gt; TAX_IDXS[taxlevel]:
                    raise ValueError(&#39;You are clustering at the {} level but are specifying&#39; \
                        &#39; {} in the `index_formatter`. This does not make sense. Either cluster&#39; \
                        &#39;at a lower tax level or specify the `index_formatter` to a higher tax &#39; \
                        &#39;level&#39;.format(taxlevel, tx))

        index_formatter = index_formatter.replace(&#39;%(asv)s&#39;, &#39;%(name)s&#39;)

        # Everything is valid, get the data dataframe and the return dataframe
        taxaname_map = {}
        df = self.df()[dtype]
        cols = list(df.columns)
        cols.append(taxlevel)
        dfnew = pd.DataFrame(columns = cols).set_index(taxlevel)

        # Get the level in the taxonomy, create a new entry if it is not there already
        taxa = {} # lineage -&gt; label
        for i, taxon in enumerate(self.taxa):
            row = df.index[i]
            tax = taxon.get_lineage(level=taxlevel)
            tax = tuple(tax)
            tax = str(tax).replace(&#34;&#39;&#34;, &#39;&#39;)
            if tax in taxa:
                dfnew.loc[taxa[tax]] += df.loc[row]
            else:
                if not taxon.tax_is_defined(taxlevel) and smart_unspec:
                    # Get the least common ancestor above the taxlevel
                    taxlevelidx = TAX_IDXS[taxlevel]
                    ttt = None
                    while taxlevelidx &gt; -1:
                        if taxon.tax_is_defined(TAX_LEVELS[taxlevelidx]):
                            ttt = TAX_LEVELS[taxlevelidx]
                            break
                        taxlevelidx -= 1
                    if ttt is None:
                        raise ValueError(&#39;Could not find a single taxlevel: {}&#39;.format(str(taxon)))
                    taxa[tax] = &#39;{} {}, {} NA&#39;.format(ttt.capitalize(), 
                        taxon.taxonomy[ttt], taxlevel.capitalize())
                else:
                    taxa[tax] = taxaname_formatter(format=index_formatter, taxon=taxon, taxa=self.taxa)
                toadd = pd.DataFrame(np.array(list(df.loc[row])).reshape(1,-1),
                    index=[taxa[tax]], columns=dfnew.columns)
                dfnew = dfnew.append(toadd)
            
            if taxa[tax] not in taxaname_map:
                taxaname_map[taxa[tax]] = []
            taxaname_map[taxa[tax]].append(taxon.name)
        
        return dfnew, taxaname_map

    def _split_on_perturbations(self):
        &#39;&#39;&#39;If there are perturbations, then we take out the data on perturbations
        and we set the data in the different segments to different subjects

        Internal funciton, should not be used by the user
        &#39;&#39;&#39;
        if len(self.parent.perturbations) == 0:
            logging.info(&#39;No perturbations to split on, do nothing&#39;)
            return

        # Get the time intervals for each of the times that we are not on perturbations
        start_tidx = 0
        not_perts = []
        in_pert = False
        for i in range(len(self.times)):
            # check if the time is in a perturbation
            a = False
            for pert in self.parent.perturbations:
                if self.name not in pert:
                    continue
                start = pert.starts[self.name]
                end = pert.ends[self.name]
                # check if in the perturbation
                if self.times[i] &gt; start and self.times[i] &lt;= end:
                    a = True
                    break
            if a:
                # If the current time point is in a perturbation and we previously
                # have no been in a perturbation, this means we can add the previous
                # interval into the intervals that we want to keep
                if not in_pert:
                    not_perts.append((start_tidx, i))
                in_pert = True
            else:
                # If we are not currently in a perturbation but we previously were
                # then we restart to `start_tidx`
                if in_pert:
                    start_tidx = i
                    in_pert = False
        # If we have finished and we are out of a perturbation at the end, then
        # we can add the rest of the times at the end to a valid not in perturbation time
        if not in_pert:
            not_perts.append((start_tidx, len(self.times)))

        # For each of the time slices recorded, make a new subject
        if len(in_pert) == 0:
            raise ValueError(&#39;THere are perturbations ({}), this must not be zero.&#39; \
                &#39; Something went wrong&#39;.format(len(self.parent.perturbations)))
        ii = 0
        for start,end in not_perts:
            mid = self.name+&#39;_{}&#39;.format(ii)
            self.parent.add(name=mid)
            for i in range(start,end):
                t = self.times[i]
                self.parent[mid].qpcr[t] = self.qpcr[t]
                self.parent[mid].reads[t] = self.reads[t]
            self.parent[mid].times = self.times[start:end]

    def _deaggregate_item(self, agg: OTU, other: str):
        &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
        `other` is then appended to the end. This is called from 
        `mdsine2.Study.deaggregate_item`.

        Parameters
        ----------
        agg : OTU
            This is an OTU with multiple sequences contained. Must 
            have the name `other` in there
        other : str
            This is the name of the taxon that should be taken out of `agg`
        &#39;&#39;&#39;
        # Append the reads of the deaggregated at the bottom and subtract them
        # from the aggregated index
        if other not in self._reads_individ:
            raise ValueError(&#39;`other` ({}) reads not found in archive. This probably &#39; \
                &#39;happened because you called `aggregate_items` from the TaxaSet object&#39; \
                &#39; instead from this object. Study object not consistent. Failing.&#39;.format(other))
        
        aggidx = agg.idx
        for t in self.times:
            try:
                new_reads = self._reads_individ[other][t]
            except:
                raise ValueError(&#39;Timepoint `{}` added into subject `{}` after &#39; \
                    &#39;Taxon `{}` was removed. Study object is not consistent. You &#39; \
                    &#39;cannot add in other timepoints after you aggregate taxa. Failing.&#39;.format(
                        t, self.name, other))
            self.reads[t][aggidx] = self.reads[t][aggidx] - new_reads
            self.reads[t] = np.append(self.reads[t], new_reads)
        self._reads_individ.pop(other)
        return

    def _aggregate_items(self, anchor: Union[OTU, Taxon], other: Union[OTU, Taxon]):
        &#39;&#39;&#39;Aggregate the taxon `other` into `anchor`. This is called from 
        `mdsine2.Study.aggregate_items`.

        Parameters
        ----------
        anchor, other : OTU, Taxon
            These are the s to combine
        &#39;&#39;&#39;
        # If one of them are taxon, then record their individual reads
        # if we want to dissociate them later
        for taxon in [anchor, other]:
            if istaxontype(taxon):
                if taxon.name in self._reads_individ:
                    raise ValueError(&#39;Taxon is already in this dict. This should not happen.&#39;)
                aidx = taxon.idx
                self._reads_individ[taxon.name] = {}
                for t in self.times:
                    self._reads_individ[taxon.name][t] = self.reads[t][aidx]
        
        for t in self.times:
            self.reads[t][anchor.idx] += self.reads[t][other.idx]
            self.reads[t] = np.delete(self.reads[t], other.idx)
        return</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="mdsine2.pylab.base.Subject.index"><code class="name">var <span class="ident">index</span> : int</code></dt>
<dd>
<div class="desc"><p>Return the index of this subject in the Study file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def index(self) -&gt; int:
    &#39;&#39;&#39;Return the index of this subject in the Study file
    &#39;&#39;&#39;
    for iii, subj in enumerate(self.parent):
        if subj.name == self.name:
            return iii
    raise ValueError(&#39;Should not get here&#39;)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.perturbations"><code class="name">var <span class="ident">perturbations</span> : <a title="mdsine2.pylab.base.Perturbations" href="#mdsine2.pylab.base.Perturbations">Perturbations</a></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def perturbations(self) -&gt; Perturbations:
    return self.parent.perturbations</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.taxa"><code class="name">var <span class="ident">taxa</span> : <a title="mdsine2.pylab.base.TaxaSet" href="#mdsine2.pylab.base.TaxaSet">TaxaSet</a></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def taxa(self) -&gt; TaxaSet:
    return self.parent.taxa</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Subject.add_qpcr"><code class="name flex">
<span>def <span class="ident">add_qpcr</span></span>(<span>self, timepoints: Union[numpy.ndarray, int, float], qpcr: numpy.ndarray, masses: Union[numpy.ndarray, int, float] = None, dilution_factors: Union[numpy.ndarray, int, float] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Add qpcr measurements for timepoints <code>timepoints</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>timepoint</code></strong> :&ensp;<code>numeric, array</code></dt>
<dd>This is the time that the measurement occurs. If it is an array, then
we are adding for multiple timepoints</dd>
<dt><strong><code>qpcr</code></strong> :&ensp;<code>np.ndarray(N_TIMEPOINTS, N_REPLICATES)</code></dt>
<dd>These are the qPCR measurements in order of timepoints. Assumed to be in the
same order as timepoints.If timepoints is an array, then we are adding
for multiple timepoints. In this case we assume that the rows index the
timepoint and the columns index the replicates of the qpcr measurement.</dd>
<dt><strong><code>masses</code></strong> :&ensp;<code>numeric, np.ndarray</code></dt>
<dd>These are the masses for each on of the qPCR measurements. If this is not
specified, then this assumes that the numbers in <code>qpcr</code> are already normalized
by their sample weight.</dd>
<dt><strong><code>dilution_factors</code></strong> :&ensp;<code>numeric, np.ndarray</code></dt>
<dd>These are the dilution factors for each of the qPCR measurements. If this is
not specified, then this assumes that each one of the numbers in <code>qpcr</code> are
already normalized by the dilution factor</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_qpcr(self, timepoints: Union[np.ndarray, int, float], qpcr: np.ndarray, 
    masses: Union[np.ndarray, int, float]=None, dilution_factors: Union[np.ndarray, int, float]=None):
    &#39;&#39;&#39;Add qpcr measurements for timepoints `timepoints`

    Parameters
    ----------
    timepoint : numeric, array
        This is the time that the measurement occurs. If it is an array, then
        we are adding for multiple timepoints
    qpcr : np.ndarray(N_TIMEPOINTS, N_REPLICATES)
        These are the qPCR measurements in order of timepoints. Assumed to be in the 
        same order as timepoints.If timepoints is an array, then we are adding 
        for multiple timepoints. In this case we assume that the rows index the 
        timepoint and the columns index the replicates of the qpcr measurement.
    masses : numeric, np.ndarray
        These are the masses for each on of the qPCR measurements. If this is not 
        specified, then this assumes that the numbers in `qpcr` are already normalized
        by their sample weight.
    dilution_factors : numeric, np.ndarray
        These are the dilution factors for each of the qPCR measurements. If this is
        not specified, then this assumes that each one of the numbers in `qpcr` are
        already normalized by the dilution factor
    &#39;&#39;&#39;
    if not plutil.isarray(timepoints):
        timepoints = [timepoints]
    for timepoint in timepoints:
        if not plutil.isnumeric(timepoint):
            raise TypeError(&#39;`timepoint` ({}) must be a numeric&#39;.format(type(timepoint)))
    if masses is not None:
        if plutil.isnumeric(masses):
            masses = [masses]
        for mass in masses:
            if not plutil.isnumeric(mass):
                raise TypeError(&#39;Each mass in `masses` ({}) must be a numeric&#39;.format(type(mass)))
            if mass &lt;= 0:
                raise ValueError(&#39;Each mass in `masses` ({}) must be &gt; 0&#39;.format(mass))
        if len(masses) != len(timepoints):
            raise ValueError(&#39;Number of timepoints ({}) and number of masses ({}) &#39; \
                &#39;must be equal&#39;.format(len(timepoints), len(masses)))
    if dilution_factors is not None:
        if plutil.isnumeric(dilution_factors):
            dilution_factors = [dilution_factors]
        for dilution_factor in dilution_factors:
            if not plutil.isnumeric(dilution_factor):
                raise TypeError(&#39;Each dilution_factor in `dilution_factors` ({}) &#39; \
                    &#39;must be a numeric&#39;.format(type(dilution_factor)))
            if dilution_factor &lt;= 0:
                raise ValueError(&#39;Each dilution_factor in `dilution_factors` ({}) &#39; \
                    &#39;must be &gt; 0&#39;.format(dilution_factor))
        if len(dilution_factors) != len(timepoints):
            raise ValueError(&#39;Number of timepoints ({}) and number of dilution_factors ({}) &#39; \
                &#39;must be equal&#39;.format(len(timepoints), len(dilution_factors)))
        
    if not plutil.isarray(qpcr):
        raise TypeError(&#39;`qpcr` ({}) must be an array&#39;.format(type(qpcr)))
    if qpcr.ndim == 1:
        qpcr = qpcr.reshape(1,-1)
    if qpcr.ndim != 2:
        raise ValueError(&#39;`qpcr` {} must be a matrix&#39;.format(qpcr.shape))
    if qpcr.shape[0] != len(timepoints):
        raise ValueError(&#39;`qpcr` shape {} does not align with the number of timepoints ({}) &#39; \
            &#39;&#39;.format(qpcr.shape, len(timepoints)))

    for tidx, timepoint in enumerate(timepoints):
        if timepoint in self.qpcr:
            if self.qpcr[timepoint] is not None:
                logging.debug(&#39;There are already qpcr measurements specified at time `{}` for subject `{}`, overwriting&#39;.format(
                    timepoint, self.name))
        if masses is not None:
            mass = masses[tidx]
        else:
            mass = 1
        if dilution_factors is not None:
            dil = dilution_factors[tidx]
        else:
            dil = 1

        self.qpcr[timepoint] = qPCRdata(cfus=qpcr[tidx,:], mass=mass, 
            dilution_factor=dil)
            
        if timepoint not in self.times:
            self.times = np.sort(np.append(self.times, timepoint))
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.add_reads"><code class="name flex">
<span>def <span class="ident">add_reads</span></span>(<span>self, timepoints: Union[numpy.ndarray, int, float], reads: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>Add the reads for timepoint <code>timepoint</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>timepoint</code></strong> :&ensp;<code>numeric, array</code></dt>
<dd>This is the time that the measurement occurs. If it is an array, then
we are adding for multiple timepoints</dd>
<dt><strong><code>reads</code></strong> :&ensp;<code>np.ndarray(N_TAXA, N_TIMEPOINTS)</code></dt>
<dd>These are the reads for the taxa in order. Assumed to be in the
same order as the TaxaSet. If it is a dataframe then we use the rows
to index the taxon names. If timepoints is an array, then we are adding
for multiple timepoints. In this case we assume that the rows index
the
taxon and the columns index the timepoint.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_reads(self, timepoints: Union[np.ndarray, int, float], reads: np.ndarray):
    &#39;&#39;&#39;Add the reads for timepoint `timepoint`

    Parameters
    ----------
    timepoint : numeric, array
        This is the time that the measurement occurs. If it is an array, then
        we are adding for multiple timepoints
    reads : np.ndarray(N_TAXA, N_TIMEPOINTS)
        These are the reads for the taxa in order. Assumed to be in the 
        same order as the TaxaSet. If it is a dataframe then we use the rows
        to index the taxon names. If timepoints is an array, then we are adding 
        for multiple timepoints. In this case we assume that the rows index  the 
        taxon and the columns index the timepoint.
    &#39;&#39;&#39;
    if not plutil.isarray(timepoints):
        timepoints = [timepoints]
    for timepoint in timepoints:
        if not plutil.isnumeric(timepoint):
            raise TypeError(&#39;`timepoint` ({}) must be a numeric&#39;.format(type(timepoint)))
    if not plutil.isarray(reads):
        raise TypeError(&#39;`reads` ({}) must be an array&#39;.format(type(reads)))
    
    if reads.ndim == 1:
        reads = reads.reshape(-1,1)
    if reads.ndim != 2:
        raise ValueError(&#39;`reads` {} must be a matrix&#39;.format(reads.shape))
    if reads.shape[0] != len(self.taxa) or reads.shape[1] != len(timepoints):
        raise ValueError(&#39;`reads` shape {} does not align with the number of taxa ({}) &#39; \
            &#39;or timepoints ({})&#39;.format(reads.shape, len(self.taxa), len(timepoints)))

    for tidx, timepoint in enumerate(timepoints):
        if timepoint in self.reads:
            if self.reads[timepoint] is not None:
                logging.debug(&#39;There are already reads specified at time `{}` for subject `{}`, overwriting&#39;.format(
                    timepoint, self.name))
            
        self.reads[timepoint] = reads[:,tidx]
        if timepoint not in self.times:
            self.times = np.sort(np.append(self.times, timepoint))
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.add_time"><code class="name flex">
<span>def <span class="ident">add_time</span></span>(<span>self, timepoint: Union[float, int])</span>
</code></dt>
<dd>
<div class="desc"><p>Add the timepoint <code>timepoint</code>. Set the reads and qpcr at that timepoint
to None</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>timepoint</code></strong> :&ensp;<code>float, int</code></dt>
<dd>Time point to add</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_time(self, timepoint: Union[float, int]):
    &#39;&#39;&#39;Add the timepoint `timepoint`. Set the reads and qpcr at that timepoint
    to None

    Parameters
    ----------
    timepoint : float, int
        Time point to add
    &#39;&#39;&#39;
    if timepoint in self.times:
        return
    self.times = np.sort(np.append(self.times, timepoint))
    self.reads[timepoint] = None
    self.qpcr[timepoint] = None</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.cluster_by_taxlevel"><code class="name flex">
<span>def <span class="ident">cluster_by_taxlevel</span></span>(<span>self, dtype: str, taxlevel: str, index_formatter: str = None, smart_unspec: bool = True) ‑> Tuple[pandas.core.frame.DataFrame, Dict[str, str]]</span>
</code></dt>
<dd>
<div class="desc"><p>Clusters the taxa into the taxonomic level indicated in <code>taxlevel</code>.</p>
<h2 id="smart-unspecified">Smart Unspecified</h2>
<p>If True, returns the higher taxonomic classification while saying the desired taxonomic level
is unspecified. Example: 'Order ABC, Family NA'. Note that this overrides the <code>index_formatter</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the type of data to cluster. Options are:
'raw': These are the counts
'rel': This is the relative abundances
'abs': This is the absolute abundance (qPCR * rel)</dd>
<dt><strong><code>taxlevel</code></strong> :&ensp;<code>str, None</code></dt>
<dd>This is the taxonomic level to aggregate the data at. If it is
None then we do not do any collapsing (this is the same as 'asv')</dd>
<dt><strong><code>index_formatter</code></strong> :&ensp;<code>str</code></dt>
<dd>How to make the index using <code><a title="mdsine2.pylab.base.taxaname_formatter" href="#mdsine2.pylab.base.taxaname_formatter">taxaname_formatter()</a></code>. Note that you cannot
specify anything at a lower taxonomic level than what youre clustering at. For
example, you cannot cluster at the 'class' level and then specify '%(genus)s'
in the index formatter.
If nothing is specified then only return the specified taxonomic level</dd>
<dt><strong><code>smart_unspec</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, if the taxonomic level is not not specified for that OTU/Taxon, then use the
lowest taxonomic level instead.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>Dataframe of the data</dd>
<dt><code>dict (str-&gt;str)</code></dt>
<dd>Maps taxon name to the row it got allocated to</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cluster_by_taxlevel(self, dtype: str, taxlevel: str, index_formatter: str=None, 
    smart_unspec: bool=True) -&gt; Tuple[pd.DataFrame, Dict[str,str]]:
    &#39;&#39;&#39;Clusters the taxa into the taxonomic level indicated in `taxlevel`.

    Smart Unspecified
    -----------------
    If True, returns the higher taxonomic classification while saying the desired taxonomic level
    is unspecified. Example: &#39;Order ABC, Family NA&#39;. Note that this overrides the `index_formatter`.

    Parameters
    ----------
    dtype : str
        This is the type of data to cluster. Options are:
            &#39;raw&#39;: These are the counts
            &#39;rel&#39;: This is the relative abundances
            &#39;abs&#39;: This is the absolute abundance (qPCR * rel)
    taxlevel : str, None
        This is the taxonomic level to aggregate the data at. If it is 
        None then we do not do any collapsing (this is the same as &#39;asv&#39;)
    index_formatter : str
        How to make the index using `taxaname_formatter`. Note that you cannot
        specify anything at a lower taxonomic level than what youre clustering at. For 
        example, you cannot cluster at the &#39;class&#39; level and then specify &#39;%(genus)s&#39; 
        in the index formatter.
        If nothing is specified then only return the specified taxonomic level
    smart_unspec : bool
        If True, if the taxonomic level is not not specified for that OTU/Taxon, then use the
        lowest taxonomic level instead.

    Returns
    -------
    pandas.DataFrame
        Dataframe of the data
    dict (str-&gt;str)
        Maps taxon name to the row it got allocated to
    &#39;&#39;&#39;
    # Type checking
    if not plutil.isstr(dtype):
        raise TypeError(&#39;`dtype` ({}) must be a str&#39;.format(type(dtype)))
    if dtype not in [&#39;raw&#39;, &#39;rel&#39;, &#39;abs&#39;]:
        raise ValueError(&#39;`dtype` ({}) not recognized&#39;.format(dtype))
    if not plutil.isstr(taxlevel):
        raise TypeError(&#39;`taxlevel` ({}) must be a str&#39;.format(type(taxlevel)))
    if taxlevel not in [&#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;,  &#39;order&#39;, &#39;family&#39;, 
        &#39;genus&#39;, &#39;species&#39;, &#39;asv&#39;]:
        raise ValueError(&#39;`taxlevel` ({}) not recognized&#39;.format(taxlevel))
    if index_formatter is None:
        index_formatter = taxlevel
    if index_formatter is not None:
        if not plutil.isstr(index_formatter):
            raise TypeError(&#39;`index_formatter` ({}) must be a str&#39;.format(type(index_formatter)))
        
        for tx in TAX_IDXS:
            if tx in index_formatter and TAX_IDXS[tx] &gt; TAX_IDXS[taxlevel]:
                raise ValueError(&#39;You are clustering at the {} level but are specifying&#39; \
                    &#39; {} in the `index_formatter`. This does not make sense. Either cluster&#39; \
                    &#39;at a lower tax level or specify the `index_formatter` to a higher tax &#39; \
                    &#39;level&#39;.format(taxlevel, tx))

    index_formatter = index_formatter.replace(&#39;%(asv)s&#39;, &#39;%(name)s&#39;)

    # Everything is valid, get the data dataframe and the return dataframe
    taxaname_map = {}
    df = self.df()[dtype]
    cols = list(df.columns)
    cols.append(taxlevel)
    dfnew = pd.DataFrame(columns = cols).set_index(taxlevel)

    # Get the level in the taxonomy, create a new entry if it is not there already
    taxa = {} # lineage -&gt; label
    for i, taxon in enumerate(self.taxa):
        row = df.index[i]
        tax = taxon.get_lineage(level=taxlevel)
        tax = tuple(tax)
        tax = str(tax).replace(&#34;&#39;&#34;, &#39;&#39;)
        if tax in taxa:
            dfnew.loc[taxa[tax]] += df.loc[row]
        else:
            if not taxon.tax_is_defined(taxlevel) and smart_unspec:
                # Get the least common ancestor above the taxlevel
                taxlevelidx = TAX_IDXS[taxlevel]
                ttt = None
                while taxlevelidx &gt; -1:
                    if taxon.tax_is_defined(TAX_LEVELS[taxlevelidx]):
                        ttt = TAX_LEVELS[taxlevelidx]
                        break
                    taxlevelidx -= 1
                if ttt is None:
                    raise ValueError(&#39;Could not find a single taxlevel: {}&#39;.format(str(taxon)))
                taxa[tax] = &#39;{} {}, {} NA&#39;.format(ttt.capitalize(), 
                    taxon.taxonomy[ttt], taxlevel.capitalize())
            else:
                taxa[tax] = taxaname_formatter(format=index_formatter, taxon=taxon, taxa=self.taxa)
            toadd = pd.DataFrame(np.array(list(df.loc[row])).reshape(1,-1),
                index=[taxa[tax]], columns=dfnew.columns)
            dfnew = dfnew.append(toadd)
        
        if taxa[tax] not in taxaname_map:
            taxaname_map[taxa[tax]] = []
        taxaname_map[taxa[tax]].append(taxon.name)
    
    return dfnew, taxaname_map</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.df"><code class="name flex">
<span>def <span class="ident">df</span></span>(<span>self) ‑> Dict[str, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a dataframe of the data - same as matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def df(self) -&gt; Dict[str, pd.DataFrame]:
    &#39;&#39;&#39;Returns a dataframe of the data - same as matrix
    &#39;&#39;&#39;
    d = self.matrix()
    index = self.taxa.names.order
    times = self.times
    for key in d:
        d[key] = pd.DataFrame(data=d[key], index=index, columns=times)
    return d</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.matrix"><code class="name flex">
<span>def <span class="ident">matrix</span></span>(<span>self) ‑> Dict[str, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Make a numpy matrix out of our data - returns the raw reads,
the relative abundance, and the absolute abundance.</p>
<p>If there is no qPCR data, then the absolute abundance is set to None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def matrix(self) -&gt; Dict[str, np.ndarray]:
    &#39;&#39;&#39;Make a numpy matrix out of our data - returns the raw reads,
    the relative abundance, and the absolute abundance.

    If there is no qPCR data, then the absolute abundance is set to None.
    &#39;&#39;&#39;

    shape = (len(self.taxa), len(self.times))
    raw = np.zeros(shape=shape, dtype=int)
    rel = np.zeros(shape=shape, dtype=float)
    abs = np.zeros(shape=shape, dtype=float)

    for i,t in enumerate(self.times):
        raw[:,i] = self.reads[t]
        rel[:,i] = raw[:,i]/np.sum(raw[:,i])
    
    try:
        for i,t in enumerate(self.times):
            abs[:,i] = rel[:,i] * self.qpcr[t].mean()
    except AttributeError as e:
        logging.info(&#39;Attribute Error ({}) for absolute abundance. This is likely &#39; \
            &#39;because you did not set the qPCR abundances. Skipping `abs`&#39;.format(e))
        abs = None

    return {&#39;raw&#39;:raw, &#39;rel&#39;: rel, &#39;abs&#39;:abs}</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Subject.read_depth"><code class="name flex">
<span>def <span class="ident">read_depth</span></span>(<span>self, t: Union[int, float] = None) ‑> Union[numpy.ndarray, int]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the read depth at time <code>t</code>. If nothing is given then return all
of them</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>t</code></strong> :&ensp;<code>int, float, Optional</code></dt>
<dd>Get the read depth at this time. If nothing is provided, all of the read depths for this
subject are returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_depth(self, t: Union[int, float]=None) -&gt; Union[np.ndarray, int]:
    &#39;&#39;&#39;Get the read depth at time `t`. If nothing is given then return all
    of them

    Parameters
    ----------
    t : int, float, Optional
        Get the read depth at this time. If nothing is provided, all of the read depths for this 
        subject are returned
    &#39;&#39;&#39;
    if t is None:
        return np.sum(self.matrix()[&#39;raw&#39;], axis=0)
    if t not in self.reads:
        raise ValueError(&#39;`t` ({}) not recognized. Valid times: {}&#39;.format(
            t, self.times))
    return np.sum(self.reads[t])</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.base.Saveable.load" href="#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.save" href="#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.set_save_location" href="#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet"><code class="flex name class">
<span>class <span class="ident">TaxaSet</span></span>
<span>(</span><span>taxonomy_table: pandas.core.frame.DataFrame = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Wraps a set of `` objects. You can get the
object via the
id,
name.
Provides functionality for aggregating sequeunces and getting subsets for lineages.</p>
<h2 id="aggregatingdeaggregating">Aggregating/Deaggregating</h2>
<p>s that are aggregated together to become OTUs are used because sequences are
very close together. This class provides functionality for aggregating taxa together
(<code>mdsine2.TaxaSet.aggregate_items</code>) and to deaggregate a specific name from an aggregation
(<code>mdsine2.TaxaSet.deaggregate_item</code>). If this object is within a <code>mdsine2.Study</code> object,
MAKE SURE TO CALL THE AGGREGATION FUNCTIONS FROM THE <code>mdsine2.Study</code> OBJECT
(<code>mdsine2.Study.aggregate_items</code>, <code>mdsine2.Study.deaggregate_item</code>) so that the reads
for the agglomerates and individual taxa can be consistent with the TaxaSet.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>taxonomy_table</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>This is the table defining the set. If this is specified, then it is passed into
TaxaSet.parse</dd>
</dl>
<h2 id="see-also">See Also</h2>
<p><code>mdsine2.TaxaSet.parse</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TaxaSet(Clusterable):
    &#39;&#39;&#39;Wraps a set of `` objects. You can get the  object via the
     id,  name.
    Provides functionality for aggregating sequeunces and getting subsets for lineages.

    Aggregating/Deaggregating
    -------------------------
    s that are aggregated together to become OTUs are used because sequences are 
    very close together. This class provides functionality for aggregating taxa together
    (`mdsine2.TaxaSet.aggregate_items`) and to deaggregate a specific name from an aggregation
    (`mdsine2.TaxaSet.deaggregate_item`). If this object is within a `mdsine2.Study` object,
    MAKE SURE TO CALL THE AGGREGATION FUNCTIONS FROM THE `mdsine2.Study` OBJECT 
    (`mdsine2.Study.aggregate_items`, `mdsine2.Study.deaggregate_item`) so that the reads
    for the agglomerates and individual taxa can be consistent with the TaxaSet.

    Parameters
    ----------
    taxonomy_table : pandas.DataFrame
        This is the table defining the set. If this is specified, then it is passed into
        TaxaSet.parse

    See also
    --------
    mdsine2.TaxaSet.parse
    &#39;&#39;&#39;

    def __init__(self, taxonomy_table: pd.DataFrame=None):
        self.taxonomy_table = taxonomy_table 
        self.ids = CustomOrderedDict() # Effectively a dictionary (id (int) -&gt; OTU or Taxon)
        self.names = CustomOrderedDict() # Effectively a dictionary (name (int) -&gt; OTU or Taxon)
        self.index = [] # List (index (int) -&gt; OTU or Taxon)
        self._len = 0

        # Add all of the taxa from the dataframe if necessary
        if taxonomy_table is not None:
            self.parse(taxonomy_table=taxonomy_table)

    def __contains__(self, key: Union[Taxon, OTU, str, int]) -&gt; bool:
        try:
            self[key]
            return True
        except:
            return False

    def __getitem__(self, key: Union[Taxon, OTU, str, int]):
        &#39;&#39;&#39;Get a Taxon/OTU by either its sequence, name, index, or id

        Parameters
        ----------
        key : str, int
            Key to reference the Taxon
        &#39;&#39;&#39;
        if istaxontype(key):
            return key
        if key in self.ids:
            return self.ids[key]
        elif plutil.isint(key):
            return self.index[key]
        elif key in self.names:
            return self.names[key]
        else:
            raise IndexError(&#39;`{}` ({}) was not found as a name, sequence, index, or id&#39;.format(
                key, type(key)))

    def __iter__(self) -&gt; Union[Taxon, OTU]:
        &#39;&#39;&#39;Returns each Taxa obejct in order
        &#39;&#39;&#39;
        for taxon in self.index:
            yield taxon

    def __len__(self) -&gt; int:
        &#39;&#39;&#39;Return the number of taxa in the TaxaSet
        &#39;&#39;&#39;
        return self._len

    @property
    def n_taxa(self) -&gt; int:
        &#39;&#39;&#39;Alias for __len__
        &#39;&#39;&#39;
        return self._len

    def parse(self, taxonomy_table: pd.DataFrame):
        &#39;&#39;&#39;Parse a taxonomy table

        `taxonomy_table`
        ----------------
        This is a dataframe that contains the taxonomic information for each Taxon.
        The columns that must be included are:
            &#39;name&#39; : name of the taxon
            &#39;sequence&#39; : sequence of the taxon
        All of the taxonomy specifications are optional:
            &#39;kingdom&#39; : kingdom taxonomy
            &#39;phylum&#39; : phylum taxonomy
            &#39;class&#39; : class taxonomy
            &#39;family&#39; : family taxonomy
            &#39;genus&#39; : genus taxonomy
            &#39;species&#39; : species taxonomy

        Note that if the `name` column is not in the columns, this assumes that the
        OTU names are the index already.

        Parameters
        ----------
        taxonomy_table : pandas.DataFrame, Optional
            DataFrame containing the required information (Taxonomy, sequence).
            If nothing is passed in, it will be an empty TaxaSet
        &#39;&#39;&#39;
        logging.info(&#39;TaxaSet parsng new taxonomy table. Resetting&#39;)
        self.taxonomy_table = taxonomy_table
        self.ids = CustomOrderedDict()
        self.names = CustomOrderedDict()
        self.index = []
        self._len = 0

        self.taxonomy_table = taxonomy_table
        taxonomy_table = taxonomy_table.rename(str.lower, axis=&#39;columns&#39;)
        if &#39;name&#39; not in taxonomy_table.columns:
            logging.info(&#39;No `name` found - assuming index is the name&#39;)
        else:
            taxonomy_table = taxonomy_table.set_index(&#39;name&#39;)
        if SEQUENCE_COLUMN_LABEL not in taxonomy_table.columns:
            raise ValueError(&#39;`&#34;{}&#34;` ({}) not found as a column in `taxonomy_table`&#39;.format(
                SEQUENCE_COLUMN_LABEL, taxonomy_table.columns))

        for tax in TAX_LEVELS[:-1]:
            if tax not in taxonomy_table.columns:
                logging.info(&#39;Adding in `{}` column&#39;.format(tax))
                taxonomy_table = taxonomy_table.insert(-1, tax, 
                    [DEFAULT_TAXLEVEL_NAME for _ in range(len(taxonomy_table.index))])

        for i, name in enumerate(taxonomy_table.index):
            seq = taxonomy_table[SEQUENCE_COLUMN_LABEL][name]
            taxon = Taxon(name=name, sequence=seq, idx=self._len)
            taxon.set_taxonomy(
                tax_kingdom=taxonomy_table.loc[name][&#39;kingdom&#39;],
                tax_phylum=taxonomy_table.loc[name][&#39;phylum&#39;],
                tax_class=taxonomy_table.loc[name][&#39;class&#39;],
                tax_order=taxonomy_table.loc[name][&#39;order&#39;],
                tax_family=taxonomy_table.loc[name][&#39;family&#39;],
                tax_genus=taxonomy_table.loc[name][&#39;genus&#39;],
                tax_species=taxonomy_table.loc[name][&#39;species&#39;])

            self.ids[taxon.id] = taxon
            self.names[taxon.name] = taxon
            self.index.append(taxon)  
            self._len += 1

        self.ids.update_order()
        self.names.update_order()

    def add_taxon(self, name: str, sequence: Iterator[str]=None):
        &#39;&#39;&#39;Adds a taxon to the set

        Parameters
        ----------
        name : str
            This is the name of the taxon
        sequence : str
            This is the sequence of the taxon
        &#39;&#39;&#39;
        taxon = Taxon(name=name, sequence=sequence, idx=self._len)
        self.ids[taxon.id] = taxon
        self.names[taxon.name] = taxon
        self.index.append(taxon)

        # update the order of the taxa
        self.ids.update_order()
        self.names.update_order()
        self._len += 1

        return self

    def del_taxon(self, taxon: Union[Taxon, OTU, str, int]):
        &#39;&#39;&#39;Deletes the taxon from the set.

        Parameters
        ----------
        taxon : str, int, Taxon
            Can either be the name, sequence, or the ID of the taxon
        &#39;&#39;&#39;
        # Get the ID
        taxon = self[taxon]
        oidx = self.ids.index[taxon.id]

        # Delete the taxon from everything
        # taxon = self[taxon]
        self.ids.pop(taxon.id, None)
        self.names.pop(taxon.name, None)
        self.index.pop(oidx)

        # update the order of the taxa
        self.ids.update_order()
        self.names.update_order()

        # Update the indices of the taxa
        # Since everything points to the same object we only need to do it once
        for aidx, taxon in enumerate(self.index):
            taxon.idx = aidx

        self._len -= 1
        return self

    def taxonomic_similarity(self, 
        oid1: Union[Taxon, OTU, str, int], 
        oid2: Union[Taxon, OTU, str, int]) -&gt; float:
        &#39;&#39;&#39;Calculate the taxonomic similarity between taxon1 and taxon2
        Iterates through most broad to least broad taxonomic level and
        returns the fraction that are the same.

        Example:
            taxon1.taxonomy = (A,B,C,D)
            taxon2.taxonomy = (A,B,E,F)
            similarity = 0.5

            taxon1.taxonomy = (A,B,C,D)
            taxon2.taxonomy = (A,B,C,F)
            similarity = 0.75

            taxon1.taxonomy = (A,B,C,D)
            taxon2.taxonomy = (A,B,C,D)
            similarity = 1.0

            taxon1.taxonomy = (X,Y,Z,M)
            taxon2.taxonomy = (A,B,E,F)
            similarity = 0.0

        Parameters
        ----------
        oid1, oid2 : str, int
            The name, id, or sequence for the taxon
        &#39;&#39;&#39;
        if oid1 == oid2:
            return 1
        taxon1 = self[oid1].get_lineage()
        taxon2 = self[oid2].get_lineage()
        i = 0
        for a in taxon1:
            if a == taxon2[i]:
                i += 1
            else:
                break
        return i/8 # including asv

    def aggregate_items(self, anchor: Union[Taxon, OTU, str, int], other: Union[Taxon, OTU, str, int]):
        &#39;&#39;&#39;Create an OTU with the anchor `anchor` and other taxon  `other`.
        The aggregate takes the sequence and the taxonomy from the anchor.

        Parameters
        ----------
        anchor, other : str, int, mdsine2.Taxon, mdsine2.OTU
            These are the Taxa/Aggregates that you&#39;re joining together. The anchor is
            the one you are setting the sequeunce and taxonomy to

        Returns
        -------
        mdsine2.OTU
            This is the new aggregated taxon containing anchor and other
        &#39;&#39;&#39;
        anchor = self[anchor]
        other = self[other]
        
        agg = OTU(anchor=anchor, other=other)

        self.index[agg.idx] = agg
        self.index.pop(other.idx)

        self.ids = CustomOrderedDict()
        self.names = CustomOrderedDict()

        for idx, taxon in enumerate(self.index):
            taxon.idx = idx
            self.ids[taxon.id] = taxon
            self.names[taxon.name] = taxon
        
        # update the order of the taxa
        self.ids.update_order()
        self.names.update_order()

        self._len = len(self.index)
        return agg

    def deaggregate_item(self, agg: Union[Taxon, OTU, str, int], other: str) -&gt; Taxon:
        &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
        `other` is then appended to the end 

        Parameters
        ----------
        agg : OTU, str
            This is an OTU with multiple sequences contained. Must 
            have the name `other` in there
        other : str
            This is the name of the taxon that should be taken out of `agg`

        Returns
        -------
        mdsine2.Taxon
            This is the deaggregated taxon
        &#39;&#39;&#39;
        agg = self[agg]
        if not isotu(agg):
            raise TypeError(&#39;`agg` ({}) must be an OTU&#39;.format(type(agg)))
        if not plutil.isstr(other):
            raise TypeError(&#39;`other` ({}) must be a str&#39;.format(type(other)))
        if other not in agg.aggregated_taxa:
            raise ValueError(&#39;`other` ({}) is not contained in `agg` ({}) ({})&#39;.format(
                other, agg.name, agg.aggregated_taxa))

        other = Taxon(name=other, sequence=agg.aggregated_seqs[other], idx=self._len)
        other.taxonomy = agg.aggregated_taxonomies[other.name]
        agg.aggregated_seqs.pop(other.name, None)
        agg.aggregated_taxa.remove(other.name)
        agg.aggregated_taxonomies.pop(other.name, None)

        self.index.append(other)
        self.ids[other.id] = other
        self.names[other.name] = other

        self.ids.update_order()
        self.names.update_order()
        self._len += 1
        return other

    def rename(self, prefix: str, zero_based_index: bool=False):
        &#39;&#39;&#39;Rename the contents based on their index:

        Example
        -------
        Names before in order:
        [Taxon_22, Taxon_9982, TUDD_8484]

        Calling taxa.rename(prefix=&#39;OTU&#39;)
        New names:
        [OTU_1, OTU_2, OTU_3]

        Calling taxa.rename(prefix=&#39;OTU&#39;, zero_based_index=True)
        New names:
        [OTU_0, OTU_1, OTU_2]

        Parameters
        ----------
        prefix : str
            This is the prefix of the new taxon. The name of the taxa will change
            to `&#39;{}_{}&#39;.format(prefix, index)`
        zero_based_index : bool
            If this is False, then we start the enumeration of the taxa from 1
            instead of 0. If True, then the enumeration starts at 0
        &#39;&#39;&#39;
        if not plutil.isstr(prefix):
            raise TypeError(&#39;`prefix` ({}) must be a str&#39;.format(type(prefix)))
        if not plutil.isbool(zero_based_index):
            raise TypeError(&#39;`zero_based_index` ({}) must be a bool&#39;.format(
                type(zero_based_index)))

        offset = 0
        if not zero_based_index:
            offset = 1

        self.names = CustomOrderedDict()
        for taxon in self.index:
            newname = prefix + &#39;_{}&#39;.format(int(taxon.idx + offset))
            taxon.name = newname
            self.names[taxon.name] = taxon

    def generate_consensus_seqs(self, threshold: float=0.65, noconsensus_char: str=&#39;N&#39;):
        &#39;&#39;&#39;Generate the consensus sequence for all of the taxa given the sequences
        of all the contained ASVs of the respective OTUs

        Parameters
        ----------
        threshold : float
            This is the threshold for consensus (0 &lt; threshold &lt;= 1)
        noconsensus_char : str
            This is the character to replace
        &#39;&#39;&#39;
        for taxon in self:
            if isotu(taxon):
                taxon.generate_consensus_seq(
                    threshold=threshold, 
                    noconsensus_char=noconsensus_char)

    def generate_consensus_taxonomies(self, consensus_table: pd.DataFrame=None):
        &#39;&#39;&#39;Generates the consensus taxonomies for all of the OTUs within the TaxaSet.
        For details on the algorithm - see `OTU.generate_consensus_taxonomy`

        See Also
        --------
        mdsine2.pylab.base.OTU.generate_consensus_taxonomy
        &#39;&#39;&#39;
        for taxon in self:
            if isotu(taxon):
                taxon.generate_consensus_taxonomy(consensus_table=consensus_table)

    def write_taxonomy_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
        &#39;&#39;&#39;Write the taxon names, sequences, and taxonomy to a table. If a path
        is passed in, then write to that table

        Parameters
        ----------
        path : str
            This is the location to save the metadata file
        sep : str
            This is the separator of the table
        &#39;&#39;&#39;
        columns = [&#39;name&#39;, &#39;sequence&#39;, &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;, &#39;species&#39;]
        data = []

        for taxon in self:
            temp = [taxon.name, taxon.sequence]
            for taxlevel in TAX_LEVELS[:-1]:
                temp.append(taxon.taxonomy[taxlevel])
            data.append(temp)
        
        df = pd.DataFrame(data, columns=columns)
        if path is not None:
            df.to_csv(path, sep=sep, index=False, header=True)
        return df</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.Clusterable" href="#mdsine2.pylab.base.Clusterable">Clusterable</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="mdsine2.pylab.base.TaxaSet.n_taxa"><code class="name">var <span class="ident">n_taxa</span> : int</code></dt>
<dd>
<div class="desc"><p>Alias for <strong>len</strong></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def n_taxa(self) -&gt; int:
    &#39;&#39;&#39;Alias for __len__
    &#39;&#39;&#39;
    return self._len</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.TaxaSet.add_taxon"><code class="name flex">
<span>def <span class="ident">add_taxon</span></span>(<span>self, name: str, sequence: Iterator[str] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a taxon to the set</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the name of the taxon</dd>
<dt><strong><code>sequence</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the sequence of the taxon</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_taxon(self, name: str, sequence: Iterator[str]=None):
    &#39;&#39;&#39;Adds a taxon to the set

    Parameters
    ----------
    name : str
        This is the name of the taxon
    sequence : str
        This is the sequence of the taxon
    &#39;&#39;&#39;
    taxon = Taxon(name=name, sequence=sequence, idx=self._len)
    self.ids[taxon.id] = taxon
    self.names[taxon.name] = taxon
    self.index.append(taxon)

    # update the order of the taxa
    self.ids.update_order()
    self.names.update_order()
    self._len += 1

    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.aggregate_items"><code class="name flex">
<span>def <span class="ident">aggregate_items</span></span>(<span>self, anchor: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str, int], other: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str, int])</span>
</code></dt>
<dd>
<div class="desc"><p>Create an OTU with the anchor <code>anchor</code> and other taxon
<code>other</code>.
The aggregate takes the sequence and the taxonomy from the anchor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>anchor</code></strong>, <strong><code>other</code></strong> :&ensp;<code>str, int, mdsine2.Taxon, mdsine2.OTU</code></dt>
<dd>These are the Taxa/Aggregates that you're joining together. The anchor is
the one you are setting the sequeunce and taxonomy to</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.OTU</code></dt>
<dd>This is the new aggregated taxon containing anchor and other</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_items(self, anchor: Union[Taxon, OTU, str, int], other: Union[Taxon, OTU, str, int]):
    &#39;&#39;&#39;Create an OTU with the anchor `anchor` and other taxon  `other`.
    The aggregate takes the sequence and the taxonomy from the anchor.

    Parameters
    ----------
    anchor, other : str, int, mdsine2.Taxon, mdsine2.OTU
        These are the Taxa/Aggregates that you&#39;re joining together. The anchor is
        the one you are setting the sequeunce and taxonomy to

    Returns
    -------
    mdsine2.OTU
        This is the new aggregated taxon containing anchor and other
    &#39;&#39;&#39;
    anchor = self[anchor]
    other = self[other]
    
    agg = OTU(anchor=anchor, other=other)

    self.index[agg.idx] = agg
    self.index.pop(other.idx)

    self.ids = CustomOrderedDict()
    self.names = CustomOrderedDict()

    for idx, taxon in enumerate(self.index):
        taxon.idx = idx
        self.ids[taxon.id] = taxon
        self.names[taxon.name] = taxon
    
    # update the order of the taxa
    self.ids.update_order()
    self.names.update_order()

    self._len = len(self.index)
    return agg</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.deaggregate_item"><code class="name flex">
<span>def <span class="ident">deaggregate_item</span></span>(<span>self, agg: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str, int], other: str) ‑> <a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a></span>
</code></dt>
<dd>
<div class="desc"><p>Deaggregate the sequence <code>other</code> from OTU <code>agg</code>.
<code>other</code> is then appended to the end </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>agg</code></strong> :&ensp;<code><a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str</code></dt>
<dd>This is an OTU with multiple sequences contained. Must
have the name <code>other</code> in there</dd>
<dt><strong><code>other</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the name of the taxon that should be taken out of <code>agg</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.Taxon</code></dt>
<dd>This is the deaggregated taxon</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deaggregate_item(self, agg: Union[Taxon, OTU, str, int], other: str) -&gt; Taxon:
    &#39;&#39;&#39;Deaggregate the sequence `other` from OTU `agg`.
    `other` is then appended to the end 

    Parameters
    ----------
    agg : OTU, str
        This is an OTU with multiple sequences contained. Must 
        have the name `other` in there
    other : str
        This is the name of the taxon that should be taken out of `agg`

    Returns
    -------
    mdsine2.Taxon
        This is the deaggregated taxon
    &#39;&#39;&#39;
    agg = self[agg]
    if not isotu(agg):
        raise TypeError(&#39;`agg` ({}) must be an OTU&#39;.format(type(agg)))
    if not plutil.isstr(other):
        raise TypeError(&#39;`other` ({}) must be a str&#39;.format(type(other)))
    if other not in agg.aggregated_taxa:
        raise ValueError(&#39;`other` ({}) is not contained in `agg` ({}) ({})&#39;.format(
            other, agg.name, agg.aggregated_taxa))

    other = Taxon(name=other, sequence=agg.aggregated_seqs[other], idx=self._len)
    other.taxonomy = agg.aggregated_taxonomies[other.name]
    agg.aggregated_seqs.pop(other.name, None)
    agg.aggregated_taxa.remove(other.name)
    agg.aggregated_taxonomies.pop(other.name, None)

    self.index.append(other)
    self.ids[other.id] = other
    self.names[other.name] = other

    self.ids.update_order()
    self.names.update_order()
    self._len += 1
    return other</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.del_taxon"><code class="name flex">
<span>def <span class="ident">del_taxon</span></span>(<span>self, taxon: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str, int])</span>
</code></dt>
<dd>
<div class="desc"><p>Deletes the taxon from the set.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>taxon</code></strong> :&ensp;<code>str, int, <a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a></code></dt>
<dd>Can either be the name, sequence, or the ID of the taxon</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def del_taxon(self, taxon: Union[Taxon, OTU, str, int]):
    &#39;&#39;&#39;Deletes the taxon from the set.

    Parameters
    ----------
    taxon : str, int, Taxon
        Can either be the name, sequence, or the ID of the taxon
    &#39;&#39;&#39;
    # Get the ID
    taxon = self[taxon]
    oidx = self.ids.index[taxon.id]

    # Delete the taxon from everything
    # taxon = self[taxon]
    self.ids.pop(taxon.id, None)
    self.names.pop(taxon.name, None)
    self.index.pop(oidx)

    # update the order of the taxa
    self.ids.update_order()
    self.names.update_order()

    # Update the indices of the taxa
    # Since everything points to the same object we only need to do it once
    for aidx, taxon in enumerate(self.index):
        taxon.idx = aidx

    self._len -= 1
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.generate_consensus_seqs"><code class="name flex">
<span>def <span class="ident">generate_consensus_seqs</span></span>(<span>self, threshold: float = 0.65, noconsensus_char: str = 'N')</span>
</code></dt>
<dd>
<div class="desc"><p>Generate the consensus sequence for all of the taxa given the sequences
of all the contained ASVs of the respective OTUs</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>This is the threshold for consensus (0 &lt; threshold &lt;= 1)</dd>
<dt><strong><code>noconsensus_char</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the character to replace</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_consensus_seqs(self, threshold: float=0.65, noconsensus_char: str=&#39;N&#39;):
    &#39;&#39;&#39;Generate the consensus sequence for all of the taxa given the sequences
    of all the contained ASVs of the respective OTUs

    Parameters
    ----------
    threshold : float
        This is the threshold for consensus (0 &lt; threshold &lt;= 1)
    noconsensus_char : str
        This is the character to replace
    &#39;&#39;&#39;
    for taxon in self:
        if isotu(taxon):
            taxon.generate_consensus_seq(
                threshold=threshold, 
                noconsensus_char=noconsensus_char)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.generate_consensus_taxonomies"><code class="name flex">
<span>def <span class="ident">generate_consensus_taxonomies</span></span>(<span>self, consensus_table: pandas.core.frame.DataFrame = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates the consensus taxonomies for all of the OTUs within the TaxaSet.
For details on the algorithm - see <code><a title="mdsine2.pylab.base.OTU.generate_consensus_taxonomy" href="#mdsine2.pylab.base.OTU.generate_consensus_taxonomy">OTU.generate_consensus_taxonomy()</a></code></p>
<h2 id="see-also">See Also</h2>
<p><code><a title="mdsine2.pylab.base.OTU.generate_consensus_taxonomy" href="#mdsine2.pylab.base.OTU.generate_consensus_taxonomy">OTU.generate_consensus_taxonomy()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_consensus_taxonomies(self, consensus_table: pd.DataFrame=None):
    &#39;&#39;&#39;Generates the consensus taxonomies for all of the OTUs within the TaxaSet.
    For details on the algorithm - see `OTU.generate_consensus_taxonomy`

    See Also
    --------
    mdsine2.pylab.base.OTU.generate_consensus_taxonomy
    &#39;&#39;&#39;
    for taxon in self:
        if isotu(taxon):
            taxon.generate_consensus_taxonomy(consensus_table=consensus_table)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.parse"><code class="name flex">
<span>def <span class="ident">parse</span></span>(<span>self, taxonomy_table: pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse a taxonomy table</p>
<h2 id="taxonomy_table"><code>taxonomy_table</code></h2>
<p>This is a dataframe that contains the taxonomic information for each Taxon.
The columns that must be included are:
'name' : name of the taxon
'sequence' : sequence of the taxon
All of the taxonomy specifications are optional:
'kingdom' : kingdom taxonomy
'phylum' : phylum taxonomy
'class' : class taxonomy
'family' : family taxonomy
'genus' : genus taxonomy
'species' : species taxonomy</p>
<p>Note that if the <code>name</code> column is not in the columns, this assumes that the
OTU names are the index already.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>taxonomy_table</code></strong> :&ensp;<code>pandas.DataFrame, Optional</code></dt>
<dd>DataFrame containing the required information (Taxonomy, sequence).
If nothing is passed in, it will be an empty TaxaSet</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse(self, taxonomy_table: pd.DataFrame):
    &#39;&#39;&#39;Parse a taxonomy table

    `taxonomy_table`
    ----------------
    This is a dataframe that contains the taxonomic information for each Taxon.
    The columns that must be included are:
        &#39;name&#39; : name of the taxon
        &#39;sequence&#39; : sequence of the taxon
    All of the taxonomy specifications are optional:
        &#39;kingdom&#39; : kingdom taxonomy
        &#39;phylum&#39; : phylum taxonomy
        &#39;class&#39; : class taxonomy
        &#39;family&#39; : family taxonomy
        &#39;genus&#39; : genus taxonomy
        &#39;species&#39; : species taxonomy

    Note that if the `name` column is not in the columns, this assumes that the
    OTU names are the index already.

    Parameters
    ----------
    taxonomy_table : pandas.DataFrame, Optional
        DataFrame containing the required information (Taxonomy, sequence).
        If nothing is passed in, it will be an empty TaxaSet
    &#39;&#39;&#39;
    logging.info(&#39;TaxaSet parsng new taxonomy table. Resetting&#39;)
    self.taxonomy_table = taxonomy_table
    self.ids = CustomOrderedDict()
    self.names = CustomOrderedDict()
    self.index = []
    self._len = 0

    self.taxonomy_table = taxonomy_table
    taxonomy_table = taxonomy_table.rename(str.lower, axis=&#39;columns&#39;)
    if &#39;name&#39; not in taxonomy_table.columns:
        logging.info(&#39;No `name` found - assuming index is the name&#39;)
    else:
        taxonomy_table = taxonomy_table.set_index(&#39;name&#39;)
    if SEQUENCE_COLUMN_LABEL not in taxonomy_table.columns:
        raise ValueError(&#39;`&#34;{}&#34;` ({}) not found as a column in `taxonomy_table`&#39;.format(
            SEQUENCE_COLUMN_LABEL, taxonomy_table.columns))

    for tax in TAX_LEVELS[:-1]:
        if tax not in taxonomy_table.columns:
            logging.info(&#39;Adding in `{}` column&#39;.format(tax))
            taxonomy_table = taxonomy_table.insert(-1, tax, 
                [DEFAULT_TAXLEVEL_NAME for _ in range(len(taxonomy_table.index))])

    for i, name in enumerate(taxonomy_table.index):
        seq = taxonomy_table[SEQUENCE_COLUMN_LABEL][name]
        taxon = Taxon(name=name, sequence=seq, idx=self._len)
        taxon.set_taxonomy(
            tax_kingdom=taxonomy_table.loc[name][&#39;kingdom&#39;],
            tax_phylum=taxonomy_table.loc[name][&#39;phylum&#39;],
            tax_class=taxonomy_table.loc[name][&#39;class&#39;],
            tax_order=taxonomy_table.loc[name][&#39;order&#39;],
            tax_family=taxonomy_table.loc[name][&#39;family&#39;],
            tax_genus=taxonomy_table.loc[name][&#39;genus&#39;],
            tax_species=taxonomy_table.loc[name][&#39;species&#39;])

        self.ids[taxon.id] = taxon
        self.names[taxon.name] = taxon
        self.index.append(taxon)  
        self._len += 1

    self.ids.update_order()
    self.names.update_order()</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.rename"><code class="name flex">
<span>def <span class="ident">rename</span></span>(<span>self, prefix: str, zero_based_index: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Rename the contents based on their index:</p>
<h2 id="example">Example</h2>
<p>Names before in order:
[Taxon_22, Taxon_9982, TUDD_8484]</p>
<p>Calling taxa.rename(prefix='OTU')
New names:
[OTU_1, OTU_2, OTU_3]</p>
<p>Calling taxa.rename(prefix='OTU', zero_based_index=True)
New names:
[OTU_0, OTU_1, OTU_2]</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>prefix</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the prefix of the new taxon. The name of the taxa will change
to <code>'{}_{}'.format(prefix, index)</code></dd>
<dt><strong><code>zero_based_index</code></strong> :&ensp;<code>bool</code></dt>
<dd>If this is False, then we start the enumeration of the taxa from 1
instead of 0. If True, then the enumeration starts at 0</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rename(self, prefix: str, zero_based_index: bool=False):
    &#39;&#39;&#39;Rename the contents based on their index:

    Example
    -------
    Names before in order:
    [Taxon_22, Taxon_9982, TUDD_8484]

    Calling taxa.rename(prefix=&#39;OTU&#39;)
    New names:
    [OTU_1, OTU_2, OTU_3]

    Calling taxa.rename(prefix=&#39;OTU&#39;, zero_based_index=True)
    New names:
    [OTU_0, OTU_1, OTU_2]

    Parameters
    ----------
    prefix : str
        This is the prefix of the new taxon. The name of the taxa will change
        to `&#39;{}_{}&#39;.format(prefix, index)`
    zero_based_index : bool
        If this is False, then we start the enumeration of the taxa from 1
        instead of 0. If True, then the enumeration starts at 0
    &#39;&#39;&#39;
    if not plutil.isstr(prefix):
        raise TypeError(&#39;`prefix` ({}) must be a str&#39;.format(type(prefix)))
    if not plutil.isbool(zero_based_index):
        raise TypeError(&#39;`zero_based_index` ({}) must be a bool&#39;.format(
            type(zero_based_index)))

    offset = 0
    if not zero_based_index:
        offset = 1

    self.names = CustomOrderedDict()
    for taxon in self.index:
        newname = prefix + &#39;_{}&#39;.format(int(taxon.idx + offset))
        taxon.name = newname
        self.names[taxon.name] = taxon</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.taxonomic_similarity"><code class="name flex">
<span>def <span class="ident">taxonomic_similarity</span></span>(<span>self, oid1: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str, int], oid2: Union[<a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a>, <a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a>, str, int]) ‑> float</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the taxonomic similarity between taxon1 and taxon2
Iterates through most broad to least broad taxonomic level and
returns the fraction that are the same.</p>
<h2 id="example">Example</h2>
<p>taxon1.taxonomy = (A,B,C,D)
taxon2.taxonomy = (A,B,E,F)
similarity = 0.5</p>
<p>taxon1.taxonomy = (A,B,C,D)
taxon2.taxonomy = (A,B,C,F)
similarity = 0.75</p>
<p>taxon1.taxonomy = (A,B,C,D)
taxon2.taxonomy = (A,B,C,D)
similarity = 1.0</p>
<p>taxon1.taxonomy = (X,Y,Z,M)
taxon2.taxonomy = (A,B,E,F)
similarity = 0.0</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>oid1</code></strong>, <strong><code>oid2</code></strong> :&ensp;<code>str, int</code></dt>
<dd>The name, id, or sequence for the taxon</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def taxonomic_similarity(self, 
    oid1: Union[Taxon, OTU, str, int], 
    oid2: Union[Taxon, OTU, str, int]) -&gt; float:
    &#39;&#39;&#39;Calculate the taxonomic similarity between taxon1 and taxon2
    Iterates through most broad to least broad taxonomic level and
    returns the fraction that are the same.

    Example:
        taxon1.taxonomy = (A,B,C,D)
        taxon2.taxonomy = (A,B,E,F)
        similarity = 0.5

        taxon1.taxonomy = (A,B,C,D)
        taxon2.taxonomy = (A,B,C,F)
        similarity = 0.75

        taxon1.taxonomy = (A,B,C,D)
        taxon2.taxonomy = (A,B,C,D)
        similarity = 1.0

        taxon1.taxonomy = (X,Y,Z,M)
        taxon2.taxonomy = (A,B,E,F)
        similarity = 0.0

    Parameters
    ----------
    oid1, oid2 : str, int
        The name, id, or sequence for the taxon
    &#39;&#39;&#39;
    if oid1 == oid2:
        return 1
    taxon1 = self[oid1].get_lineage()
    taxon2 = self[oid2].get_lineage()
    i = 0
    for a in taxon1:
        if a == taxon2[i]:
            i += 1
        else:
            break
    return i/8 # including asv</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.TaxaSet.write_taxonomy_to_csv"><code class="name flex">
<span>def <span class="ident">write_taxonomy_to_csv</span></span>(<span>self, path: str = None, sep: str = '\t') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Write the taxon names, sequences, and taxonomy to a table. If a path
is passed in, then write to that table</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the location to save the metadata file</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the separator of the table</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_taxonomy_to_csv(self, path: str=None, sep:str=&#39;\t&#39;) -&gt; pd.DataFrame:
    &#39;&#39;&#39;Write the taxon names, sequences, and taxonomy to a table. If a path
    is passed in, then write to that table

    Parameters
    ----------
    path : str
        This is the location to save the metadata file
    sep : str
        This is the separator of the table
    &#39;&#39;&#39;
    columns = [&#39;name&#39;, &#39;sequence&#39;, &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;, &#39;species&#39;]
    data = []

    for taxon in self:
        temp = [taxon.name, taxon.sequence]
        for taxlevel in TAX_LEVELS[:-1]:
            temp.append(taxon.taxonomy[taxlevel])
        data.append(temp)
    
    df = pd.DataFrame(data, columns=columns)
    if path is not None:
        df.to_csv(path, sep=sep, index=False, header=True)
    return df</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.base.Clusterable" href="#mdsine2.pylab.base.Clusterable">Clusterable</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.base.Clusterable.load" href="#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.base.Clusterable.save" href="#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.base.Clusterable.set_save_location" href="#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.pylab.base.Taxon"><code class="flex name class">
<span>class <span class="ident">Taxon</span></span>
<span>(</span><span>name: str, idx: int, sequence: Iterator[str] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper class for a single Taxon</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name given to the Taxon</dd>
<dt><strong><code>sequence</code></strong> :&ensp;<code>str</code></dt>
<dd>Base Pair sequence</dd>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>The index that the asv occurs</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Taxon(ClusterItem):
    &#39;&#39;&#39;Wrapper class for a single Taxon

    Parameters
    ----------
    name : str
        Name given to the Taxon
    sequence : str
        Base Pair sequence
    idx : int
        The index that the asv occurs
    &#39;&#39;&#39;
    def __init__(self, name: str, idx: int, sequence: Iterator[str]=None):
        ClusterItem.__init__(self, name=name)
        self.sequence = sequence
        self.idx = idx
        # Initialize the taxonomies to nothing
        self.taxonomy = {
            &#39;kingdom&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;phylum&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;class&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;order&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;family&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;genus&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;species&#39;: DEFAULT_TAXLEVEL_NAME,
            &#39;asv&#39;: self.name}
        self.id = id(self)

    def __eq__(self, val: Any) -&gt; bool:
        &#39;&#39;&#39;Compares different taxa between each other. Checks all of the attributes but the id

        Parameters
        ----------
        val : any
            This is what we are checking if they are equivalent
        &#39;&#39;&#39;
        if not istaxon(val):
            return False
        if self.name != val.name:
            return False
        if self.sequence != val.sequence:
            return False
        for k,v in self.taxonomy.items():
            if v != val.taxonomy[k]:
                return False
        return True

    def __str__(self) -&gt; str:
        return &#39;Taxon\n\tid: {}\n\tidx: {}\n\tname: {}\n&#39; \
            &#39;\ttaxonomy:\n\t\tkingdom: {}\n\t\tphylum: {}\n&#39; \
            &#39;\t\tclass: {}\n\t\torder: {}\n\t\tfamily: {}\n&#39; \
            &#39;\t\tgenus: {}\n\t\tspecies: {}&#39;.format(
            self.id, self.idx, self.name,
            self.taxonomy[&#39;kingdom&#39;], self.taxonomy[&#39;phylum&#39;],
            self.taxonomy[&#39;class&#39;], self.taxonomy[&#39;order&#39;],
            self.taxonomy[&#39;family&#39;], self.taxonomy[&#39;genus&#39;],
            self.taxonomy[&#39;species&#39;])

    def set_taxonomy(self, tax_kingdom: str=None, tax_phylum: str=None, tax_class: str=None,
        tax_order: str=None, tax_family: str=None, tax_genus: str=None, tax_species: str=None):
        &#39;&#39;&#39;Sets the taxonomy of the parts that are specified

        Parameters
        ----------
        tax_kingdom, tax_phylum, tax_class, tax_order, tax_family, tax_genus : str
            &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;
            Name of the taxon for each respective level
        &#39;&#39;&#39;
        if tax_kingdom is not None and tax_kingdom != &#39;&#39; and plutil.isstr(tax_kingdom):
            self.taxonomy[&#39;kingdom&#39;] = tax_kingdom
        if tax_phylum is not None and tax_phylum != &#39;&#39; and plutil.isstr(tax_phylum):
            self.taxonomy[&#39;phylum&#39;] = tax_phylum
        if tax_class is not None and tax_class != &#39;&#39; and plutil.isstr(tax_class):
            self.taxonomy[&#39;class&#39;] = tax_class
        if tax_order is not None and tax_order != &#39;&#39; and plutil.isstr(tax_order):
            self.taxonomy[&#39;order&#39;] = tax_order
        if tax_family is not None and tax_family != &#39;&#39; and plutil.isstr(tax_family):
            self.taxonomy[&#39;family&#39;] = tax_family
        if tax_genus is not None and tax_genus != &#39;&#39; and plutil.isstr(tax_genus):
            self.taxonomy[&#39;genus&#39;] = tax_genus
        if tax_species is not None and tax_species != &#39;&#39; and plutil.isstr(tax_species):
            self.taxonomy[&#39;species&#39;] = tax_species
        return self

    def get_lineage(self, level: str=None) -&gt; Iterator[str]:
        &#39;&#39;&#39;Returns a tuple of the lineage in order from Kingdom to the level
        indicated. Default value for level is `asv`.
        Parameters
        ----------
        level : str, Optional
            The taxonomic level you want the lineage until
            If nothing is provided, it returns the entire taxonomic lineage
            Example:
                level = &#39;class&#39;
                returns a tuple of (kingdom, phylum, class)
        Returns
        -------
        str
        &#39;&#39;&#39;
        a =  (self.taxonomy[&#39;kingdom&#39;], self.taxonomy[&#39;phylum&#39;], self.taxonomy[&#39;class&#39;],
            self.taxonomy[&#39;order&#39;], self.taxonomy[&#39;family&#39;], self.taxonomy[&#39;genus&#39;],
            self.taxonomy[&#39;species&#39;], self.taxonomy[&#39;asv&#39;])

        if level is None:
            a = a
        if level == &#39;asv&#39;:
            a = a
        elif level == &#39;species&#39;:
            a = a[:-1]
        elif level == &#39;genus&#39;:
            a = a[:-2]
        elif level == &#39;family&#39;:
            a = a[:-3]
        elif level == &#39;order&#39;:
            a = a[:-4]
        elif level == &#39;class&#39;:
            a = a[:-5]
        elif level == &#39;phylum&#39;:
            a = a[:-6]
        elif level == &#39;kingdom&#39;:
            a = a[:-7]
        else:
            raise ValueError(&#39;level `{}` was not recognized&#39;.format(level))

        return a
    
    def get_taxonomy(self, level: str) -&gt; str:
        &#39;&#39;&#39;Get the taxonomy at the level specified

        Parameters
        ----------
        level : str
            This is the level to get
            Valid responses: &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;

        Returns
        -------
        str
        &#39;&#39;&#39;
        return self.get_lineage(level=level)[-1]

    def tax_is_defined(self, level: str) -&gt; bool:
        &#39;&#39;&#39;Whether or not the taxon is defined at the specified taxonomic level

        Parameters
        ----------
        level : str
            This is the level to get
            Valid responses: &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;
        
        Returns
        -------
        bool
        &#39;&#39;&#39;
        try:
            tax = self.taxonomy[level]
        except:
            raise KeyError(&#39;`tax` ({}) not defined. Available taxs: {}&#39;.format(level, 
                list(self.taxonomy.keys())))
        return (type(tax) != float) and (tax != DEFAULT_TAXLEVEL_NAME) and (tax != &#39;&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.ClusterItem" href="#mdsine2.pylab.base.ClusterItem">ClusterItem</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Taxon.get_lineage"><code class="name flex">
<span>def <span class="ident">get_lineage</span></span>(<span>self, level: str = None) ‑> Iterator[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a tuple of the lineage in order from Kingdom to the level
indicated. Default value for level is <code>asv</code>.
Parameters</p>
<hr>
<dl>
<dt><strong><code>level</code></strong> :&ensp;<code>str, Optional</code></dt>
<dd>The taxonomic level you want the lineage until
If nothing is provided, it returns the entire taxonomic lineage
Example:
level = 'class'
returns a tuple of (kingdom, phylum, class)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_lineage(self, level: str=None) -&gt; Iterator[str]:
    &#39;&#39;&#39;Returns a tuple of the lineage in order from Kingdom to the level
    indicated. Default value for level is `asv`.
    Parameters
    ----------
    level : str, Optional
        The taxonomic level you want the lineage until
        If nothing is provided, it returns the entire taxonomic lineage
        Example:
            level = &#39;class&#39;
            returns a tuple of (kingdom, phylum, class)
    Returns
    -------
    str
    &#39;&#39;&#39;
    a =  (self.taxonomy[&#39;kingdom&#39;], self.taxonomy[&#39;phylum&#39;], self.taxonomy[&#39;class&#39;],
        self.taxonomy[&#39;order&#39;], self.taxonomy[&#39;family&#39;], self.taxonomy[&#39;genus&#39;],
        self.taxonomy[&#39;species&#39;], self.taxonomy[&#39;asv&#39;])

    if level is None:
        a = a
    if level == &#39;asv&#39;:
        a = a
    elif level == &#39;species&#39;:
        a = a[:-1]
    elif level == &#39;genus&#39;:
        a = a[:-2]
    elif level == &#39;family&#39;:
        a = a[:-3]
    elif level == &#39;order&#39;:
        a = a[:-4]
    elif level == &#39;class&#39;:
        a = a[:-5]
    elif level == &#39;phylum&#39;:
        a = a[:-6]
    elif level == &#39;kingdom&#39;:
        a = a[:-7]
    else:
        raise ValueError(&#39;level `{}` was not recognized&#39;.format(level))

    return a</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Taxon.get_taxonomy"><code class="name flex">
<span>def <span class="ident">get_taxonomy</span></span>(<span>self, level: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Get the taxonomy at the level specified</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>level</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the level to get
Valid responses: 'kingdom', 'phylum', 'class', 'order', 'family', 'genus'</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_taxonomy(self, level: str) -&gt; str:
    &#39;&#39;&#39;Get the taxonomy at the level specified

    Parameters
    ----------
    level : str
        This is the level to get
        Valid responses: &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;

    Returns
    -------
    str
    &#39;&#39;&#39;
    return self.get_lineage(level=level)[-1]</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Taxon.set_taxonomy"><code class="name flex">
<span>def <span class="ident">set_taxonomy</span></span>(<span>self, tax_kingdom: str = None, tax_phylum: str = None, tax_class: str = None, tax_order: str = None, tax_family: str = None, tax_genus: str = None, tax_species: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the taxonomy of the parts that are specified</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tax_kingdom</code></strong>, <strong><code>tax_phylum</code></strong>, <strong><code>tax_class</code></strong>, <strong><code>tax_order</code></strong>, <strong><code>tax_family</code></strong>, <strong><code>tax_genus</code></strong> :&ensp;<code>str</code></dt>
<dd>'kingdom', 'phylum', 'class', 'order', 'family', 'genus'
Name of the taxon for each respective level</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_taxonomy(self, tax_kingdom: str=None, tax_phylum: str=None, tax_class: str=None,
    tax_order: str=None, tax_family: str=None, tax_genus: str=None, tax_species: str=None):
    &#39;&#39;&#39;Sets the taxonomy of the parts that are specified

    Parameters
    ----------
    tax_kingdom, tax_phylum, tax_class, tax_order, tax_family, tax_genus : str
        &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;
        Name of the taxon for each respective level
    &#39;&#39;&#39;
    if tax_kingdom is not None and tax_kingdom != &#39;&#39; and plutil.isstr(tax_kingdom):
        self.taxonomy[&#39;kingdom&#39;] = tax_kingdom
    if tax_phylum is not None and tax_phylum != &#39;&#39; and plutil.isstr(tax_phylum):
        self.taxonomy[&#39;phylum&#39;] = tax_phylum
    if tax_class is not None and tax_class != &#39;&#39; and plutil.isstr(tax_class):
        self.taxonomy[&#39;class&#39;] = tax_class
    if tax_order is not None and tax_order != &#39;&#39; and plutil.isstr(tax_order):
        self.taxonomy[&#39;order&#39;] = tax_order
    if tax_family is not None and tax_family != &#39;&#39; and plutil.isstr(tax_family):
        self.taxonomy[&#39;family&#39;] = tax_family
    if tax_genus is not None and tax_genus != &#39;&#39; and plutil.isstr(tax_genus):
        self.taxonomy[&#39;genus&#39;] = tax_genus
    if tax_species is not None and tax_species != &#39;&#39; and plutil.isstr(tax_species):
        self.taxonomy[&#39;species&#39;] = tax_species
    return self</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Taxon.tax_is_defined"><code class="name flex">
<span>def <span class="ident">tax_is_defined</span></span>(<span>self, level: str) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Whether or not the taxon is defined at the specified taxonomic level</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>level</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the level to get
Valid responses: 'kingdom', 'phylum', 'class', 'order', 'family', 'genus'</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tax_is_defined(self, level: str) -&gt; bool:
    &#39;&#39;&#39;Whether or not the taxon is defined at the specified taxonomic level

    Parameters
    ----------
    level : str
        This is the level to get
        Valid responses: &#39;kingdom&#39;, &#39;phylum&#39;, &#39;class&#39;, &#39;order&#39;, &#39;family&#39;, &#39;genus&#39;
    
    Returns
    -------
    bool
    &#39;&#39;&#39;
    try:
        tax = self.taxonomy[level]
    except:
        raise KeyError(&#39;`tax` ({}) not defined. Available taxs: {}&#39;.format(level, 
            list(self.taxonomy.keys())))
    return (type(tax) != float) and (tax != DEFAULT_TAXLEVEL_NAME) and (tax != &#39;&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.pylab.base.Traceable"><code class="flex name class">
<span>class <span class="ident">Traceable</span></span>
</code></dt>
<dd>
<div class="desc"><p>Defines the functionality for a Node to interact with the Graph tracer object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Traceable:
    &#39;&#39;&#39;Defines the functionality for a Node to interact with the Graph tracer object
    &#39;&#39;&#39;

    def set_trace(self):
        &#39;&#39;&#39;Initialize the trace arrays for the variable in the Tracer object. 

        It will initialize a buffer the size of the checkpoint size in Tracer
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;User needs to define this function&#39;)

    def add_trace(self):
        &#39;&#39;&#39;Adds the current value to the trace. If the buffer is full
        it will end it to disk
        &#39;&#39;&#39;
        raise NotImplementedError(&#39;User needs to define this function&#39;)

    def get_trace_from_disk(self, section: str = &#39;posterior&#39;, slices: slice = None) -&gt; np.ndarray:
        &#39;&#39;&#39;Returns the entire trace (after burnin) writen on the disk. NOTE: This may/may not 
        include the samples in the local buffer trace and could be very large

        Parameters
        ----------
        section : str
            Which part of the trace to return - description above
        slices : list(slice), slice
            A list of slicing objects or a slice object.

            slice(start, stop, step)
            Example, single dimension:
                slice(None) == :
                slice(5) == :5
                slice(4, None, None) == 4:
                slice(9, 22,None) == 9:22
            Example, multiple dimensions:
                [slice(None), slice(4, None, None)] == :, 4:
                [slice(None), 4, 5] == :, 4, 5

        Returns
        -------
        np.ndarray
        &#39;&#39;&#39;
        return self.G.tracer.get_trace(name=self.name, section=section, slices=slices)

    def overwrite_entire_trace_on_disk(self, data: np.ndarray, **kwargs):
        &#39;&#39;&#39;Overwrites the entire trace of the variable with the given data.

        Parameters
        ----------
        data : np.ndarray
            Data you are overwriting the trace with.
        &#39;&#39;&#39;
        self.G.tracer.overwrite_entire_trace_on_disk(
            name=self.name, data=data, dtype=self.dtype, **kwargs)

    def get_iter(self) -&gt; int:
        &#39;&#39;&#39;Get the number of iterations saved to the hdf5 file of the variable

        Returns
        -------
        int
        &#39;&#39;&#39;
        return self.G.tracer.get_iter(name=self.name)</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.cluster.ClusterValue" href="cluster.html#mdsine2.pylab.cluster.ClusterValue">ClusterValue</a></li>
<li><a title="mdsine2.pylab.cluster.Clustering" href="cluster.html#mdsine2.pylab.cluster.Clustering">Clustering</a></li>
<li><a title="mdsine2.pylab.contrib.Interactions" href="contrib.html#mdsine2.pylab.contrib.Interactions">Interactions</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.Traceable.add_trace"><code class="name flex">
<span>def <span class="ident">add_trace</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds the current value to the trace. If the buffer is full
it will end it to disk</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_trace(self):
    &#39;&#39;&#39;Adds the current value to the trace. If the buffer is full
    it will end it to disk
    &#39;&#39;&#39;
    raise NotImplementedError(&#39;User needs to define this function&#39;)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Traceable.get_iter"><code class="name flex">
<span>def <span class="ident">get_iter</span></span>(<span>self) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>Get the number of iterations saved to the hdf5 file of the variable</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_iter(self) -&gt; int:
    &#39;&#39;&#39;Get the number of iterations saved to the hdf5 file of the variable

    Returns
    -------
    int
    &#39;&#39;&#39;
    return self.G.tracer.get_iter(name=self.name)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Traceable.get_trace_from_disk"><code class="name flex">
<span>def <span class="ident">get_trace_from_disk</span></span>(<span>self, section: str = 'posterior', slices: slice = None) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the entire trace (after burnin) writen on the disk. NOTE: This may/may not
include the samples in the local buffer trace and could be very large</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>section</code></strong> :&ensp;<code>str</code></dt>
<dd>Which part of the trace to return - description above</dd>
<dt><strong><code>slices</code></strong> :&ensp;<code>list(slice), slice</code></dt>
<dd>
<p>A list of slicing objects or a slice object.</p>
<p>slice(start, stop, step)
Example, single dimension:
slice(None) == :
slice(5) == :5
slice(4, None, None) == 4:
slice(9, 22,None) == 9:22
Example, multiple dimensions:
[slice(None), slice(4, None, None)] == :, 4:
[slice(None), 4, 5] == :, 4, 5</p>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_trace_from_disk(self, section: str = &#39;posterior&#39;, slices: slice = None) -&gt; np.ndarray:
    &#39;&#39;&#39;Returns the entire trace (after burnin) writen on the disk. NOTE: This may/may not 
    include the samples in the local buffer trace and could be very large

    Parameters
    ----------
    section : str
        Which part of the trace to return - description above
    slices : list(slice), slice
        A list of slicing objects or a slice object.

        slice(start, stop, step)
        Example, single dimension:
            slice(None) == :
            slice(5) == :5
            slice(4, None, None) == 4:
            slice(9, 22,None) == 9:22
        Example, multiple dimensions:
            [slice(None), slice(4, None, None)] == :, 4:
            [slice(None), 4, 5] == :, 4, 5

    Returns
    -------
    np.ndarray
    &#39;&#39;&#39;
    return self.G.tracer.get_trace(name=self.name, section=section, slices=slices)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk"><code class="name flex">
<span>def <span class="ident">overwrite_entire_trace_on_disk</span></span>(<span>self, data: numpy.ndarray, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Overwrites the entire trace of the variable with the given data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Data you are overwriting the trace with.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def overwrite_entire_trace_on_disk(self, data: np.ndarray, **kwargs):
    &#39;&#39;&#39;Overwrites the entire trace of the variable with the given data.

    Parameters
    ----------
    data : np.ndarray
        Data you are overwriting the trace with.
    &#39;&#39;&#39;
    self.G.tracer.overwrite_entire_trace_on_disk(
        name=self.name, data=data, dtype=self.dtype, **kwargs)</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.Traceable.set_trace"><code class="name flex">
<span>def <span class="ident">set_trace</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the trace arrays for the variable in the Tracer object. </p>
<p>It will initialize a buffer the size of the checkpoint size in Tracer</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_trace(self):
    &#39;&#39;&#39;Initialize the trace arrays for the variable in the Tracer object. 

    It will initialize a buffer the size of the checkpoint size in Tracer
    &#39;&#39;&#39;
    raise NotImplementedError(&#39;User needs to define this function&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata"><code class="flex name class">
<span>class <span class="ident">qPCRdata</span></span>
<span>(</span><span>cfus: numpy.ndarray, mass: float = 1.0, dilution_factor: float = 1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Single entry of qpcr data at a timepoint with maybe multiple technical replicates.
Assumes that the dilution factor is constant between the replicate runs</p>
<p>The normalized data is assumed to be:
(cfus * dilution_factor / mass) * scaling_factor</p>
<p>scaling_factor is a scale that we impose on the data so that the numbers don't get
super large in the numerical calculations and we get errors, it does nothing to affect
the empirical variance of the data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cfus</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>These are the raw CFUs - it can be a single CFU measurement or a list of all
the measurements</dd>
<dt><strong><code>mass</code></strong> :&ensp;<code>float</code></dt>
<dd>This is the mass of the sample in grams</dd>
<dt><strong><code>dilution_factor</code></strong> :&ensp;<code>float</code></dt>
<dd>This is the dilution factor of the samples
Example:
If the sample was diluted to 1/100 of its original concentration,
the dilution factor is 100, NOT 1/100.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class qPCRdata:
    &#39;&#39;&#39;Single entry of qpcr data at a timepoint with maybe multiple technical replicates.
    Assumes that the dilution factor is constant between the replicate runs

    The normalized data is assumed to be:
        (cfus * dilution_factor / mass) * scaling_factor

    scaling_factor is a scale that we impose on the data so that the numbers don&#39;t get
    super large in the numerical calculations and we get errors, it does nothing to affect
    the empirical variance of the data.

    Parameters
    ----------
    cfus : np.ndarray
        These are the raw CFUs - it can be a single CFU measurement or a list of all
        the measurements
    mass : float
        This is the mass of the sample in grams
    dilution_factor : float
        This is the dilution factor of the samples
        Example:
            If the sample was diluted to 1/100 of its original concentration,
            the dilution factor is 100, NOT 1/100.

    &#39;&#39;&#39;
    def __init__(self, cfus: np.ndarray, mass: float=1., dilution_factor: float=1.):
        self._raw_data = np.asarray(cfus) # array of raw CFU values
        self.mass = mass
        self.dilution_factor = dilution_factor
        self.scaling_factor = 1 # Initialize with no scaling factor
        self.recalculate_parameters()

    def recalculate_parameters(self):
        &#39;&#39;&#39;Generate the normalized abundances and recalculate the statistics
        &#39;&#39;&#39;
        if len(self._raw_data) == 0:
            return

        self.data = (self._raw_data*self.dilution_factor/self.mass)*self.scaling_factor # array of normalized values
        self.log_data = np.log(self.data) 
        
        self.loc = np.mean(self.log_data)
        self.scale = np.std(self.log_data - self.loc)
        self.scale2 = self.scale ** 2


        self._mean_dist = np.exp(self.loc + (self.scale2/2) )
        self._var_dist = (np.exp(self.scale2) - 1) * np.exp(2*self.loc + self.scale2)
        self._std_dist = np.sqrt(self._var_dist)
        self._gmean = (np.prod(self.data))**(1/len(self.data))

    def __str__(self) -&gt; str:
        s = &#39;cfus: {}\nmass: {}\ndilution_factor: {}\n scaling_factor: {}\n&#39; \
            &#39;data: {}\nlog_data: {}\nloc: {}\n scale: {}&#39;.format( 
                self._raw_data, self.mass, self.dilution_factor, self.scaling_factor, 
                self.data, self.log_data, self.loc, self.scale)
        return s

    def add(self, raw_data: Union[np.ndarray, float, int]):
        &#39;&#39;&#39;Add a single qPCR measurement to add to the set of observations

        Parameters
        ----------
        raw_data : float, array_like
            This is the measurement to add
        &#39;&#39;&#39;
        self._raw_data = np.append(self._raw_data,raw_data)
        self.recalculate_parameters()

    def set_to_nan(self):
        &#39;&#39;&#39;Set all attributes to `np.nan`
        &#39;&#39;&#39;
        self._raw_data *= np.nan
        self.data *= np.nan
        self.mass = np.nan
        self.dilution_factor = np.nan
        self._mean_dist = np.nan
        self._std_dist = np.nan
        self._var_dist = np.nan
        self._gmean = np.nan
        self.loc = np.nan
        self.scale = np.nan
        self.scale2 = np.nan
        self.scaling_factor = np.nan

    def set_scaling_factor(self, scaling_factor: float):
        &#39;&#39;&#39;Resets the scaling factor

        Parameters
        ----------
        scaling_factor : float, int
            This is the scaling factor to set everything to
        &#39;&#39;&#39;
        if scaling_factor &lt;= 0:
            raise ValueError(&#39;The scaling factor must strictly be positive&#39;)
        self.scaling_factor = scaling_factor
        self.recalculate_parameters()

    def mean(self) -&gt; float:
        &#39;&#39;&#39;Return the geometric mean
        &#39;&#39;&#39;
        return self.gmean()
    
    def var(self) -&gt; float:
        return self._var_dist

    def std(self) -&gt; float:
        return self._std_dist

    def gmean(self) -&gt; float:
        return self._gmean</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.pylab.base.qPCRdata.add"><code class="name flex">
<span>def <span class="ident">add</span></span>(<span>self, raw_data: Union[numpy.ndarray, float, int])</span>
</code></dt>
<dd>
<div class="desc"><p>Add a single qPCR measurement to add to the set of observations</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>raw_data</code></strong> :&ensp;<code>float, array_like</code></dt>
<dd>This is the measurement to add</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add(self, raw_data: Union[np.ndarray, float, int]):
    &#39;&#39;&#39;Add a single qPCR measurement to add to the set of observations

    Parameters
    ----------
    raw_data : float, array_like
        This is the measurement to add
    &#39;&#39;&#39;
    self._raw_data = np.append(self._raw_data,raw_data)
    self.recalculate_parameters()</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata.gmean"><code class="name flex">
<span>def <span class="ident">gmean</span></span>(<span>self) ‑> float</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gmean(self) -&gt; float:
    return self._gmean</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self) ‑> float</span>
</code></dt>
<dd>
<div class="desc"><p>Return the geometric mean</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self) -&gt; float:
    &#39;&#39;&#39;Return the geometric mean
    &#39;&#39;&#39;
    return self.gmean()</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata.recalculate_parameters"><code class="name flex">
<span>def <span class="ident">recalculate_parameters</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate the normalized abundances and recalculate the statistics</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def recalculate_parameters(self):
    &#39;&#39;&#39;Generate the normalized abundances and recalculate the statistics
    &#39;&#39;&#39;
    if len(self._raw_data) == 0:
        return

    self.data = (self._raw_data*self.dilution_factor/self.mass)*self.scaling_factor # array of normalized values
    self.log_data = np.log(self.data) 
    
    self.loc = np.mean(self.log_data)
    self.scale = np.std(self.log_data - self.loc)
    self.scale2 = self.scale ** 2


    self._mean_dist = np.exp(self.loc + (self.scale2/2) )
    self._var_dist = (np.exp(self.scale2) - 1) * np.exp(2*self.loc + self.scale2)
    self._std_dist = np.sqrt(self._var_dist)
    self._gmean = (np.prod(self.data))**(1/len(self.data))</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata.set_scaling_factor"><code class="name flex">
<span>def <span class="ident">set_scaling_factor</span></span>(<span>self, scaling_factor: float)</span>
</code></dt>
<dd>
<div class="desc"><p>Resets the scaling factor</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scaling_factor</code></strong> :&ensp;<code>float, int</code></dt>
<dd>This is the scaling factor to set everything to</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_scaling_factor(self, scaling_factor: float):
    &#39;&#39;&#39;Resets the scaling factor

    Parameters
    ----------
    scaling_factor : float, int
        This is the scaling factor to set everything to
    &#39;&#39;&#39;
    if scaling_factor &lt;= 0:
        raise ValueError(&#39;The scaling factor must strictly be positive&#39;)
    self.scaling_factor = scaling_factor
    self.recalculate_parameters()</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata.set_to_nan"><code class="name flex">
<span>def <span class="ident">set_to_nan</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Set all attributes to <code>np.nan</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_to_nan(self):
    &#39;&#39;&#39;Set all attributes to `np.nan`
    &#39;&#39;&#39;
    self._raw_data *= np.nan
    self.data *= np.nan
    self.mass = np.nan
    self.dilution_factor = np.nan
    self._mean_dist = np.nan
    self._std_dist = np.nan
    self._var_dist = np.nan
    self._gmean = np.nan
    self.loc = np.nan
    self.scale = np.nan
    self.scale2 = np.nan
    self.scaling_factor = np.nan</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata.std"><code class="name flex">
<span>def <span class="ident">std</span></span>(<span>self) ‑> float</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def std(self) -&gt; float:
    return self._std_dist</code></pre>
</details>
</dd>
<dt id="mdsine2.pylab.base.qPCRdata.var"><code class="name flex">
<span>def <span class="ident">var</span></span>(<span>self) ‑> float</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def var(self) -&gt; float:
    return self._var_dist</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mdsine2.pylab" href="index.html">mdsine2.pylab</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="mdsine2.pylab.base.condense_matrix_with_taxonomy" href="#mdsine2.pylab.base.condense_matrix_with_taxonomy">condense_matrix_with_taxonomy</a></code></li>
<li><code><a title="mdsine2.pylab.base.isclusterable" href="#mdsine2.pylab.base.isclusterable">isclusterable</a></code></li>
<li><code><a title="mdsine2.pylab.base.isotu" href="#mdsine2.pylab.base.isotu">isotu</a></code></li>
<li><code><a title="mdsine2.pylab.base.isperturbation" href="#mdsine2.pylab.base.isperturbation">isperturbation</a></code></li>
<li><code><a title="mdsine2.pylab.base.isqpcrdata" href="#mdsine2.pylab.base.isqpcrdata">isqpcrdata</a></code></li>
<li><code><a title="mdsine2.pylab.base.issavable" href="#mdsine2.pylab.base.issavable">issavable</a></code></li>
<li><code><a title="mdsine2.pylab.base.isstudy" href="#mdsine2.pylab.base.isstudy">isstudy</a></code></li>
<li><code><a title="mdsine2.pylab.base.issubject" href="#mdsine2.pylab.base.issubject">issubject</a></code></li>
<li><code><a title="mdsine2.pylab.base.istaxaset" href="#mdsine2.pylab.base.istaxaset">istaxaset</a></code></li>
<li><code><a title="mdsine2.pylab.base.istaxon" href="#mdsine2.pylab.base.istaxon">istaxon</a></code></li>
<li><code><a title="mdsine2.pylab.base.istaxontype" href="#mdsine2.pylab.base.istaxontype">istaxontype</a></code></li>
<li><code><a title="mdsine2.pylab.base.istraceable" href="#mdsine2.pylab.base.istraceable">istraceable</a></code></li>
<li><code><a title="mdsine2.pylab.base.taxaname_for_paper" href="#mdsine2.pylab.base.taxaname_for_paper">taxaname_for_paper</a></code></li>
<li><code><a title="mdsine2.pylab.base.taxaname_formatter" href="#mdsine2.pylab.base.taxaname_formatter">taxaname_formatter</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mdsine2.pylab.base.BasePerturbation" href="#mdsine2.pylab.base.BasePerturbation">BasePerturbation</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.BasePerturbation.isactive" href="#mdsine2.pylab.base.BasePerturbation.isactive">isactive</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.ClusterItem" href="#mdsine2.pylab.base.ClusterItem">ClusterItem</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.ClusterItem.cluster_str" href="#mdsine2.pylab.base.ClusterItem.cluster_str">cluster_str</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.Clusterable" href="#mdsine2.pylab.base.Clusterable">Clusterable</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.Clusterable.stritem" href="#mdsine2.pylab.base.Clusterable.stritem">stritem</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.CustomOrderedDict" href="#mdsine2.pylab.base.CustomOrderedDict">CustomOrderedDict</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.CustomOrderedDict.update_order" href="#mdsine2.pylab.base.CustomOrderedDict.update_order">update_order</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.OTU" href="#mdsine2.pylab.base.OTU">OTU</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.OTU.generate_consensus_seq" href="#mdsine2.pylab.base.OTU.generate_consensus_seq">generate_consensus_seq</a></code></li>
<li><code><a title="mdsine2.pylab.base.OTU.generate_consensus_taxonomy" href="#mdsine2.pylab.base.OTU.generate_consensus_taxonomy">generate_consensus_taxonomy</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.Perturbations" href="#mdsine2.pylab.base.Perturbations">Perturbations</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.Perturbations.append" href="#mdsine2.pylab.base.Perturbations.append">append</a></code></li>
<li><code><a title="mdsine2.pylab.base.Perturbations.remove" href="#mdsine2.pylab.base.Perturbations.remove">remove</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.Saveable" href="#mdsine2.pylab.base.Saveable">Saveable</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.Saveable.get_save_location" href="#mdsine2.pylab.base.Saveable.get_save_location">get_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.load" href="#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.save" href="#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.base.Saveable.set_save_location" href="#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.Study" href="#mdsine2.pylab.base.Study">Study</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.Study.add_perturbation" href="#mdsine2.pylab.base.Study.add_perturbation">add_perturbation</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.add_subject" href="#mdsine2.pylab.base.Study.add_subject">add_subject</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.aggregate_items" href="#mdsine2.pylab.base.Study.aggregate_items">aggregate_items</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.aggregate_items_like" href="#mdsine2.pylab.base.Study.aggregate_items_like">aggregate_items_like</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.deaggregate_item" href="#mdsine2.pylab.base.Study.deaggregate_item">deaggregate_item</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.denormalize_qpcr" href="#mdsine2.pylab.base.Study.denormalize_qpcr">denormalize_qpcr</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.df" href="#mdsine2.pylab.base.Study.df">df</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.iloc" href="#mdsine2.pylab.base.Study.iloc">iloc</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.matrix" href="#mdsine2.pylab.base.Study.matrix">matrix</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.names" href="#mdsine2.pylab.base.Study.names">names</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.normalize_qpcr" href="#mdsine2.pylab.base.Study.normalize_qpcr">normalize_qpcr</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.parse" href="#mdsine2.pylab.base.Study.parse">parse</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.pop_subject" href="#mdsine2.pylab.base.Study.pop_subject">pop_subject</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.pop_taxa" href="#mdsine2.pylab.base.Study.pop_taxa">pop_taxa</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.pop_taxa_like" href="#mdsine2.pylab.base.Study.pop_taxa_like">pop_taxa_like</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.pop_times" href="#mdsine2.pylab.base.Study.pop_times">pop_times</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.split_on_perturbations" href="#mdsine2.pylab.base.Study.split_on_perturbations">split_on_perturbations</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.times" href="#mdsine2.pylab.base.Study.times">times</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.write_metadata_to_csv" href="#mdsine2.pylab.base.Study.write_metadata_to_csv">write_metadata_to_csv</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.write_perturbations_to_csv" href="#mdsine2.pylab.base.Study.write_perturbations_to_csv">write_perturbations_to_csv</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.write_qpcr_to_csv" href="#mdsine2.pylab.base.Study.write_qpcr_to_csv">write_qpcr_to_csv</a></code></li>
<li><code><a title="mdsine2.pylab.base.Study.write_reads_to_csv" href="#mdsine2.pylab.base.Study.write_reads_to_csv">write_reads_to_csv</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.Subject" href="#mdsine2.pylab.base.Subject">Subject</a></code></h4>
<ul class="two-column">
<li><code><a title="mdsine2.pylab.base.Subject.add_qpcr" href="#mdsine2.pylab.base.Subject.add_qpcr">add_qpcr</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.add_reads" href="#mdsine2.pylab.base.Subject.add_reads">add_reads</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.add_time" href="#mdsine2.pylab.base.Subject.add_time">add_time</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.cluster_by_taxlevel" href="#mdsine2.pylab.base.Subject.cluster_by_taxlevel">cluster_by_taxlevel</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.df" href="#mdsine2.pylab.base.Subject.df">df</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.index" href="#mdsine2.pylab.base.Subject.index">index</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.matrix" href="#mdsine2.pylab.base.Subject.matrix">matrix</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.perturbations" href="#mdsine2.pylab.base.Subject.perturbations">perturbations</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.read_depth" href="#mdsine2.pylab.base.Subject.read_depth">read_depth</a></code></li>
<li><code><a title="mdsine2.pylab.base.Subject.taxa" href="#mdsine2.pylab.base.Subject.taxa">taxa</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.TaxaSet" href="#mdsine2.pylab.base.TaxaSet">TaxaSet</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.TaxaSet.add_taxon" href="#mdsine2.pylab.base.TaxaSet.add_taxon">add_taxon</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.aggregate_items" href="#mdsine2.pylab.base.TaxaSet.aggregate_items">aggregate_items</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.deaggregate_item" href="#mdsine2.pylab.base.TaxaSet.deaggregate_item">deaggregate_item</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.del_taxon" href="#mdsine2.pylab.base.TaxaSet.del_taxon">del_taxon</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.generate_consensus_seqs" href="#mdsine2.pylab.base.TaxaSet.generate_consensus_seqs">generate_consensus_seqs</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.generate_consensus_taxonomies" href="#mdsine2.pylab.base.TaxaSet.generate_consensus_taxonomies">generate_consensus_taxonomies</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.n_taxa" href="#mdsine2.pylab.base.TaxaSet.n_taxa">n_taxa</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.parse" href="#mdsine2.pylab.base.TaxaSet.parse">parse</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.rename" href="#mdsine2.pylab.base.TaxaSet.rename">rename</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.taxonomic_similarity" href="#mdsine2.pylab.base.TaxaSet.taxonomic_similarity">taxonomic_similarity</a></code></li>
<li><code><a title="mdsine2.pylab.base.TaxaSet.write_taxonomy_to_csv" href="#mdsine2.pylab.base.TaxaSet.write_taxonomy_to_csv">write_taxonomy_to_csv</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.Taxon" href="#mdsine2.pylab.base.Taxon">Taxon</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.Taxon.get_lineage" href="#mdsine2.pylab.base.Taxon.get_lineage">get_lineage</a></code></li>
<li><code><a title="mdsine2.pylab.base.Taxon.get_taxonomy" href="#mdsine2.pylab.base.Taxon.get_taxonomy">get_taxonomy</a></code></li>
<li><code><a title="mdsine2.pylab.base.Taxon.set_taxonomy" href="#mdsine2.pylab.base.Taxon.set_taxonomy">set_taxonomy</a></code></li>
<li><code><a title="mdsine2.pylab.base.Taxon.tax_is_defined" href="#mdsine2.pylab.base.Taxon.tax_is_defined">tax_is_defined</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.Traceable" href="#mdsine2.pylab.base.Traceable">Traceable</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.Traceable.add_trace" href="#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.base.Traceable.get_iter" href="#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.base.Traceable.get_trace_from_disk" href="#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk" href="#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.base.Traceable.set_trace" href="#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.pylab.base.qPCRdata" href="#mdsine2.pylab.base.qPCRdata">qPCRdata</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.pylab.base.qPCRdata.add" href="#mdsine2.pylab.base.qPCRdata.add">add</a></code></li>
<li><code><a title="mdsine2.pylab.base.qPCRdata.gmean" href="#mdsine2.pylab.base.qPCRdata.gmean">gmean</a></code></li>
<li><code><a title="mdsine2.pylab.base.qPCRdata.mean" href="#mdsine2.pylab.base.qPCRdata.mean">mean</a></code></li>
<li><code><a title="mdsine2.pylab.base.qPCRdata.recalculate_parameters" href="#mdsine2.pylab.base.qPCRdata.recalculate_parameters">recalculate_parameters</a></code></li>
<li><code><a title="mdsine2.pylab.base.qPCRdata.set_scaling_factor" href="#mdsine2.pylab.base.qPCRdata.set_scaling_factor">set_scaling_factor</a></code></li>
<li><code><a title="mdsine2.pylab.base.qPCRdata.set_to_nan" href="#mdsine2.pylab.base.qPCRdata.set_to_nan">set_to_nan</a></code></li>
<li><code><a title="mdsine2.pylab.base.qPCRdata.std" href="#mdsine2.pylab.base.qPCRdata.std">std</a></code></li>
<li><code><a title="mdsine2.pylab.base.qPCRdata.var" href="#mdsine2.pylab.base.qPCRdata.var">var</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>