<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>mdsine2.run API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mdsine2.run</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import logging
import numpy as np
import h5py
import os

from typing import Union, Dict, Iterator, Tuple, List, Any, IO, Callable

# Custom modules
from . import config
from .names import STRNAMES
from . import design_matrices
from . import posterior

from . import pylab as pl
from .pylab import Study, BaseMCMC

def initialize_graph(params: config.MDSINE2ModelConfig, graph_name: str, subjset: Study, continue_inference: int=None, 
    intermediate_validation: Dict[str, Union[float, Callable, Dict[str, Any]]]=None) -&gt; BaseMCMC:
    &#39;&#39;&#39;Builds the graph with the posterior classes and creates an
    mdsine2.BaseMCMC inference chain object that you ran run inference with

    Parameters
    ----------
    params : mdsine2.config.MDSINE2ModelConfig
        This class specifies all of the parameters of the model.
    graph_name : str
        Name of the graph you want to build
    subjset : mdsine2.Study
        This is the subjectset that contains all of the trajectories for inference.
        Note that this subjectset has already been filtered
    continue_inference : int, None
        Gibb sample to restart inference from
    intermediate_validation : dict
        A dictionary with the following arguments:
            &#39;t&#39; : float
                This is how often, in seconds, you want to run this function
            &#39;func&#39; : callable
                This function is called every `t` seconds
            &#39;kwargs&#39; : dict
                These are additional arguments to pass into fucntion `func`

    Returns
    -------
    pl.inference.BaseMCMC
        Inference chain
    &#39;&#39;&#39;
    # Type Check
    # ----------
    if not config.isModelConfig(params):
        raise TypeError(&#39;`params` ({}) needs to be a config.ModelConfig object&#39;.format(type(params)))
    if not pl.isstudy(subjset):
        raise TypeError(&#39;`subjset` ({}) must be a mdsine2.Study&#39;.format(type(subjset)))
    if not pl.isstr(graph_name):
        raise TypeError(&#39;`graph_name` ({}) must be a str&#39;.format(type(graph_name)))
    if continue_inference is not None:
        if not pl.isint(continue_inference):
            raise TypeError(&#39;`continue_inference` ({}) must be an int&#39;.format(type(continue_inference)))
        if continue_inference &lt;= 0:
            raise ValueError(&#39;`continue_inference` ({}0 must be &gt; 0&#39;.format(continue_inference))

        GRAPH = pl.graph.Graph.load(params.GRAPH_FILENAME)
    else:
        GRAPH = pl.Graph(name=graph_name, seed=params.SEED)
    GRAPH.as_default()
    pl.seed(params.SEED)

    # Continue inference if necessary
    # -------------------------------
    if continue_inference is not None:
        logging.info(&#39;Continuing inference at Gibb step {}&#39;.format(continue_inference))
        mcmc = pl.inference.BaseMCMC.load(params.MCMC_FILENAME)
        mcmc.continue_inference(gibb_step_start=continue_inference)

        return mcmc

    # Make the basepath
    # -----------------
    basepath = params.OUTPUT_BASEPATH
    os.makedirs(basepath, exist_ok=True)

    # Normalize the qpcr measurements for numerical stability
    # -------------------------------------------------------
    if params.QPCR_NORMALIZATION_MAX_VALUE is not None:
        subjset.normalize_qpcr(max_value=params.QPCR_NORMALIZATION_MAX_VALUE)
        logging.info(&#39;Normalizing abundances for a max value of {}. Normalization &#39; \
            &#39;constant: {:.4E}&#39;.format(params.QPCR_NORMALIZATION_MAX_VALUE, 
            subjset.qpcr_normalization_factor))
        
        params.INITIALIZATION_KWARGS[STRNAMES.FILTERING][&#39;v2&#39;] *= subjset.qpcr_normalization_factor
        params.INITIALIZATION_KWARGS[STRNAMES.SELF_INTERACTION_VALUE][&#39;rescale_value&#39;] = \
            subjset.qpcr_normalization_factor
    
    subjset_filename = os.path.join(basepath, config.SUBJSET_FILENAME)
    subjset.save(subjset_filename)

    # Instantiate the posterior classes
    # ---------------------------------
    taxa = subjset.taxa
    d = design_matrices.Data(subjects=subjset, G=GRAPH, 
        zero_inflation_transition_policy=params.ZERO_INFLATION_TRANSITION_POLICY)
    clustering = pl.Clustering(clusters=None, items=taxa, G=GRAPH,
        name=STRNAMES.CLUSTERING_OBJ)

    # Interactions
    var_interactions = posterior.PriorVarInteractions(
        prior=pl.variables.SICS(
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH), 
        G=GRAPH), G=GRAPH)
    mean_interactions = posterior.PriorMeanInteractions(
        prior=pl.variables.Normal(
            loc=pl.Constant(None, G=GRAPH),
            scale2=pl.Constant(None, G=GRAPH), 
        G=GRAPH), G=GRAPH)
    interaction_value = pl.variables.Normal(
        loc=mean_interactions, scale2=var_interactions, G=GRAPH)

    interaction_indicator = posterior.ClusterInteractionIndicatorProbability(
        prior=pl.variables.Beta(a=pl.Constant(None, G=GRAPH), b=pl.Constant(None, G=GRAPH), G=GRAPH),
        G=GRAPH)
    interactions = posterior.ClusterInteractionValue(
        prior=interaction_value, clustering=clustering, G=GRAPH)
    Z = posterior.ClusterInteractionIndicators(prior=interaction_indicator, G=GRAPH)

    # Growth
    var_growth = posterior.PriorVarMH(
        prior=pl.variables.SICS(
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH), G=GRAPH),
        child_name=STRNAMES.GROWTH_VALUE, G=GRAPH)
    mean_growth = posterior.PriorMeanMH(
        prior=pl.variables.TruncatedNormal(
            loc=pl.Constant(None, G=GRAPH),
            scale2=pl.Constant(None, G=GRAPH), G=GRAPH), 
        child_name=STRNAMES.GROWTH_VALUE, G=GRAPH)
    prior_growth = pl.variables.Normal(
        loc=mean_growth, scale2=var_growth,
        name=&#39;prior_{}&#39;.format(STRNAMES.GROWTH_VALUE), G=GRAPH)
    growth = posterior.Growth(prior=prior_growth, G=GRAPH)

    # Self-Interactions
    var_si = posterior.PriorVarMH(
        prior=pl.variables.SICS(
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH), G=GRAPH),
        child_name=STRNAMES.SELF_INTERACTION_VALUE, G=GRAPH)
    mean_si = posterior.PriorMeanMH(
        prior=pl.variables.TruncatedNormal(
            loc=pl.Constant(None, G=GRAPH),
            scale2=pl.Constant(None, G=GRAPH), G=GRAPH), 
        child_name=STRNAMES.SELF_INTERACTION_VALUE, G=GRAPH)
    prior_si = pl.variables.Normal(
        loc=mean_si, scale2=var_si,
        name=&#39;prior_{}&#39;.format(STRNAMES.SELF_INTERACTION_VALUE), G=GRAPH)
    self_interactions = posterior.SelfInteractions(prior=prior_si, G=GRAPH)

    # Process Variance
    prior_processvar = pl.variables.SICS( 
        dof=pl.Constant(None, G=GRAPH),
        scale=pl.Constant(None, G=GRAPH), G=GRAPH)
    processvar = posterior.ProcessVarGlobal(G=GRAPH, prior=prior_processvar)

    # Clustering
    prior_concentration = pl.variables.Gamma(
        shape=pl.Constant(None, G=GRAPH),
        scale=pl.Constant(None, G=GRAPH),
        G=GRAPH)
    concentration = posterior.Concentration(
        prior=prior_concentration, G=GRAPH)
    cluster_assignments = posterior.ClusterAssignments(
        clustering=clustering, concentration=concentration,
        G=GRAPH, mp=params.MP_CLUSTERING)

    # Filtering and zero inflation
    filtering = posterior.FilteringLogMP(G=GRAPH, mp=params.MP_FILTERING, 
        zero_inflation_transition_policy=params.ZERO_INFLATION_TRANSITION_POLICY)
    zero_inflation = posterior.ZeroInflation(G=GRAPH)

    # Perturbations
    if subjset.perturbations is not None:
        for pidx, subj_pert in enumerate(subjset.perturbations):
            name = subj_pert.name
            perturbation = pl.ClusterPerturbationEffect(
                starts=subj_pert.starts, ends=subj_pert.ends, 
                probability=pl.variables.Beta(
                    name=name + &#39;_probability&#39;, G=GRAPH, value=None, a=None, b=None),
                clustering=clustering, G=GRAPH, name=name,
                signal_when_clusters_change=False, signal_when_item_assignment_changes=False)

            magnitude_var = posterior.PriorVarPerturbationSingle(
                prior=pl.variables.SICS(
                    dof=pl.Constant(None, G=GRAPH),
                    scale=pl.Constant(None, G=GRAPH), G=GRAPH), 
                perturbation=perturbation, G=GRAPH)
            magnitude_mean = posterior.PriorMeanPerturbationSingle(
                prior=pl.variables.Normal(
                    loc=pl.Constant(None, G=GRAPH),
                    scale2=pl.Constant(None, G=GRAPH),
                    G=GRAPH), 
                perturbation=perturbation, G=GRAPH)
            prior_magnitude = pl.variables.Normal(G=GRAPH, loc=magnitude_mean, scale2=magnitude_var)
            perturbation.magnitude.add_prior(prior_magnitude)

            prior_prob = pl.variables.Beta(
                a=pl.Constant(None, G=GRAPH),
                b=pl.Constant(None, G=GRAPH),
                G=GRAPH)
            perturbation.probability.add_prior(prior_prob)
        
        magnitude_var_perts = posterior.PriorVarPerturbations(G=GRAPH)
        magnitude_mean_perts = posterior.PriorMeanPerturbations(G=GRAPH)
        magnitude_perts = posterior.PerturbationMagnitudes(G=GRAPH)
        indicator_perts = posterior.PerturbationIndicators(G=GRAPH, need_to_trace=False, relative=True)
        indicator_prob_perts = posterior.PerturbationProbabilities(G=GRAPH)
    else:
        magnitude_perts = None
        pert_ind = None
        pert_ind_prob = None

    beta = posterior.GLVParameters(
        growth=growth, self_interactions=self_interactions,
        interactions=interactions, pert_mag=magnitude_perts, G=GRAPH)

    # Set qPCR variance priors and hyper priors
    qpcr_variances = posterior.qPCRVariances(G=GRAPH, L=params.N_QPCR_BUCKETS)
    qpcr_dofs = posterior.qPCRDegsOfFreedoms(G=GRAPH, L=params.N_QPCR_BUCKETS)
    qpcr_scales = posterior.qPCRScales(G=GRAPH, L=params.N_QPCR_BUCKETS)

    for l in range(params.N_QPCR_BUCKETS):
        qpcr_scale_prior = pl.variables.SICS( 
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH),
            name=&#39;prior_&#39; + STRNAMES.QPCR_SCALES + &#39;_{}&#39;.format(l), G=GRAPH)
        qpcr_dof_prior = pl.variables.Uniform(
            low=pl.Constant(None, G=GRAPH),
            high=pl.Constant(None, G=GRAPH),
            name=&#39;prior_&#39; + STRNAMES.QPCR_DOFS + &#39;_{}&#39;.format(l), G=GRAPH)
        
        # add priors
        qpcr_dofs.value[l].add_prior(qpcr_dof_prior)
        qpcr_scales.value[l].add_prior(qpcr_scale_prior)

    # Allocate qpcr measurements into buckets
    mean_log_measurements = []
    indices = []
    for ridx in range(d.n_replicates):
        for tidx,t in enumerate(d.given_timepoints[ridx]):
            mean_log_measurements.append(np.mean(d.qpcr[ridx][t].log_data))
            indices.append((ridx, tidx))

    idxs = np.argsort(mean_log_measurements)
    l_len = int(len(mean_log_measurements)/params.N_QPCR_BUCKETS)
    logging.info(&#39;There are {} qPCR measurements for {} buckets. Each bucket is&#39; \
        &#39; {} measurements long&#39;.format(len(indices), params.N_QPCR_BUCKETS, l_len))

    iii = 0
    for l in range(params.N_QPCR_BUCKETS):
        # If it is the last bucket, assign the rest of the elements to it
        if l == params.N_QPCR_BUCKETS - 1:
            l_len = len(mean_log_measurements) - iii
        for i in range(l_len):
            idx = idxs[iii]
            ridx,tidx = indices[idx]
            qpcr_variances.add_qpcr_measurement(ridx=ridx, tidx=tidx, l=l)
            qpcr_dofs.add_qpcr_measurement(ridx=ridx, tidx=tidx, l=l)
            qpcr_scales.add_qpcr_measurement(ridx=ridx, tidx=tidx, l=l)
            iii += 1
    qpcr_dofs.set_shape()
    qpcr_scales.set_shape()

    # Set up inference and the inference order.
    # -----------------------------------------
    mcmc = pl.BaseMCMC(burnin=params.BURNIN, n_samples=params.N_SAMPLES, graph=GRAPH)
    order = []
    for name in params.INFERENCE_ORDER:
        if params.LEARN[name]:
            if not STRNAMES.is_perturbation_param(name):
                order.append(name)
            elif subjset.perturbations is not None:
                order.append(name)
    mcmc.set_inference_order(order)

    if intermediate_validation is not None:
        mcmc.set_intermediate_validation(**intermediate_validation)
    
    # Initialize the posterior and instantiate the design matrices
    # ------------------------------------------------------------
    for name in params.INITIALIZATION_ORDER:
        logging.info(&#39;Initializing {}&#39;.format(name))
        if STRNAMES.is_perturbation_param(name) and subjset.perturbations is None:
            logging.info(&#39;Skipping over {} because it is a perturbation parameter &#39; \
                &#39;and there are no perturbations&#39;.format(name))
            continue
        
        # Call `initialize`
        try:
            GRAPH[name].initialize(**params.INITIALIZATION_KWARGS[name])
        except Exception as error:
            logging.critical(&#39;Initialization in `{}` failed with the parameters: {}&#39;.format(
                name, params.INITIALIZATION_KWARGS[name]) + &#39; with the follwing error:\n{}&#39;.format(
                    error))
            for a in GRAPH._persistent_pntr:
                a.kill()
            raise

        # Initialize data matrices if necessary
        if name == STRNAMES.ZERO_INFLATION:
            # Initialize the basic data matrices after initializing filtering
            lhs = design_matrices.LHSVector(G=GRAPH, name=&#39;lhs_vector&#39;)
            lhs.build()
            growthDM = design_matrices.GrowthDesignMatrix(G=GRAPH)
            growthDM.build_without_perturbations()
            selfinteractionsDM = design_matrices.SelfInteractionDesignMatrix(G=GRAPH)
            selfinteractionsDM.build()
        if name == STRNAMES.CLUSTER_INTERACTION_INDICATOR:
            # Initialize the interactions data matrices after initializing the interactions
            interactionsDM = design_matrices.InteractionsDesignMatrix(G=GRAPH)
            interactionsDM.build()
        if name == STRNAMES.PERT_INDICATOR and subjset.perturbations is not None:
            # Initialize the perturbation data matrices after initializing the perturbations
            perturbationsDM = design_matrices.PerturbationDesignMatrix(G=GRAPH)
            perturbationsDM.base.build()
            perturbationsDM.M.build()
        if name == STRNAMES.PERT_VALUE and subjset.perturbations is not None:
            d.design_matrices[STRNAMES.GROWTH_VALUE].build_with_perturbations()

    logging.info(&#39;\n\n\n&#39;)
    logging.info(&#39;Initialization Values:&#39;)
    logging.info(&#39;Growth&#39;)
    logging.info(&#39;\tprior.loc: {}&#39;.format(GRAPH[STRNAMES.GROWTH_VALUE].prior.loc.value))
    logging.info(&#39;\tprior.scale2: {}&#39;.format(GRAPH[STRNAMES.GROWTH_VALUE].prior.scale2.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.GROWTH_VALUE].value.flatten()))

    logging.info(&#39;Self-Interactions&#39;)
    logging.info(&#39;\tprior.loc: {}&#39;.format(GRAPH[STRNAMES.SELF_INTERACTION_VALUE].prior.loc.value))
    logging.info(&#39;\tprior.scale2: {}&#39;.format(GRAPH[STRNAMES.SELF_INTERACTION_VALUE].prior.scale2.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.SELF_INTERACTION_VALUE].value.flatten()))

    logging.info(&#39;Prior Variance Growth&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_GROWTH].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_GROWTH].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_GROWTH].value))

    logging.info(&#39;Prior Variance Self-Interactions&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].value))

    logging.info(&#39;Prior Variance Interactions&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_INTERACTIONS].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_INTERACTIONS].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_INTERACTIONS].value))

    logging.info(&#39;Process Variance&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PROCESSVAR].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PROCESSVAR].prior.scale.value))
    logging.info(&#39;\tprior mean: {}&#39;.format(GRAPH[STRNAMES.PROCESSVAR].prior.mean()))

    logging.info(&#39;Concentration&#39;)
    logging.info(&#39;\tprior.shape: {}&#39;.format(GRAPH[STRNAMES.CONCENTRATION].prior.shape.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.CONCENTRATION].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.CONCENTRATION].value))

    logging.info(&#39;Indicator probability&#39;)
    logging.info(&#39;\tprior.a: {}&#39;.format(GRAPH[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].prior.a.value))
    logging.info(&#39;\tprior.b: {}&#39;.format(GRAPH[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].prior.b.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value))

    if subjset.perturbations is not None:
        logging.info(&#39;Perturbation values:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\tperturbation {}&#39;.format(perturbation.name))
            logging.info(&#39;\t\tvalue: {}&#39;.format(perturbation.magnitude.value))
            logging.info(&#39;\t\tprior.loc: {}&#39;.format(perturbation.magnitude.prior.loc.value))
        logging.info(&#39;Perturbation prior variances:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\t\tdof: {}&#39;.format(perturbation.magnitude.prior.scale2.prior.dof.value))
            logging.info(&#39;\t\tscale: {}&#39;.format(perturbation.magnitude.prior.scale2.prior.scale.value))
            logging.info(&#39;\t\tvalue: {}&#39;.format(perturbation.magnitude.prior.scale2.value))
        logging.info(&#39;Perturbation indicators:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\tperturbation {}: {}&#39;.format(perturbation.name,
                perturbation.indicator.cluster_array()))
        logging.info(&#39;Perturbation indicator probability:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\tperturbation {}&#39;.format(perturbation.name))
            logging.info(&#39;\t\tvalue: {}&#39;.format(perturbation.probability.value))
            logging.info(&#39;\t\tprior.a: {}&#39;.format(perturbation.probability.prior.a.value))
            logging.info(&#39;\t\tprior.b: {}&#39;.format(perturbation.probability.prior.b.value))

    logging.info(&#39;\n\n\n&#39;)

    # Setup filenames
    # ---------------
    hdf5_filename = os.path.join(basepath, config.HDF5_FILENAME)
    mcmc_filename = os.path.join(basepath, config.MCMC_FILENAME)
    mcmc.set_tracer(filename=hdf5_filename, checkpoint=params.CHECKPOINT)
    mcmc.set_save_location(mcmc_filename)
    params.save(os.path.join(basepath, config.PARAMS_FILENAME))
    pl.seed(params.SEED)

    return mcmc

def run_graph(mcmc: BaseMCMC, crash_if_error: bool=True) -&gt; BaseMCMC:
    &#39;&#39;&#39;Run the MCMC chain `mcmc`. Initialize the MCMC chain with `build_graph`

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        Inference object that is already built and initialized
    crash_if_error : bool
        If True, throws an error if there is an exception during inference. Otherwise
        it continues out of inference.

    Returns
    -------
    mdsine2.BaseMCMC
    &#39;&#39;&#39;
    try:
        mcmc.run(log_every=1)
    except Exception as e:
        logging.critical(&#39;CHAIN `{}` CRASHED&#39;.format(mcmc.graph.name))
        logging.critical(&#39;Error: {}&#39;.format(e))
        if crash_if_error:
            raise
    mcmc.graph[STRNAMES.FILTERING].kill()
    mcmc.graph[STRNAMES.CLUSTERING].kill()

    if mcmc.graph.data.subjects.qpcr_normalization_factor is not None:
        mcmc, mcmc.graph.data.subjects = denormalize_parameters(mcmc)
    mcmc.graph.data.design_matrices = None
    return mcmc

def normalize_parameters(mcmc: BaseMCMC, subjset: Study) -&gt; Tuple[BaseMCMC, Study]:
    &#39;&#39;&#39;Normalize the abundance of the parameters by the normalization factor
    in the subject set

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        This is the inference object that has all of the parameters in it
    subjset : mdsine2.Study
        This is the data object that contains all of the trajectories

    Returns
    -------
    mdsine2.BaseMCMC, mdsine2.Study
    &#39;&#39;&#39;
    GRAPH = mcmc.graph
    if subjset.qpcr_normalization_factor is None:
        f = h5py.File(GRAPH.tracer.filename, &#39;r+&#39;, libver=&#39;latest&#39;)
        checkpoint = GRAPH.tracer.checkpoint

        try:
            GRAPH[STRNAMES.FILTERING].v2 *= subjset.qpcr_normalization_factor
        except:
            logging.info(&#39;v2 not applicable&#39;)

        # Adjust the self interactions if necessary
        if STRNAMES.SELF_INTERACTION_VALUE in mcmc.tracer.being_traced:
            dset = f[STRNAMES.SELF_INTERACTION_VALUE]
            dset[:,:] = dset[:,:] / subjset.qpcr_normalization_factor

        if STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS in mcmc.tracer.being_traced:
            dset = f[STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS]
            dset[:] = dset[:] / subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_SELF_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS]
            dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_VARIANCES):
            vs = GRAPH[STRNAMES.QPCR_VARIANCES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_VARIANCES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_SCALES):
            vs = GRAPH[STRNAMES.QPCR_SCALES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_SCALES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        # Adjust the interactions if necessary
        if mcmc.tracer.is_being_traced(STRNAMES.INTERACTIONS_OBJ):
            dset = f[STRNAMES.INTERACTIONS_OBJ]
            total_samples = dset.attrs[&#39;end_iter&#39;]
            i = 0
            while (i * checkpoint) &lt; total_samples:
                start_idx = int(i * checkpoint)
                end_idx = int((i+1) * checkpoint)

                if end_idx &gt; total_samples:
                    end_idx = total_samples
                dset[start_idx: end_idx] = dset[start_idx: end_idx] / subjset.qpcr_normalization_factor
                i += 1
        
        if mcmc.is_in_inference_order(STRNAMES.PRIOR_MEAN_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_MEAN_INTERACTIONS]
            dset[:] = dset[:] / subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_INTERACTIONS]
            dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.FILTERING):
            for subj in subjset:
                name = STRNAMES.LATENT_TRAJECTORY + &#39;_{}&#39;.format(subj.name)
                if name not in f:
                    continue
                dset = f[name]
                total_samples = dset.attrs[&#39;end_iter&#39;]
                i = 0
                while (i * checkpoint) &lt; total_samples:
                    start_idx = int(i * checkpoint)
                    end_idx = int((i+1) * checkpoint)

                    if end_idx &gt; total_samples:
                        end_idx = total_samples
                    dset[start_idx: end_idx] = dset[start_idx: end_idx]*subjset.qpcr_normalization_factor
                    i += 1

        f.close()
    else:
        logging.info(&#39;Objects are already normalized&#39;)
    
    return mcmc, subjset

def denormalize_parameters(mcmc: BaseMCMC) -&gt; Tuple[BaseMCMC, Study]:
    &#39;&#39;&#39;Denormalize the abundance of the parameters by the normalization factor
    in the subject set

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        This is the inference object that has all of the parameters in it
    subjset : mdsine2.Study
        This is the data object that contains all of the trajectories

    Returns
    -------
    mdsine2.BaseMCMC, mdsine2.Study
    &#39;&#39;&#39;
    GRAPH = mcmc.graph
    subjset = mcmc.graph.data.subjects
    if subjset.qpcr_normalization_factor is not None:
        logging.info(&#39;Denormalizing the parameters&#39;)

        f = h5py.File(GRAPH.tracer.filename, &#39;r+&#39;, libver=&#39;latest&#39;)
        checkpoint = GRAPH.tracer.checkpoint

        try:
            GRAPH[STRNAMES.FILTERING].v2 /= subjset.qpcr_normalization_factor
        except:
            logging.info(&#39;v2 not applicable&#39;)

        # Adjust the self interactions if necessary
        if STRNAMES.SELF_INTERACTION_VALUE in mcmc.tracer.being_traced:
            dset = f[STRNAMES.SELF_INTERACTION_VALUE]
            dset[:,:] = dset[:,:] * subjset.qpcr_normalization_factor

        if STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS in mcmc.tracer.being_traced:
            dset = f[STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS]
            dset[:] = dset[:] * subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_SELF_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS]
            dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_VARIANCES):
            vs = GRAPH[STRNAMES.QPCR_VARIANCES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_VARIANCES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_SCALES):
            vs = GRAPH[STRNAMES.QPCR_SCALES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_SCALES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        # Adjust the interactions if necessary
        if mcmc.tracer.is_being_traced(STRNAMES.INTERACTIONS_OBJ):
            dset = f[STRNAMES.INTERACTIONS_OBJ]
            total_samples = dset.attrs[&#39;end_iter&#39;]
            i = 0
            while (i * checkpoint) &lt; total_samples:
                start_idx = int(i * checkpoint)
                end_idx = int((i+1) * checkpoint)

                if end_idx &gt; total_samples:
                    end_idx = total_samples
                dset[start_idx: end_idx] = dset[start_idx: end_idx] * subjset.qpcr_normalization_factor
                i += 1
        
        if mcmc.is_in_inference_order(STRNAMES.PRIOR_MEAN_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_MEAN_INTERACTIONS]
            dset[:] = dset[:] * subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_INTERACTIONS]
            dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.FILTERING):
            for subj in subjset:
                name = STRNAMES.LATENT_TRAJECTORY + &#39;_{}&#39;.format(subj.name)
                if name not in f:
                    continue
                dset = f[name]
                total_samples = dset.attrs[&#39;end_iter&#39;]
                i = 0
                while (i * checkpoint) &lt; total_samples:
                    start_idx = int(i * checkpoint)
                    end_idx = int((i+1) * checkpoint)

                    if end_idx &gt; total_samples:
                        end_idx = total_samples
                    dset[start_idx: end_idx] = dset[start_idx: end_idx]/subjset.qpcr_normalization_factor
                    i += 1

        f.close()
        subjset.denormalize_qpcr()
        mcmc.save()
    else:
        logging.info(&#39;Data already denormalized&#39;)
    return mcmc, subjset

def calculate_stability_over_gibbs(mcmc: BaseMCMC, section: str=&#39;auto&#39;, log_every: int=1000) -&gt; np.ndarray:
    &#39;&#39;&#39;Calculate the stability over each of the Gibb steps in the chain `mcmc`

    stability = diag(r) @ A, where
        r : growth rates
        A : interaction matrix

    Note that if the growth, self_interactions, or interactions are fixed during inference,
    we use the fixed values

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        Inference object that contains the traces
    section : str
        This is the section of the trace we are calculating over. Options:
            &#39;entire&#39; : burn-in and the posterior
            &#39;burnin&#39; : just the burn-in samples
            &#39;posterior&#39; : just the posterior samples
            &#39;auto&#39; : most robust choice. If the chain did not do the total number of
                Gibb steps, it will only calcualte the stability over the Gibb steps that
                it has samples for. If the number is less than the burn-in, it will return the
                stability over the burn-in. If the number of Gibb steps is greater than the 
                number of burn-in. It will only return the stability of the samples in the posterior.
                If the inference has done the total number of gibb samples, then it is done over the
                entire posterior.
    log_every : int, None
        Print out the Gibb step the stability calcualtion is currently doing ever `log_every` Gibb
        steps. If None then there is not display.
    
    Returns
    -------
    np.ndarray (n_gibb, n_taxa, n_taxa)
    &#39;&#39;&#39;
    # Type check
    # ----------
    if not pl.isMCMC(mcmc):
        raise TypeError(&#39;`mcmc` ({}) must be a mdsine2.BaseMCMC object&#39;.format(type(mcmc)))
    if log_every is not None:
        if not pl.isint(log_every):
            raise TypeError(&#39;`log_every` ({}) must be an int&#39;.format(type(log_every)))
        if log_every &lt;= 0:
            raise ValueError(&#39;`log_every` ({}) must be &gt; 0&#39;.format(log_every))

    smaller_arr = False
    if not pl.isstr(section):
        raise TypeError(&#39;`section` ({}) must be a str&#39;.format(type(section)))
    if section == &#39;burnin&#39;:
        if mcmc.sample_iter &gt;= mcmc.burnin:
            LEN_ARR = mcmc.burnin
        else:
            raise ValueError(&#39;chain `{}` only has {} Gibb steps but you chose to `burnin` ({}) section.&#39;.format(
                mcmc.graph.name, mcmc.sample_iter, mcmc.burnin))
    elif section == &#39;posterior&#39;:
        if mcmc.ran:
            LEN_ARR = mcmc.n_samples - mcmc.burnin
        else:
            raise ValueError(&#39;chain `{}` only has {} Gibb steps but you chose to `posterior` ({}) section.&#39;.format(
                mcmc.graph.name, mcmc.sample_iter, mcmc.n_samples))
    elif section == &#39;entire&#39;:
        if mcmc.ran:
            LEN_ARR = mcmc.n_samples
        else:
            raise ValueError(&#39;chain `{}` only has {} Gibb steps but you chose to `entire` ({}) section.&#39;.format(
                mcmc.graph.name, mcmc.sample_iter, mcmc.n_samples))
    elif section == &#39;auto&#39;:
        if mcmc.ran:
            LEN_ARR = mcmc.n_samples
            section=&#39;posterior&#39;
        elif mcmc.sample_iter &gt; mcmc.burnin:
            section = &#39;posterior&#39;
            LEN_ARR = mcmc.sample_iter + 1 - mcmc.burnin
            smaller_arr = True
        else:
            section = &#39;burnin&#39;
            LEN_ARR = mcmc.sample_iter + 1
            smaller_arr = True
    else:
        raise ValueError(&#39;`section` ({}) not recognized&#39;.format(section))

    # Load data
    # ---------
    N_TAXA = len(mcmc.graph.data.taxa)
    logging.info(&#39;Loading data for stability&#39;)
    growth = mcmc.graph[STRNAMES.GROWTH_VALUE]
    if mcmc.tracer.is_being_traced(STRNAMES.GROWTH_VALUE):
        growth = growth.get_trace_from_disk(section=section)
        if smaller_arr:
            growth = growth[:LEN_ARR, ...]
    else:
        growth = growth.value
        growth = growth.reshape(-1,1) + np.zeros(shape=(LEN_ARR, N_TAXA))

    si = mcmc.graph[STRNAMES.SELF_INTERACTION_VALUE]
    if mcmc.tracer.is_being_traced(STRNAMES.SELF_INTERACTION_VALUE):
        si = si.get_trace_from_disk(section=section)
        if smaller_arr:
            si = si[:LEN_ARR, ...]
    else:
        si = si.value
        si = si.reshape(-1,1) + np.zeros(shape=(LEN_ARR, N_TAXA))

    interactions = mcmc.graph[STRNAMES.GROWTH_VALUE]
    if mcmc.tracer.is_being_traced(STRNAMES.GROWTH_VALUE):
        interactions = interactions.get_trace_from_disk(section=section)
        interactions[np.isnan(interactions)] = 0
        if smaller_arr:
            interactions = interactions[:LEN_ARR, ...]
    else:
        interactions = interactions.get_datalevel_value_matrix(set_neg_indicators_to_nan=False)
        interactions = interactions.reshape(-1,1) + np.zeros(shape=(LEN_ARR, N_TAXA, N_TAXA))

    # Set the self-interactions as the diagonal
    for i in range(N_TAXA):
        interactions[:,i,i] = - np.absolute(si[:, i])

    # Calculate stability
    # -------------------
    if log_every is None:
        log_every = LEN_ARR + 1
    ret = np.zeros(shape=interactions.shape)
    for i in range(ret.shape[0]):
        if i % log_every == 0:
            if i == 0:
                continue
            else:
                logging.info(&#39;{}/{}&#39;.foramt(i, LEN_ARR))
        
        ret[i] = np.diag(growth[i]) @ interactions[i]
    return ret</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="mdsine2.run.calculate_stability_over_gibbs"><code class="name flex">
<span>def <span class="ident">calculate_stability_over_gibbs</span></span>(<span>mcmc: <a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a>, section: str = 'auto', log_every: int = 1000) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the stability over each of the Gibb steps in the chain <code>mcmc</code></p>
<p>stability = diag(r) @ A, where
r : growth rates
A : interaction matrix</p>
<p>Note that if the growth, self_interactions, or interactions are fixed during inference,
we use the fixed values</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>mcmc</code></strong> :&ensp;<code>mdsine2.BaseMCMC</code></dt>
<dd>Inference object that contains the traces</dd>
<dt><strong><code>section</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the section of the trace we are calculating over. Options:
'entire' : burn-in and the posterior
'burnin' : just the burn-in samples
'posterior' : just the posterior samples
'auto' : most robust choice. If the chain did not do the total number of
Gibb steps, it will only calcualte the stability over the Gibb steps that
it has samples for. If the number is less than the burn-in, it will return the
stability over the burn-in. If the number of Gibb steps is greater than the
number of burn-in. It will only return the stability of the samples in the posterior.
If the inference has done the total number of gibb samples, then it is done over the
entire posterior.</dd>
<dt><strong><code>log_every</code></strong> :&ensp;<code>int, None</code></dt>
<dd>Print out the Gibb step the stability calcualtion is currently doing ever <code>log_every</code> Gibb
steps. If None then there is not display.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray (n_gibb, n_taxa, n_taxa)</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_stability_over_gibbs(mcmc: BaseMCMC, section: str=&#39;auto&#39;, log_every: int=1000) -&gt; np.ndarray:
    &#39;&#39;&#39;Calculate the stability over each of the Gibb steps in the chain `mcmc`

    stability = diag(r) @ A, where
        r : growth rates
        A : interaction matrix

    Note that if the growth, self_interactions, or interactions are fixed during inference,
    we use the fixed values

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        Inference object that contains the traces
    section : str
        This is the section of the trace we are calculating over. Options:
            &#39;entire&#39; : burn-in and the posterior
            &#39;burnin&#39; : just the burn-in samples
            &#39;posterior&#39; : just the posterior samples
            &#39;auto&#39; : most robust choice. If the chain did not do the total number of
                Gibb steps, it will only calcualte the stability over the Gibb steps that
                it has samples for. If the number is less than the burn-in, it will return the
                stability over the burn-in. If the number of Gibb steps is greater than the 
                number of burn-in. It will only return the stability of the samples in the posterior.
                If the inference has done the total number of gibb samples, then it is done over the
                entire posterior.
    log_every : int, None
        Print out the Gibb step the stability calcualtion is currently doing ever `log_every` Gibb
        steps. If None then there is not display.
    
    Returns
    -------
    np.ndarray (n_gibb, n_taxa, n_taxa)
    &#39;&#39;&#39;
    # Type check
    # ----------
    if not pl.isMCMC(mcmc):
        raise TypeError(&#39;`mcmc` ({}) must be a mdsine2.BaseMCMC object&#39;.format(type(mcmc)))
    if log_every is not None:
        if not pl.isint(log_every):
            raise TypeError(&#39;`log_every` ({}) must be an int&#39;.format(type(log_every)))
        if log_every &lt;= 0:
            raise ValueError(&#39;`log_every` ({}) must be &gt; 0&#39;.format(log_every))

    smaller_arr = False
    if not pl.isstr(section):
        raise TypeError(&#39;`section` ({}) must be a str&#39;.format(type(section)))
    if section == &#39;burnin&#39;:
        if mcmc.sample_iter &gt;= mcmc.burnin:
            LEN_ARR = mcmc.burnin
        else:
            raise ValueError(&#39;chain `{}` only has {} Gibb steps but you chose to `burnin` ({}) section.&#39;.format(
                mcmc.graph.name, mcmc.sample_iter, mcmc.burnin))
    elif section == &#39;posterior&#39;:
        if mcmc.ran:
            LEN_ARR = mcmc.n_samples - mcmc.burnin
        else:
            raise ValueError(&#39;chain `{}` only has {} Gibb steps but you chose to `posterior` ({}) section.&#39;.format(
                mcmc.graph.name, mcmc.sample_iter, mcmc.n_samples))
    elif section == &#39;entire&#39;:
        if mcmc.ran:
            LEN_ARR = mcmc.n_samples
        else:
            raise ValueError(&#39;chain `{}` only has {} Gibb steps but you chose to `entire` ({}) section.&#39;.format(
                mcmc.graph.name, mcmc.sample_iter, mcmc.n_samples))
    elif section == &#39;auto&#39;:
        if mcmc.ran:
            LEN_ARR = mcmc.n_samples
            section=&#39;posterior&#39;
        elif mcmc.sample_iter &gt; mcmc.burnin:
            section = &#39;posterior&#39;
            LEN_ARR = mcmc.sample_iter + 1 - mcmc.burnin
            smaller_arr = True
        else:
            section = &#39;burnin&#39;
            LEN_ARR = mcmc.sample_iter + 1
            smaller_arr = True
    else:
        raise ValueError(&#39;`section` ({}) not recognized&#39;.format(section))

    # Load data
    # ---------
    N_TAXA = len(mcmc.graph.data.taxa)
    logging.info(&#39;Loading data for stability&#39;)
    growth = mcmc.graph[STRNAMES.GROWTH_VALUE]
    if mcmc.tracer.is_being_traced(STRNAMES.GROWTH_VALUE):
        growth = growth.get_trace_from_disk(section=section)
        if smaller_arr:
            growth = growth[:LEN_ARR, ...]
    else:
        growth = growth.value
        growth = growth.reshape(-1,1) + np.zeros(shape=(LEN_ARR, N_TAXA))

    si = mcmc.graph[STRNAMES.SELF_INTERACTION_VALUE]
    if mcmc.tracer.is_being_traced(STRNAMES.SELF_INTERACTION_VALUE):
        si = si.get_trace_from_disk(section=section)
        if smaller_arr:
            si = si[:LEN_ARR, ...]
    else:
        si = si.value
        si = si.reshape(-1,1) + np.zeros(shape=(LEN_ARR, N_TAXA))

    interactions = mcmc.graph[STRNAMES.GROWTH_VALUE]
    if mcmc.tracer.is_being_traced(STRNAMES.GROWTH_VALUE):
        interactions = interactions.get_trace_from_disk(section=section)
        interactions[np.isnan(interactions)] = 0
        if smaller_arr:
            interactions = interactions[:LEN_ARR, ...]
    else:
        interactions = interactions.get_datalevel_value_matrix(set_neg_indicators_to_nan=False)
        interactions = interactions.reshape(-1,1) + np.zeros(shape=(LEN_ARR, N_TAXA, N_TAXA))

    # Set the self-interactions as the diagonal
    for i in range(N_TAXA):
        interactions[:,i,i] = - np.absolute(si[:, i])

    # Calculate stability
    # -------------------
    if log_every is None:
        log_every = LEN_ARR + 1
    ret = np.zeros(shape=interactions.shape)
    for i in range(ret.shape[0]):
        if i % log_every == 0:
            if i == 0:
                continue
            else:
                logging.info(&#39;{}/{}&#39;.foramt(i, LEN_ARR))
        
        ret[i] = np.diag(growth[i]) @ interactions[i]
    return ret</code></pre>
</details>
</dd>
<dt id="mdsine2.run.denormalize_parameters"><code class="name flex">
<span>def <span class="ident">denormalize_parameters</span></span>(<span>mcmc: <a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a>) ‑> Tuple[<a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a>, <a title="mdsine2.pylab.base.Study" href="pylab/base.html#mdsine2.pylab.base.Study">Study</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Denormalize the abundance of the parameters by the normalization factor
in the subject set</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>mcmc</code></strong> :&ensp;<code>mdsine2.BaseMCMC</code></dt>
<dd>This is the inference object that has all of the parameters in it</dd>
<dt><strong><code>subjset</code></strong> :&ensp;<code>mdsine2.Study</code></dt>
<dd>This is the data object that contains all of the trajectories</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.BaseMCMC, mdsine2.Study</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def denormalize_parameters(mcmc: BaseMCMC) -&gt; Tuple[BaseMCMC, Study]:
    &#39;&#39;&#39;Denormalize the abundance of the parameters by the normalization factor
    in the subject set

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        This is the inference object that has all of the parameters in it
    subjset : mdsine2.Study
        This is the data object that contains all of the trajectories

    Returns
    -------
    mdsine2.BaseMCMC, mdsine2.Study
    &#39;&#39;&#39;
    GRAPH = mcmc.graph
    subjset = mcmc.graph.data.subjects
    if subjset.qpcr_normalization_factor is not None:
        logging.info(&#39;Denormalizing the parameters&#39;)

        f = h5py.File(GRAPH.tracer.filename, &#39;r+&#39;, libver=&#39;latest&#39;)
        checkpoint = GRAPH.tracer.checkpoint

        try:
            GRAPH[STRNAMES.FILTERING].v2 /= subjset.qpcr_normalization_factor
        except:
            logging.info(&#39;v2 not applicable&#39;)

        # Adjust the self interactions if necessary
        if STRNAMES.SELF_INTERACTION_VALUE in mcmc.tracer.being_traced:
            dset = f[STRNAMES.SELF_INTERACTION_VALUE]
            dset[:,:] = dset[:,:] * subjset.qpcr_normalization_factor

        if STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS in mcmc.tracer.being_traced:
            dset = f[STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS]
            dset[:] = dset[:] * subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_SELF_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS]
            dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_VARIANCES):
            vs = GRAPH[STRNAMES.QPCR_VARIANCES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_VARIANCES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_SCALES):
            vs = GRAPH[STRNAMES.QPCR_SCALES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_SCALES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        # Adjust the interactions if necessary
        if mcmc.tracer.is_being_traced(STRNAMES.INTERACTIONS_OBJ):
            dset = f[STRNAMES.INTERACTIONS_OBJ]
            total_samples = dset.attrs[&#39;end_iter&#39;]
            i = 0
            while (i * checkpoint) &lt; total_samples:
                start_idx = int(i * checkpoint)
                end_idx = int((i+1) * checkpoint)

                if end_idx &gt; total_samples:
                    end_idx = total_samples
                dset[start_idx: end_idx] = dset[start_idx: end_idx] * subjset.qpcr_normalization_factor
                i += 1
        
        if mcmc.is_in_inference_order(STRNAMES.PRIOR_MEAN_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_MEAN_INTERACTIONS]
            dset[:] = dset[:] * subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_INTERACTIONS]
            dset[:] = dset[:] * (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.FILTERING):
            for subj in subjset:
                name = STRNAMES.LATENT_TRAJECTORY + &#39;_{}&#39;.format(subj.name)
                if name not in f:
                    continue
                dset = f[name]
                total_samples = dset.attrs[&#39;end_iter&#39;]
                i = 0
                while (i * checkpoint) &lt; total_samples:
                    start_idx = int(i * checkpoint)
                    end_idx = int((i+1) * checkpoint)

                    if end_idx &gt; total_samples:
                        end_idx = total_samples
                    dset[start_idx: end_idx] = dset[start_idx: end_idx]/subjset.qpcr_normalization_factor
                    i += 1

        f.close()
        subjset.denormalize_qpcr()
        mcmc.save()
    else:
        logging.info(&#39;Data already denormalized&#39;)
    return mcmc, subjset</code></pre>
</details>
</dd>
<dt id="mdsine2.run.initialize_graph"><code class="name flex">
<span>def <span class="ident">initialize_graph</span></span>(<span>params: <a title="mdsine2.config.MDSINE2ModelConfig" href="config.html#mdsine2.config.MDSINE2ModelConfig">MDSINE2ModelConfig</a>, graph_name: str, subjset: <a title="mdsine2.pylab.base.Study" href="pylab/base.html#mdsine2.pylab.base.Study">Study</a>, continue_inference: int = None, intermediate_validation: Dict[str, Union[float, Callable, Dict[str, Any]]] = None) ‑> <a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a></span>
</code></dt>
<dd>
<div class="desc"><p>Builds the graph with the posterior classes and creates an
mdsine2.BaseMCMC inference chain object that you ran run inference with</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code><a title="mdsine2.config.MDSINE2ModelConfig" href="config.html#mdsine2.config.MDSINE2ModelConfig">MDSINE2ModelConfig</a></code></dt>
<dd>This class specifies all of the parameters of the model.</dd>
<dt><strong><code>graph_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the graph you want to build</dd>
<dt><strong><code>subjset</code></strong> :&ensp;<code>mdsine2.Study</code></dt>
<dd>This is the subjectset that contains all of the trajectories for inference.
Note that this subjectset has already been filtered</dd>
<dt><strong><code>continue_inference</code></strong> :&ensp;<code>int, None</code></dt>
<dd>Gibb sample to restart inference from</dd>
<dt><strong><code>intermediate_validation</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionary with the following arguments:
't' : float
This is how often, in seconds, you want to run this function
'func' : callable
This function is called every <code>t</code> seconds
'kwargs' : dict
These are additional arguments to pass into fucntion <code>func</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pl.inference.BaseMCMC</code></dt>
<dd>Inference chain</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize_graph(params: config.MDSINE2ModelConfig, graph_name: str, subjset: Study, continue_inference: int=None, 
    intermediate_validation: Dict[str, Union[float, Callable, Dict[str, Any]]]=None) -&gt; BaseMCMC:
    &#39;&#39;&#39;Builds the graph with the posterior classes and creates an
    mdsine2.BaseMCMC inference chain object that you ran run inference with

    Parameters
    ----------
    params : mdsine2.config.MDSINE2ModelConfig
        This class specifies all of the parameters of the model.
    graph_name : str
        Name of the graph you want to build
    subjset : mdsine2.Study
        This is the subjectset that contains all of the trajectories for inference.
        Note that this subjectset has already been filtered
    continue_inference : int, None
        Gibb sample to restart inference from
    intermediate_validation : dict
        A dictionary with the following arguments:
            &#39;t&#39; : float
                This is how often, in seconds, you want to run this function
            &#39;func&#39; : callable
                This function is called every `t` seconds
            &#39;kwargs&#39; : dict
                These are additional arguments to pass into fucntion `func`

    Returns
    -------
    pl.inference.BaseMCMC
        Inference chain
    &#39;&#39;&#39;
    # Type Check
    # ----------
    if not config.isModelConfig(params):
        raise TypeError(&#39;`params` ({}) needs to be a config.ModelConfig object&#39;.format(type(params)))
    if not pl.isstudy(subjset):
        raise TypeError(&#39;`subjset` ({}) must be a mdsine2.Study&#39;.format(type(subjset)))
    if not pl.isstr(graph_name):
        raise TypeError(&#39;`graph_name` ({}) must be a str&#39;.format(type(graph_name)))
    if continue_inference is not None:
        if not pl.isint(continue_inference):
            raise TypeError(&#39;`continue_inference` ({}) must be an int&#39;.format(type(continue_inference)))
        if continue_inference &lt;= 0:
            raise ValueError(&#39;`continue_inference` ({}0 must be &gt; 0&#39;.format(continue_inference))

        GRAPH = pl.graph.Graph.load(params.GRAPH_FILENAME)
    else:
        GRAPH = pl.Graph(name=graph_name, seed=params.SEED)
    GRAPH.as_default()
    pl.seed(params.SEED)

    # Continue inference if necessary
    # -------------------------------
    if continue_inference is not None:
        logging.info(&#39;Continuing inference at Gibb step {}&#39;.format(continue_inference))
        mcmc = pl.inference.BaseMCMC.load(params.MCMC_FILENAME)
        mcmc.continue_inference(gibb_step_start=continue_inference)

        return mcmc

    # Make the basepath
    # -----------------
    basepath = params.OUTPUT_BASEPATH
    os.makedirs(basepath, exist_ok=True)

    # Normalize the qpcr measurements for numerical stability
    # -------------------------------------------------------
    if params.QPCR_NORMALIZATION_MAX_VALUE is not None:
        subjset.normalize_qpcr(max_value=params.QPCR_NORMALIZATION_MAX_VALUE)
        logging.info(&#39;Normalizing abundances for a max value of {}. Normalization &#39; \
            &#39;constant: {:.4E}&#39;.format(params.QPCR_NORMALIZATION_MAX_VALUE, 
            subjset.qpcr_normalization_factor))
        
        params.INITIALIZATION_KWARGS[STRNAMES.FILTERING][&#39;v2&#39;] *= subjset.qpcr_normalization_factor
        params.INITIALIZATION_KWARGS[STRNAMES.SELF_INTERACTION_VALUE][&#39;rescale_value&#39;] = \
            subjset.qpcr_normalization_factor
    
    subjset_filename = os.path.join(basepath, config.SUBJSET_FILENAME)
    subjset.save(subjset_filename)

    # Instantiate the posterior classes
    # ---------------------------------
    taxa = subjset.taxa
    d = design_matrices.Data(subjects=subjset, G=GRAPH, 
        zero_inflation_transition_policy=params.ZERO_INFLATION_TRANSITION_POLICY)
    clustering = pl.Clustering(clusters=None, items=taxa, G=GRAPH,
        name=STRNAMES.CLUSTERING_OBJ)

    # Interactions
    var_interactions = posterior.PriorVarInteractions(
        prior=pl.variables.SICS(
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH), 
        G=GRAPH), G=GRAPH)
    mean_interactions = posterior.PriorMeanInteractions(
        prior=pl.variables.Normal(
            loc=pl.Constant(None, G=GRAPH),
            scale2=pl.Constant(None, G=GRAPH), 
        G=GRAPH), G=GRAPH)
    interaction_value = pl.variables.Normal(
        loc=mean_interactions, scale2=var_interactions, G=GRAPH)

    interaction_indicator = posterior.ClusterInteractionIndicatorProbability(
        prior=pl.variables.Beta(a=pl.Constant(None, G=GRAPH), b=pl.Constant(None, G=GRAPH), G=GRAPH),
        G=GRAPH)
    interactions = posterior.ClusterInteractionValue(
        prior=interaction_value, clustering=clustering, G=GRAPH)
    Z = posterior.ClusterInteractionIndicators(prior=interaction_indicator, G=GRAPH)

    # Growth
    var_growth = posterior.PriorVarMH(
        prior=pl.variables.SICS(
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH), G=GRAPH),
        child_name=STRNAMES.GROWTH_VALUE, G=GRAPH)
    mean_growth = posterior.PriorMeanMH(
        prior=pl.variables.TruncatedNormal(
            loc=pl.Constant(None, G=GRAPH),
            scale2=pl.Constant(None, G=GRAPH), G=GRAPH), 
        child_name=STRNAMES.GROWTH_VALUE, G=GRAPH)
    prior_growth = pl.variables.Normal(
        loc=mean_growth, scale2=var_growth,
        name=&#39;prior_{}&#39;.format(STRNAMES.GROWTH_VALUE), G=GRAPH)
    growth = posterior.Growth(prior=prior_growth, G=GRAPH)

    # Self-Interactions
    var_si = posterior.PriorVarMH(
        prior=pl.variables.SICS(
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH), G=GRAPH),
        child_name=STRNAMES.SELF_INTERACTION_VALUE, G=GRAPH)
    mean_si = posterior.PriorMeanMH(
        prior=pl.variables.TruncatedNormal(
            loc=pl.Constant(None, G=GRAPH),
            scale2=pl.Constant(None, G=GRAPH), G=GRAPH), 
        child_name=STRNAMES.SELF_INTERACTION_VALUE, G=GRAPH)
    prior_si = pl.variables.Normal(
        loc=mean_si, scale2=var_si,
        name=&#39;prior_{}&#39;.format(STRNAMES.SELF_INTERACTION_VALUE), G=GRAPH)
    self_interactions = posterior.SelfInteractions(prior=prior_si, G=GRAPH)

    # Process Variance
    prior_processvar = pl.variables.SICS( 
        dof=pl.Constant(None, G=GRAPH),
        scale=pl.Constant(None, G=GRAPH), G=GRAPH)
    processvar = posterior.ProcessVarGlobal(G=GRAPH, prior=prior_processvar)

    # Clustering
    prior_concentration = pl.variables.Gamma(
        shape=pl.Constant(None, G=GRAPH),
        scale=pl.Constant(None, G=GRAPH),
        G=GRAPH)
    concentration = posterior.Concentration(
        prior=prior_concentration, G=GRAPH)
    cluster_assignments = posterior.ClusterAssignments(
        clustering=clustering, concentration=concentration,
        G=GRAPH, mp=params.MP_CLUSTERING)

    # Filtering and zero inflation
    filtering = posterior.FilteringLogMP(G=GRAPH, mp=params.MP_FILTERING, 
        zero_inflation_transition_policy=params.ZERO_INFLATION_TRANSITION_POLICY)
    zero_inflation = posterior.ZeroInflation(G=GRAPH)

    # Perturbations
    if subjset.perturbations is not None:
        for pidx, subj_pert in enumerate(subjset.perturbations):
            name = subj_pert.name
            perturbation = pl.ClusterPerturbationEffect(
                starts=subj_pert.starts, ends=subj_pert.ends, 
                probability=pl.variables.Beta(
                    name=name + &#39;_probability&#39;, G=GRAPH, value=None, a=None, b=None),
                clustering=clustering, G=GRAPH, name=name,
                signal_when_clusters_change=False, signal_when_item_assignment_changes=False)

            magnitude_var = posterior.PriorVarPerturbationSingle(
                prior=pl.variables.SICS(
                    dof=pl.Constant(None, G=GRAPH),
                    scale=pl.Constant(None, G=GRAPH), G=GRAPH), 
                perturbation=perturbation, G=GRAPH)
            magnitude_mean = posterior.PriorMeanPerturbationSingle(
                prior=pl.variables.Normal(
                    loc=pl.Constant(None, G=GRAPH),
                    scale2=pl.Constant(None, G=GRAPH),
                    G=GRAPH), 
                perturbation=perturbation, G=GRAPH)
            prior_magnitude = pl.variables.Normal(G=GRAPH, loc=magnitude_mean, scale2=magnitude_var)
            perturbation.magnitude.add_prior(prior_magnitude)

            prior_prob = pl.variables.Beta(
                a=pl.Constant(None, G=GRAPH),
                b=pl.Constant(None, G=GRAPH),
                G=GRAPH)
            perturbation.probability.add_prior(prior_prob)
        
        magnitude_var_perts = posterior.PriorVarPerturbations(G=GRAPH)
        magnitude_mean_perts = posterior.PriorMeanPerturbations(G=GRAPH)
        magnitude_perts = posterior.PerturbationMagnitudes(G=GRAPH)
        indicator_perts = posterior.PerturbationIndicators(G=GRAPH, need_to_trace=False, relative=True)
        indicator_prob_perts = posterior.PerturbationProbabilities(G=GRAPH)
    else:
        magnitude_perts = None
        pert_ind = None
        pert_ind_prob = None

    beta = posterior.GLVParameters(
        growth=growth, self_interactions=self_interactions,
        interactions=interactions, pert_mag=magnitude_perts, G=GRAPH)

    # Set qPCR variance priors and hyper priors
    qpcr_variances = posterior.qPCRVariances(G=GRAPH, L=params.N_QPCR_BUCKETS)
    qpcr_dofs = posterior.qPCRDegsOfFreedoms(G=GRAPH, L=params.N_QPCR_BUCKETS)
    qpcr_scales = posterior.qPCRScales(G=GRAPH, L=params.N_QPCR_BUCKETS)

    for l in range(params.N_QPCR_BUCKETS):
        qpcr_scale_prior = pl.variables.SICS( 
            dof=pl.Constant(None, G=GRAPH),
            scale=pl.Constant(None, G=GRAPH),
            name=&#39;prior_&#39; + STRNAMES.QPCR_SCALES + &#39;_{}&#39;.format(l), G=GRAPH)
        qpcr_dof_prior = pl.variables.Uniform(
            low=pl.Constant(None, G=GRAPH),
            high=pl.Constant(None, G=GRAPH),
            name=&#39;prior_&#39; + STRNAMES.QPCR_DOFS + &#39;_{}&#39;.format(l), G=GRAPH)
        
        # add priors
        qpcr_dofs.value[l].add_prior(qpcr_dof_prior)
        qpcr_scales.value[l].add_prior(qpcr_scale_prior)

    # Allocate qpcr measurements into buckets
    mean_log_measurements = []
    indices = []
    for ridx in range(d.n_replicates):
        for tidx,t in enumerate(d.given_timepoints[ridx]):
            mean_log_measurements.append(np.mean(d.qpcr[ridx][t].log_data))
            indices.append((ridx, tidx))

    idxs = np.argsort(mean_log_measurements)
    l_len = int(len(mean_log_measurements)/params.N_QPCR_BUCKETS)
    logging.info(&#39;There are {} qPCR measurements for {} buckets. Each bucket is&#39; \
        &#39; {} measurements long&#39;.format(len(indices), params.N_QPCR_BUCKETS, l_len))

    iii = 0
    for l in range(params.N_QPCR_BUCKETS):
        # If it is the last bucket, assign the rest of the elements to it
        if l == params.N_QPCR_BUCKETS - 1:
            l_len = len(mean_log_measurements) - iii
        for i in range(l_len):
            idx = idxs[iii]
            ridx,tidx = indices[idx]
            qpcr_variances.add_qpcr_measurement(ridx=ridx, tidx=tidx, l=l)
            qpcr_dofs.add_qpcr_measurement(ridx=ridx, tidx=tidx, l=l)
            qpcr_scales.add_qpcr_measurement(ridx=ridx, tidx=tidx, l=l)
            iii += 1
    qpcr_dofs.set_shape()
    qpcr_scales.set_shape()

    # Set up inference and the inference order.
    # -----------------------------------------
    mcmc = pl.BaseMCMC(burnin=params.BURNIN, n_samples=params.N_SAMPLES, graph=GRAPH)
    order = []
    for name in params.INFERENCE_ORDER:
        if params.LEARN[name]:
            if not STRNAMES.is_perturbation_param(name):
                order.append(name)
            elif subjset.perturbations is not None:
                order.append(name)
    mcmc.set_inference_order(order)

    if intermediate_validation is not None:
        mcmc.set_intermediate_validation(**intermediate_validation)
    
    # Initialize the posterior and instantiate the design matrices
    # ------------------------------------------------------------
    for name in params.INITIALIZATION_ORDER:
        logging.info(&#39;Initializing {}&#39;.format(name))
        if STRNAMES.is_perturbation_param(name) and subjset.perturbations is None:
            logging.info(&#39;Skipping over {} because it is a perturbation parameter &#39; \
                &#39;and there are no perturbations&#39;.format(name))
            continue
        
        # Call `initialize`
        try:
            GRAPH[name].initialize(**params.INITIALIZATION_KWARGS[name])
        except Exception as error:
            logging.critical(&#39;Initialization in `{}` failed with the parameters: {}&#39;.format(
                name, params.INITIALIZATION_KWARGS[name]) + &#39; with the follwing error:\n{}&#39;.format(
                    error))
            for a in GRAPH._persistent_pntr:
                a.kill()
            raise

        # Initialize data matrices if necessary
        if name == STRNAMES.ZERO_INFLATION:
            # Initialize the basic data matrices after initializing filtering
            lhs = design_matrices.LHSVector(G=GRAPH, name=&#39;lhs_vector&#39;)
            lhs.build()
            growthDM = design_matrices.GrowthDesignMatrix(G=GRAPH)
            growthDM.build_without_perturbations()
            selfinteractionsDM = design_matrices.SelfInteractionDesignMatrix(G=GRAPH)
            selfinteractionsDM.build()
        if name == STRNAMES.CLUSTER_INTERACTION_INDICATOR:
            # Initialize the interactions data matrices after initializing the interactions
            interactionsDM = design_matrices.InteractionsDesignMatrix(G=GRAPH)
            interactionsDM.build()
        if name == STRNAMES.PERT_INDICATOR and subjset.perturbations is not None:
            # Initialize the perturbation data matrices after initializing the perturbations
            perturbationsDM = design_matrices.PerturbationDesignMatrix(G=GRAPH)
            perturbationsDM.base.build()
            perturbationsDM.M.build()
        if name == STRNAMES.PERT_VALUE and subjset.perturbations is not None:
            d.design_matrices[STRNAMES.GROWTH_VALUE].build_with_perturbations()

    logging.info(&#39;\n\n\n&#39;)
    logging.info(&#39;Initialization Values:&#39;)
    logging.info(&#39;Growth&#39;)
    logging.info(&#39;\tprior.loc: {}&#39;.format(GRAPH[STRNAMES.GROWTH_VALUE].prior.loc.value))
    logging.info(&#39;\tprior.scale2: {}&#39;.format(GRAPH[STRNAMES.GROWTH_VALUE].prior.scale2.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.GROWTH_VALUE].value.flatten()))

    logging.info(&#39;Self-Interactions&#39;)
    logging.info(&#39;\tprior.loc: {}&#39;.format(GRAPH[STRNAMES.SELF_INTERACTION_VALUE].prior.loc.value))
    logging.info(&#39;\tprior.scale2: {}&#39;.format(GRAPH[STRNAMES.SELF_INTERACTION_VALUE].prior.scale2.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.SELF_INTERACTION_VALUE].value.flatten()))

    logging.info(&#39;Prior Variance Growth&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_GROWTH].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_GROWTH].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_GROWTH].value))

    logging.info(&#39;Prior Variance Self-Interactions&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].value))

    logging.info(&#39;Prior Variance Interactions&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_INTERACTIONS].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_INTERACTIONS].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.PRIOR_VAR_INTERACTIONS].value))

    logging.info(&#39;Process Variance&#39;)
    logging.info(&#39;\tprior.dof: {}&#39;.format(GRAPH[STRNAMES.PROCESSVAR].prior.dof.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.PROCESSVAR].prior.scale.value))
    logging.info(&#39;\tprior mean: {}&#39;.format(GRAPH[STRNAMES.PROCESSVAR].prior.mean()))

    logging.info(&#39;Concentration&#39;)
    logging.info(&#39;\tprior.shape: {}&#39;.format(GRAPH[STRNAMES.CONCENTRATION].prior.shape.value))
    logging.info(&#39;\tprior.scale: {}&#39;.format(GRAPH[STRNAMES.CONCENTRATION].prior.scale.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.CONCENTRATION].value))

    logging.info(&#39;Indicator probability&#39;)
    logging.info(&#39;\tprior.a: {}&#39;.format(GRAPH[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].prior.a.value))
    logging.info(&#39;\tprior.b: {}&#39;.format(GRAPH[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].prior.b.value))
    logging.info(&#39;\tvalue: {}&#39;.format(GRAPH[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value))

    if subjset.perturbations is not None:
        logging.info(&#39;Perturbation values:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\tperturbation {}&#39;.format(perturbation.name))
            logging.info(&#39;\t\tvalue: {}&#39;.format(perturbation.magnitude.value))
            logging.info(&#39;\t\tprior.loc: {}&#39;.format(perturbation.magnitude.prior.loc.value))
        logging.info(&#39;Perturbation prior variances:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\t\tdof: {}&#39;.format(perturbation.magnitude.prior.scale2.prior.dof.value))
            logging.info(&#39;\t\tscale: {}&#39;.format(perturbation.magnitude.prior.scale2.prior.scale.value))
            logging.info(&#39;\t\tvalue: {}&#39;.format(perturbation.magnitude.prior.scale2.value))
        logging.info(&#39;Perturbation indicators:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\tperturbation {}: {}&#39;.format(perturbation.name,
                perturbation.indicator.cluster_array()))
        logging.info(&#39;Perturbation indicator probability:&#39;)
        for perturbation in GRAPH.perturbations:
            logging.info(&#39;\tperturbation {}&#39;.format(perturbation.name))
            logging.info(&#39;\t\tvalue: {}&#39;.format(perturbation.probability.value))
            logging.info(&#39;\t\tprior.a: {}&#39;.format(perturbation.probability.prior.a.value))
            logging.info(&#39;\t\tprior.b: {}&#39;.format(perturbation.probability.prior.b.value))

    logging.info(&#39;\n\n\n&#39;)

    # Setup filenames
    # ---------------
    hdf5_filename = os.path.join(basepath, config.HDF5_FILENAME)
    mcmc_filename = os.path.join(basepath, config.MCMC_FILENAME)
    mcmc.set_tracer(filename=hdf5_filename, checkpoint=params.CHECKPOINT)
    mcmc.set_save_location(mcmc_filename)
    params.save(os.path.join(basepath, config.PARAMS_FILENAME))
    pl.seed(params.SEED)

    return mcmc</code></pre>
</details>
</dd>
<dt id="mdsine2.run.normalize_parameters"><code class="name flex">
<span>def <span class="ident">normalize_parameters</span></span>(<span>mcmc: <a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a>, subjset: <a title="mdsine2.pylab.base.Study" href="pylab/base.html#mdsine2.pylab.base.Study">Study</a>) ‑> Tuple[<a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a>, <a title="mdsine2.pylab.base.Study" href="pylab/base.html#mdsine2.pylab.base.Study">Study</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Normalize the abundance of the parameters by the normalization factor
in the subject set</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>mcmc</code></strong> :&ensp;<code>mdsine2.BaseMCMC</code></dt>
<dd>This is the inference object that has all of the parameters in it</dd>
<dt><strong><code>subjset</code></strong> :&ensp;<code>mdsine2.Study</code></dt>
<dd>This is the data object that contains all of the trajectories</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.BaseMCMC, mdsine2.Study</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize_parameters(mcmc: BaseMCMC, subjset: Study) -&gt; Tuple[BaseMCMC, Study]:
    &#39;&#39;&#39;Normalize the abundance of the parameters by the normalization factor
    in the subject set

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        This is the inference object that has all of the parameters in it
    subjset : mdsine2.Study
        This is the data object that contains all of the trajectories

    Returns
    -------
    mdsine2.BaseMCMC, mdsine2.Study
    &#39;&#39;&#39;
    GRAPH = mcmc.graph
    if subjset.qpcr_normalization_factor is None:
        f = h5py.File(GRAPH.tracer.filename, &#39;r+&#39;, libver=&#39;latest&#39;)
        checkpoint = GRAPH.tracer.checkpoint

        try:
            GRAPH[STRNAMES.FILTERING].v2 *= subjset.qpcr_normalization_factor
        except:
            logging.info(&#39;v2 not applicable&#39;)

        # Adjust the self interactions if necessary
        if STRNAMES.SELF_INTERACTION_VALUE in mcmc.tracer.being_traced:
            dset = f[STRNAMES.SELF_INTERACTION_VALUE]
            dset[:,:] = dset[:,:] / subjset.qpcr_normalization_factor

        if STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS in mcmc.tracer.being_traced:
            dset = f[STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS]
            dset[:] = dset[:] / subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_SELF_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS]
            dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_VARIANCES):
            vs = GRAPH[STRNAMES.QPCR_VARIANCES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_VARIANCES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.QPCR_SCALES):
            vs = GRAPH[STRNAMES.QPCR_SCALES]
            for l in range(vs.L):
                dset = f[STRNAMES.QPCR_SCALES + &#39;_{}&#39;.format(l)]
                dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        # Adjust the interactions if necessary
        if mcmc.tracer.is_being_traced(STRNAMES.INTERACTIONS_OBJ):
            dset = f[STRNAMES.INTERACTIONS_OBJ]
            total_samples = dset.attrs[&#39;end_iter&#39;]
            i = 0
            while (i * checkpoint) &lt; total_samples:
                start_idx = int(i * checkpoint)
                end_idx = int((i+1) * checkpoint)

                if end_idx &gt; total_samples:
                    end_idx = total_samples
                dset[start_idx: end_idx] = dset[start_idx: end_idx] / subjset.qpcr_normalization_factor
                i += 1
        
        if mcmc.is_in_inference_order(STRNAMES.PRIOR_MEAN_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_MEAN_INTERACTIONS]
            dset[:] = dset[:] / subjset.qpcr_normalization_factor

        if mcmc.is_in_inference_order(STRNAMES.PRIOR_VAR_INTERACTIONS):
            dset = f[STRNAMES.PRIOR_VAR_INTERACTIONS]
            dset[:] = dset[:] / (subjset.qpcr_normalization_factor**2)

        if mcmc.is_in_inference_order(STRNAMES.FILTERING):
            for subj in subjset:
                name = STRNAMES.LATENT_TRAJECTORY + &#39;_{}&#39;.format(subj.name)
                if name not in f:
                    continue
                dset = f[name]
                total_samples = dset.attrs[&#39;end_iter&#39;]
                i = 0
                while (i * checkpoint) &lt; total_samples:
                    start_idx = int(i * checkpoint)
                    end_idx = int((i+1) * checkpoint)

                    if end_idx &gt; total_samples:
                        end_idx = total_samples
                    dset[start_idx: end_idx] = dset[start_idx: end_idx]*subjset.qpcr_normalization_factor
                    i += 1

        f.close()
    else:
        logging.info(&#39;Objects are already normalized&#39;)
    
    return mcmc, subjset</code></pre>
</details>
</dd>
<dt id="mdsine2.run.run_graph"><code class="name flex">
<span>def <span class="ident">run_graph</span></span>(<span>mcmc: <a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a>, crash_if_error: bool = True) ‑> <a title="mdsine2.pylab.inference.BaseMCMC" href="pylab/inference.html#mdsine2.pylab.inference.BaseMCMC">BaseMCMC</a></span>
</code></dt>
<dd>
<div class="desc"><p>Run the MCMC chain <code>mcmc</code>. Initialize the MCMC chain with <code>build_graph</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>mcmc</code></strong> :&ensp;<code>mdsine2.BaseMCMC</code></dt>
<dd>Inference object that is already built and initialized</dd>
<dt><strong><code>crash_if_error</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, throws an error if there is an exception during inference. Otherwise
it continues out of inference.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>mdsine2.BaseMCMC</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_graph(mcmc: BaseMCMC, crash_if_error: bool=True) -&gt; BaseMCMC:
    &#39;&#39;&#39;Run the MCMC chain `mcmc`. Initialize the MCMC chain with `build_graph`

    Parameters
    ----------
    mcmc : mdsine2.BaseMCMC
        Inference object that is already built and initialized
    crash_if_error : bool
        If True, throws an error if there is an exception during inference. Otherwise
        it continues out of inference.

    Returns
    -------
    mdsine2.BaseMCMC
    &#39;&#39;&#39;
    try:
        mcmc.run(log_every=1)
    except Exception as e:
        logging.critical(&#39;CHAIN `{}` CRASHED&#39;.format(mcmc.graph.name))
        logging.critical(&#39;Error: {}&#39;.format(e))
        if crash_if_error:
            raise
    mcmc.graph[STRNAMES.FILTERING].kill()
    mcmc.graph[STRNAMES.CLUSTERING].kill()

    if mcmc.graph.data.subjects.qpcr_normalization_factor is not None:
        mcmc, mcmc.graph.data.subjects = denormalize_parameters(mcmc)
    mcmc.graph.data.design_matrices = None
    return mcmc</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mdsine2" href="index.html">mdsine2</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="mdsine2.run.calculate_stability_over_gibbs" href="#mdsine2.run.calculate_stability_over_gibbs">calculate_stability_over_gibbs</a></code></li>
<li><code><a title="mdsine2.run.denormalize_parameters" href="#mdsine2.run.denormalize_parameters">denormalize_parameters</a></code></li>
<li><code><a title="mdsine2.run.initialize_graph" href="#mdsine2.run.initialize_graph">initialize_graph</a></code></li>
<li><code><a title="mdsine2.run.normalize_parameters" href="#mdsine2.run.normalize_parameters">normalize_parameters</a></code></li>
<li><code><a title="mdsine2.run.run_graph" href="#mdsine2.run.run_graph">run_graph</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>